[2024-06-26T07:00:59.088+0000] {processor.py:161} INFO - Started process (PID=1090) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:00:59.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:00:59.092+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:00:59.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:00:59.236+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:00:59.235+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:00:59.237+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:00:59.238+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:00:59.238+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:00:59.239+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:00:59.238+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:00:59.252+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:00:59.252+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:00:59.271+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:00:59.271+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:00:59.272+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:00:59.271+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:00:59.272+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:00:59.291+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:00:59.290+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:00:59.291+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:00:59.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.241 seconds
[2024-06-26T07:01:49.523+0000] {processor.py:161} INFO - Started process (PID=1102) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:01:49.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:01:49.528+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:01:49.526+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:01:49.938+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:01:49.937+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:01:49.938+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:01:49.940+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:01:49.939+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:01:49.940+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:01:49.940+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:01:50.168+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:01:50.168+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:01:50.202+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:01:50.201+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:01:50.207+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:01:50.206+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:01:50.209+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:01:50.259+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:01:50.259+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:01:50.260+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:01:50.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.827 seconds
[2024-06-26T07:02:20.549+0000] {processor.py:161} INFO - Started process (PID=1114) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:02:20.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:02:20.555+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:20.553+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:02:20.744+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:20.742+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:02:20.745+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:02:20.750+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:20.748+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:02:20.751+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:20.751+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:02:20.813+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:20.812+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:02:20.871+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:20.870+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:02:20.876+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:20.875+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:02:20.876+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:02:20.899+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:20.899+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:02:20.900+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:02:20.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.418 seconds
[2024-06-26T07:02:51.182+0000] {processor.py:161} INFO - Started process (PID=1132) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:02:51.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:02:51.188+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:51.188+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:02:51.437+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:51.436+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:02:51.438+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:02:51.441+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:51.440+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:02:51.442+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:51.441+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:02:51.462+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:51.462+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:02:51.493+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:51.491+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:02:51.494+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:51.494+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:02:51.495+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:02:51.516+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:02:51.516+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:02:51.517+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:02:51.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.391 seconds
[2024-06-26T07:03:21.677+0000] {processor.py:161} INFO - Started process (PID=1143) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:03:21.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:03:21.680+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:03:21.680+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:03:21.834+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:03:21.833+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:03:21.835+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:03:21.837+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:03:21.836+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:03:21.838+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:03:21.837+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:03:21.852+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:03:21.851+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:03:21.873+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:03:21.872+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:03:21.874+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:03:21.873+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:03:21.874+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:03:21.899+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:03:21.899+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:03:21.900+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:03:21.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.257 seconds
[2024-06-26T07:04:42.382+0000] {processor.py:161} INFO - Started process (PID=1160) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:04:42.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:04:42.386+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:04:42.386+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:04:43.864+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:04:43.864+0000] {process_utils.py:263} INFO - Waiting up to 5 seconds for processes to exit...
[2024-06-26T07:04:43.865+0000] {logging_mixin.py:188} WARNING - Waiting up to 5 seconds for processes to exit...
[2024-06-26T07:05:19.639+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:05:19.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:05:19.643+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:19.643+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:05:19.745+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:19.744+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:05:19.746+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:05:19.747+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:19.747+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:05:19.748+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:19.748+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:05:19.761+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:19.761+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:05:19.780+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:19.780+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:05:19.781+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:19.781+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:05:19.782+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:05:19.798+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:19.797+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:05:19.798+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:05:19.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.197 seconds
[2024-06-26T07:05:51.164+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:05:51.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:05:51.168+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:51.168+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:05:51.284+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:51.284+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:05:51.285+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:05:51.287+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:51.287+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:05:51.288+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:51.288+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:05:51.307+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:51.307+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:05:51.329+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:51.328+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:05:51.330+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:51.329+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:05:51.330+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:05:51.348+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:05:51.348+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:05:51.349+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:05:51.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.239 seconds
[2024-06-26T07:06:22.020+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:06:22.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:06:22.024+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:22.023+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:06:22.165+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:22.163+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:06:22.165+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:06:22.168+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:22.167+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:06:22.169+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:22.169+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:06:22.212+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:22.208+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:06:22.289+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:22.288+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:06:22.291+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:22.290+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:06:22.292+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:06:22.332+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:22.332+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:06:22.333+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:06:22.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.375 seconds
[2024-06-26T07:06:52.603+0000] {processor.py:161} INFO - Started process (PID=96) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:06:52.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:06:52.607+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:52.607+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:06:52.712+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:52.711+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:06:52.713+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:06:52.715+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:52.715+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:06:52.716+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:52.716+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:06:52.729+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:52.729+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:06:52.747+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:52.747+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:06:52.748+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:52.748+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:06:52.749+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:06:52.765+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:06:52.765+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:06:52.765+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:06:52.795+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.200 seconds
[2024-06-26T07:07:23.303+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:07:23.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:07:23.307+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:23.306+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:07:23.414+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:23.414+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:07:23.415+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:07:23.416+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:23.416+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:07:23.417+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:23.417+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:07:23.431+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:23.430+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:07:23.449+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:23.449+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:07:23.450+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:23.450+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:07:23.450+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:07:23.467+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:23.466+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:07:23.467+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:07:23.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.203 seconds
[2024-06-26T07:07:53.757+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:07:53.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:07:53.760+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:53.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:07:53.867+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:53.866+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:07:53.867+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:07:53.870+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:53.870+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:07:53.871+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:53.871+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:07:53.890+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:53.890+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:07:53.909+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:53.909+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:07:53.910+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:53.910+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:07:53.911+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:07:53.926+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:07:53.926+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:07:53.927+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:07:53.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.210 seconds
[2024-06-26T07:08:24.318+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:08:24.323+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:08:24.327+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:24.326+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:08:24.459+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:24.459+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:08:24.460+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:08:24.461+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:24.461+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:08:24.462+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:24.462+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:08:24.477+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:24.476+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:08:24.497+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:24.497+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:08:24.498+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:24.498+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:08:24.499+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:08:24.517+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:24.517+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:08:24.518+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:08:24.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.243 seconds
[2024-06-26T07:08:55.993+0000] {processor.py:161} INFO - Started process (PID=141) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:08:55.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:08:56.002+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:56.001+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:08:56.279+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:56.279+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:08:56.280+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:08:56.282+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:56.281+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:08:56.283+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:56.282+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:08:56.548+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:56.542+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:08:56.653+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:56.651+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:08:56.654+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:56.654+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:08:56.655+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:08:56.699+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:08:56.699+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:08:56.700+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:08:56.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.798 seconds
[2024-06-26T07:09:49.812+0000] {processor.py:161} INFO - Started process (PID=147) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:09:49.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:09:49.825+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:09:49.822+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:09:51.397+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:09:51.397+0000] {process_utils.py:263} INFO - Waiting up to 5 seconds for processes to exit...
[2024-06-26T07:16:24.697+0000] {processor.py:161} INFO - Started process (PID=52) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:16:24.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:16:24.705+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:24.704+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:16:24.930+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:24.928+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:16:24.932+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:16:24.937+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:24.937+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:16:24.940+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:24.939+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:16:25.000+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:24.999+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:16:25.088+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:25.088+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:16:25.092+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:25.091+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:16:25.095+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:16:25.182+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:25.181+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:16:25.184+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:16:25.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.853 seconds
[2024-06-26T07:16:55.910+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:16:55.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:16:55.915+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:55.914+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:16:56.092+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:56.091+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:16:56.093+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:16:56.096+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:56.096+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:16:56.098+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:56.097+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:16:56.121+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:56.121+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:16:56.167+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:56.166+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:16:56.169+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:56.168+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:16:56.170+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:16:56.216+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:16:56.216+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:16:56.217+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:16:56.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.367 seconds
[2024-06-26T07:17:27.676+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:17:27.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:17:27.681+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:27.680+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:17:27.865+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:27.864+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:17:27.866+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:17:27.869+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:27.868+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:17:27.870+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:27.869+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:17:27.892+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:27.892+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:17:27.923+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:27.923+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:17:27.925+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:27.924+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:17:27.925+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:17:27.952+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:27.951+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:17:27.953+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:17:27.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.336 seconds
[2024-06-26T07:17:59.568+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:17:59.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:17:59.573+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:59.572+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:17:59.784+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:59.783+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:17:59.785+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:17:59.788+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:59.787+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:17:59.789+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:59.788+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:17:59.816+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:59.815+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:17:59.860+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:59.860+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:17:59.862+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:59.861+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:17:59.863+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:17:59.893+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:17:59.893+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:17:59.894+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:17:59.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.380 seconds
[2024-06-26T07:18:31.529+0000] {processor.py:161} INFO - Started process (PID=100) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:18:31.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:18:31.538+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:18:31.537+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:18:31.817+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:18:31.815+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:18:31.818+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:18:31.821+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:18:31.820+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:18:31.822+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:18:31.821+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:18:31.849+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:18:31.848+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:18:31.928+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:18:31.928+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:18:31.932+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:18:31.931+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:18:31.935+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:18:32.008+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:18:32.007+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:18:32.010+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:18:32.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.605 seconds
[2024-06-26T07:19:04.108+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:19:04.111+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:19:04.114+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:04.113+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:19:04.485+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:04.482+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:19:04.487+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:19:04.491+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:04.490+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:19:04.493+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:04.492+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:19:04.523+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:04.523+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:19:04.556+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:04.555+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:19:04.558+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:04.556+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:19:04.559+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:19:04.588+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:04.588+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:19:04.590+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:19:04.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.574 seconds
[2024-06-26T07:19:55.814+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:19:55.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:19:55.828+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:55.820+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:19:56.287+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:56.285+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:19:56.294+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:19:56.302+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:56.301+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:19:56.306+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:56.305+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:19:56.387+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:56.386+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:19:56.499+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:56.498+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:19:56.503+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:56.502+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:19:56.505+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:19:56.598+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:19:56.597+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:19:56.600+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:19:56.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.978 seconds
[2024-06-26T07:20:27.735+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:20:27.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:20:27.742+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:27.741+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:20:28.049+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:28.048+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:20:28.051+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:20:28.056+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:28.055+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:20:28.057+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:28.057+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:20:28.089+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:28.088+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:20:28.138+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:28.137+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:20:28.140+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:28.140+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:20:28.142+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:20:28.187+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:28.187+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:20:28.190+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:20:28.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.584 seconds
[2024-06-26T07:20:58.951+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:20:58.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:20:58.959+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:58.958+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:20:59.166+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:59.165+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:20:59.167+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:20:59.171+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:59.169+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:20:59.173+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:59.172+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:20:59.202+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:59.201+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:20:59.264+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:59.264+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:20:59.266+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:59.265+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:20:59.266+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:20:59.300+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:20:59.300+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:20:59.302+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:20:59.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.420 seconds
[2024-06-26T07:25:37.510+0000] {processor.py:161} INFO - Started process (PID=159) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:25:37.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:25:37.539+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:25:37.533+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:25:38.857+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:25:38.856+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:25:38.858+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:25:38.861+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:25:38.861+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:25:38.863+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:25:38.862+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:25:39.399+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:25:39.399+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:25:39.842+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:25:39.841+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:25:39.846+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:25:39.845+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:25:39.848+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:25:40.015+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:25:40.014+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:25:40.016+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:25:40.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 2.883 seconds
[2024-06-26T07:27:11.036+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:27:11.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:27:11.042+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:27:11.041+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:27:11.276+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:27:11.275+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:27:11.277+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:27:11.279+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:27:11.279+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:27:11.280+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:27:11.280+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:27:11.306+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:27:11.306+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:27:11.338+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:27:11.337+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:27:11.340+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:27:11.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:27:11.340+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:27:11.369+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:27:11.369+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:27:11.370+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:27:11.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.389 seconds
[2024-06-26T07:28:51.964+0000] {processor.py:161} INFO - Started process (PID=82) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:28:51.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:28:51.999+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:28:51.998+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:28:52.303+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:28:52.302+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:28:52.304+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:28:52.306+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:28:52.305+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:28:52.307+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:28:52.306+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:28:52.328+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:28:52.327+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:28:52.362+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:28:52.362+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:28:52.363+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:28:52.363+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:28:52.364+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:28:52.425+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:28:52.425+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:28:52.426+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:28:52.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.750 seconds
[2024-06-26T07:29:22.966+0000] {processor.py:161} INFO - Started process (PID=94) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:29:22.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:29:22.970+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:22.970+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:29:23.126+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:23.125+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:29:23.126+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:29:23.128+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:23.128+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:29:23.128+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:23.128+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:29:23.143+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:23.143+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:29:23.163+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:23.163+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:29:23.164+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:23.163+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:29:23.164+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:29:23.183+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:23.183+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:29:23.183+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:29:23.214+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.260 seconds
[2024-06-26T07:29:53.417+0000] {processor.py:161} INFO - Started process (PID=106) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:29:53.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:29:53.420+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:53.420+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:29:53.534+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:53.534+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:29:53.535+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:29:53.537+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:53.537+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:29:53.538+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:53.538+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:29:53.553+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:53.553+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:29:53.578+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:53.577+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:29:53.579+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:53.579+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:29:53.579+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:29:53.600+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:29:53.600+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:29:53.601+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:29:53.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.221 seconds
[2024-06-26T07:30:24.322+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:30:24.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:30:24.328+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:24.327+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:30:24.722+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:24.719+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:30:24.723+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:30:24.726+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:24.726+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:30:24.727+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:24.727+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:30:24.936+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:24.936+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:30:25.018+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:25.018+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:30:25.019+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:25.019+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:30:25.019+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:30:25.046+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:25.045+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:30:25.047+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:30:25.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.769 seconds
[2024-06-26T07:30:55.690+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:30:55.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:30:55.694+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:55.694+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:30:55.808+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:55.808+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:30:55.809+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:30:55.810+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:55.810+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:30:55.811+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:55.811+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:30:55.825+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:55.825+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:30:55.842+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:55.842+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:30:55.843+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:55.843+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:30:55.844+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:30:55.859+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:30:55.859+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:30:55.860+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:30:55.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.206 seconds
[2024-06-26T07:31:26.584+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:31:26.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:31:26.588+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:26.588+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:31:26.713+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:26.711+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:31:26.714+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:31:26.718+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:26.717+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:31:26.719+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:26.719+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:31:26.738+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:26.737+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:31:26.767+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:26.766+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:31:26.768+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:26.767+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:31:26.768+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:31:26.787+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:26.787+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:31:26.788+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:31:26.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.248 seconds
[2024-06-26T07:31:57.356+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:31:57.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:31:57.360+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:57.359+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:31:57.464+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:57.463+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:31:57.464+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:31:57.466+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:57.465+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:31:57.467+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:57.466+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:31:57.481+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:57.480+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:31:57.498+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:57.498+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:31:57.499+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:57.499+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:31:57.500+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:31:57.516+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:31:57.516+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:31:57.517+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:31:57.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.200 seconds
[2024-06-26T07:32:27.683+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:32:27.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:32:27.687+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:27.686+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:32:27.795+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:27.794+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:32:27.795+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:32:27.797+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:27.797+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:32:27.798+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:27.798+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:32:27.812+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:27.812+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:32:27.830+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:27.829+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:32:27.831+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:27.830+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:32:27.831+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:32:27.846+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:27.846+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:32:27.847+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:32:27.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.198 seconds
[2024-06-26T07:32:58.205+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:32:58.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:32:58.210+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:58.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:32:58.330+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:58.330+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:32:58.331+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:32:58.334+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:58.334+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:32:58.335+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:58.335+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:32:58.350+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:58.349+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:32:58.368+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:58.368+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:32:58.369+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:58.369+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:32:58.370+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:32:58.389+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:32:58.389+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:32:58.390+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:32:58.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.221 seconds
[2024-06-26T07:33:29.065+0000] {processor.py:161} INFO - Started process (PID=191) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:33:29.067+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:33:29.070+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:29.070+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:33:29.212+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:29.211+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:33:29.212+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:33:29.214+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:29.214+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:33:29.215+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:29.215+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:33:29.237+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:29.236+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:33:29.267+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:29.267+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:33:29.268+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:29.268+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:33:29.269+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:33:29.290+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:29.289+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:33:29.290+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:33:29.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.268 seconds
[2024-06-26T07:33:59.756+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:33:59.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:33:59.761+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:59.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:33:59.881+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:59.880+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:33:59.882+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:33:59.884+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:59.884+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:33:59.885+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:59.885+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:33:59.900+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:59.899+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:33:59.919+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:59.919+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:33:59.920+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:59.920+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:33:59.921+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:33:59.937+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:33:59.937+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:33:59.938+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:33:59.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.225 seconds
[2024-06-26T07:34:30.801+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:34:30.804+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:34:30.810+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:34:30.808+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:34:30.962+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:34:30.961+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:34:30.962+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:34:30.966+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:34:30.964+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:34:30.968+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:34:30.967+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:34:30.992+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:34:30.992+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:34:31.023+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:34:31.023+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:34:31.025+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:34:31.024+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:34:31.026+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:34:31.050+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:34:31.049+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:34:31.051+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:34:31.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.288 seconds
[2024-06-26T07:35:01.350+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:35:01.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:35:01.354+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:01.353+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:35:01.461+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:01.460+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:35:01.462+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:35:01.464+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:01.464+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:35:01.465+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:01.465+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:35:01.479+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:01.479+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:35:01.496+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:01.496+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:35:01.497+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:01.497+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:35:01.498+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:35:01.513+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:01.513+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:35:01.514+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:35:01.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.202 seconds
[2024-06-26T07:35:31.653+0000] {processor.py:161} INFO - Started process (PID=238) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:35:31.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:35:31.656+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:31.656+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:35:31.767+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:31.767+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:35:31.768+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:35:31.770+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:31.770+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:35:31.771+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:31.770+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:35:31.785+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:31.785+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:35:31.803+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:31.803+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:35:31.804+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:31.804+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:35:31.805+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:35:31.821+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:35:31.820+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:35:31.821+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:35:31.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.206 seconds
[2024-06-26T07:36:03.003+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:36:03.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:36:03.010+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:03.009+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:36:03.248+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:03.247+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:36:03.249+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:36:03.251+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:03.250+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:36:03.251+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:03.251+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:36:03.270+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:03.270+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:36:03.291+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:03.290+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:36:03.292+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:03.292+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:36:03.293+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:36:03.309+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:03.309+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:36:03.310+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:36:03.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.339 seconds
[2024-06-26T07:36:33.826+0000] {processor.py:161} INFO - Started process (PID=263) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:36:33.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:36:33.831+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:33.830+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:36:33.954+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:33.954+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:36:33.955+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:36:33.956+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:33.956+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:36:33.957+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:33.957+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:36:33.972+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:33.971+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:36:33.993+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:33.993+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:36:33.995+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:33.994+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:36:33.996+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:36:34.013+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:36:34.012+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:36:34.013+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:36:34.040+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.224 seconds
[2024-06-26T07:37:04.406+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:37:04.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:37:04.411+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:04.410+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:37:04.533+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:04.532+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:37:04.534+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:37:04.536+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:04.535+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:37:04.536+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:04.536+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:37:04.553+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:04.553+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:37:04.573+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:04.572+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:37:04.574+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:04.574+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:37:04.574+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:37:04.592+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:04.592+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:37:04.593+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:37:04.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.230 seconds
[2024-06-26T07:37:35.342+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:37:35.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:37:35.346+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:35.345+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:37:35.448+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:35.447+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:37:35.448+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:37:35.450+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:35.450+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:37:35.451+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:35.451+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:37:35.464+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:35.464+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:37:35.483+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:35.483+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:37:35.484+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:35.484+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:37:35.485+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:37:35.504+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:37:35.504+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:37:35.504+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:37:35.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.199 seconds
[2024-06-26T07:38:06.124+0000] {processor.py:161} INFO - Started process (PID=299) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:38:06.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:38:06.129+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:06.128+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:38:06.252+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:06.250+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:38:06.253+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:38:06.255+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:06.255+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:38:06.256+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:06.256+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:38:06.273+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:06.273+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:38:06.291+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:06.291+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:38:06.292+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:06.292+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:38:06.293+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:38:06.308+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:06.308+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:38:06.309+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:38:06.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.222 seconds
[2024-06-26T07:38:36.964+0000] {processor.py:161} INFO - Started process (PID=311) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:38:36.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:38:36.968+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:36.968+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:38:37.100+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:37.099+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:38:37.101+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:38:37.103+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:37.102+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:38:37.105+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:37.104+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:38:37.121+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:37.121+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:38:37.150+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:37.150+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:38:37.151+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:37.151+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:38:37.152+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:38:37.177+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:38:37.177+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:38:37.178+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:38:37.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.262 seconds
[2024-06-26T07:39:07.848+0000] {processor.py:161} INFO - Started process (PID=323) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:39:07.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:39:07.853+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:07.852+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:39:07.981+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:07.980+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:39:07.981+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:39:07.983+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:07.983+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:39:07.984+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:07.984+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:39:08.005+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:08.004+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:39:08.047+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:08.047+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:39:08.048+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:08.048+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:39:08.049+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:39:08.071+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:08.071+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:39:08.072+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:39:08.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.260 seconds
[2024-06-26T07:39:38.658+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:39:38.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:39:38.663+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:38.662+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:39:38.787+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:38.787+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:39:38.788+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:39:38.790+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:38.789+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:39:38.791+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:38.790+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:39:38.806+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:38.806+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:39:38.826+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:38.826+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:39:38.827+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:38.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:39:38.828+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:39:38.843+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:39:38.843+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:39:38.844+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:39:38.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.226 seconds
[2024-06-26T07:40:09.394+0000] {processor.py:161} INFO - Started process (PID=347) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:40:09.395+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:40:09.398+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:09.397+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:40:09.513+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:09.512+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:40:09.514+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:40:09.515+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:09.515+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:40:09.516+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:09.516+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:40:09.533+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:09.533+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:40:09.555+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:09.554+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:40:09.555+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:09.555+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:40:09.556+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:40:09.574+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:09.574+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:40:09.575+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:40:09.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.225 seconds
[2024-06-26T07:40:40.154+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:40:40.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:40:40.159+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:40.158+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:40:40.264+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:40.263+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:40:40.265+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:40:40.267+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:40.267+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:40:40.268+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:40.268+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:40:40.283+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:40.282+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:40:40.303+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:40.303+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:40:40.304+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:40.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:40:40.305+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:40:40.323+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:40:40.322+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:40:40.323+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:40:40.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.208 seconds
[2024-06-26T07:41:10.905+0000] {processor.py:161} INFO - Started process (PID=371) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:41:10.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:41:10.908+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:10.908+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:41:11.013+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:11.012+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:41:11.014+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:41:11.016+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:11.016+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:41:11.018+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:11.017+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:41:11.036+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:11.036+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:41:11.054+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:11.054+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:41:11.055+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:11.055+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:41:11.056+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:41:11.072+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:11.072+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:41:11.073+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:41:11.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.200 seconds
[2024-06-26T07:41:41.607+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:41:41.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:41:41.611+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:41.610+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:41:41.717+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:41.716+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:41:41.717+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:41:41.719+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:41.719+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:41:41.720+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:41.720+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:41:41.734+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:41.734+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:41:41.752+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:41.752+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:41:41.753+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:41.753+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:41:41.754+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:41:41.770+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:41:41.769+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:41:41.770+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:41:41.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.203 seconds
[2024-06-26T07:42:12.244+0000] {processor.py:161} INFO - Started process (PID=396) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:42:12.246+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:42:12.248+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:12.248+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:42:12.361+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:12.360+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:42:12.362+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:42:12.363+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:12.363+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:42:12.364+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:12.364+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:42:12.378+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:12.378+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:42:12.396+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:12.396+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:42:12.397+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:12.397+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:42:12.398+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:42:12.416+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:12.415+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:42:12.417+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:42:12.447+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.210 seconds
[2024-06-26T07:42:43.039+0000] {processor.py:161} INFO - Started process (PID=408) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:42:43.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:42:43.044+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:43.043+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:42:43.186+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:43.185+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:42:43.187+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:42:43.189+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:43.189+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:42:43.189+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:43.189+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:42:43.206+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:43.205+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:42:43.225+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:43.225+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:42:43.226+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:43.225+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:42:43.226+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:42:43.243+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:42:43.242+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:42:43.243+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:42:43.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.273 seconds
[2024-06-26T07:43:13.524+0000] {processor.py:161} INFO - Started process (PID=420) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:43:13.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:43:13.532+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:13.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:43:13.635+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:13.634+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:43:13.635+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:43:13.637+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:13.636+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:43:13.637+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:13.637+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:43:13.651+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:13.650+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:43:13.670+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:13.670+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:43:13.671+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:13.671+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:43:13.671+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:43:13.689+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:13.688+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:43:13.690+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:43:13.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.211 seconds
[2024-06-26T07:43:43.897+0000] {processor.py:161} INFO - Started process (PID=432) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:43:43.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:43:43.901+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:43.900+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:43:44.009+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:44.008+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:43:44.009+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:43:44.011+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:44.011+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:43:44.012+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:44.011+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:43:44.027+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:44.027+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:43:44.046+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:44.046+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:43:44.047+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:44.047+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:43:44.048+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:43:44.065+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:43:44.065+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:43:44.066+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:43:44.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.213 seconds
[2024-06-26T07:44:15.206+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:44:15.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:44:15.209+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:15.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:44:15.320+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:15.320+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:44:15.321+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:44:15.323+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:15.322+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:44:15.323+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:15.323+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:44:15.337+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:15.337+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:44:15.354+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:15.354+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:44:15.355+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:15.355+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:44:15.356+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:44:15.371+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:15.370+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:44:15.371+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:44:15.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.223 seconds
[2024-06-26T07:44:46.297+0000] {processor.py:161} INFO - Started process (PID=457) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:44:46.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:44:46.303+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:46.303+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:44:46.516+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:46.515+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:44:46.517+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:44:46.519+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:46.518+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:44:46.521+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:46.521+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:44:46.547+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:46.546+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:44:46.583+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:46.582+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:44:46.585+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:46.584+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:44:46.587+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:44:46.615+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:44:46.615+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:44:46.616+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:44:46.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.378 seconds
[2024-06-26T07:45:17.286+0000] {processor.py:161} INFO - Started process (PID=469) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:45:17.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:45:17.296+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:17.295+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:45:17.458+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:17.458+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:45:17.459+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:45:17.461+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:17.461+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:45:17.462+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:17.462+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:45:17.480+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:17.479+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:45:17.509+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:17.509+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:45:17.510+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:17.510+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:45:17.511+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:45:17.532+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:17.532+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:45:17.533+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:45:17.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.298 seconds
[2024-06-26T07:45:47.721+0000] {processor.py:161} INFO - Started process (PID=481) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:45:47.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:45:47.726+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:47.725+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:45:47.904+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:47.901+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:45:47.905+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:45:47.910+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:47.908+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:45:47.913+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:47.912+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:45:47.952+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:47.950+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:45:48.001+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:48.000+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:45:48.002+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:48.002+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:45:48.003+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:45:48.037+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:45:48.037+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:45:48.038+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:45:48.080+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.370 seconds
[2024-06-26T07:46:18.176+0000] {processor.py:161} INFO - Started process (PID=492) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:46:18.177+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:46:18.181+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:18.180+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:46:18.287+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:18.287+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:46:18.288+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:46:18.289+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:18.289+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:46:18.290+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:18.290+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:46:18.308+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:18.307+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:46:18.336+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:18.335+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:46:18.337+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:18.337+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:46:18.338+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:46:18.366+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:18.366+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:46:18.369+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:46:18.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.239 seconds
[2024-06-26T07:46:48.541+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:46:48.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:46:48.545+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:48.544+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:46:48.664+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:48.662+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:46:48.665+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:46:48.667+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:48.667+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:46:48.668+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:48.667+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:46:48.681+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:48.680+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:46:48.699+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:48.698+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:46:48.700+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:48.699+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:46:48.700+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:46:48.717+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:46:48.716+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:46:48.717+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:46:48.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.218 seconds
[2024-06-26T07:47:19.692+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:47:19.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:47:19.696+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:19.695+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:47:19.819+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:19.818+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:47:19.820+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:47:19.821+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:19.821+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:47:19.822+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:19.822+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:47:19.839+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:19.839+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:47:19.859+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:19.859+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:47:19.860+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:19.860+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:47:19.861+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:47:19.889+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:19.889+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:47:19.890+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:47:19.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.242 seconds
[2024-06-26T07:47:50.490+0000] {processor.py:161} INFO - Started process (PID=527) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:47:50.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:47:50.495+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:50.495+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:47:50.604+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:50.604+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:47:50.605+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:47:50.606+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:50.606+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:47:50.607+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:50.607+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:47:50.621+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:50.621+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:47:50.639+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:50.639+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:47:50.640+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:50.640+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:47:50.641+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:47:50.658+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:47:50.658+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:47:50.659+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:47:50.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.210 seconds
[2024-06-26T07:48:21.389+0000] {processor.py:161} INFO - Started process (PID=539) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:48:21.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:48:21.394+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:21.394+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:48:21.526+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:21.525+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:48:21.527+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:48:21.528+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:21.528+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:48:21.529+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:21.529+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:48:21.548+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:21.547+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:48:21.572+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:21.572+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:48:21.574+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:21.573+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:48:21.576+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:48:21.597+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:21.597+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:48:21.599+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:48:21.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.264 seconds
[2024-06-26T07:48:51.858+0000] {processor.py:161} INFO - Started process (PID=551) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:48:51.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:48:51.862+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:51.862+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:48:51.964+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:51.963+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:48:51.965+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:48:51.966+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:51.966+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:48:51.967+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:51.967+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:48:51.981+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:51.981+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:48:51.999+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:51.999+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:48:52.000+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:52.000+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:48:52.001+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:48:52.015+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:48:52.015+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:48:52.016+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:48:52.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.193 seconds
[2024-06-26T07:49:23.017+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:49:23.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:49:23.021+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:23.021+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:49:23.152+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:23.152+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:49:23.153+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:49:23.155+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:23.154+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:49:23.155+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:23.155+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:49:23.171+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:23.171+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:49:23.198+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:23.198+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:49:23.199+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:23.199+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:49:23.200+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:49:23.228+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:23.228+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:49:23.229+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:49:23.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.255 seconds
[2024-06-26T07:49:53.907+0000] {processor.py:161} INFO - Started process (PID=579) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:49:53.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:49:53.915+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:53.914+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:49:54.042+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:54.041+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:49:54.042+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:49:54.044+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:54.044+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:49:54.045+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:54.044+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:49:54.061+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:54.061+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:49:54.085+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:54.085+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:49:54.087+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:54.087+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:49:54.088+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:49:54.108+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:49:54.108+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:49:54.109+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:49:54.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.260 seconds
[2024-06-26T07:50:24.308+0000] {processor.py:161} INFO - Started process (PID=590) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:50:24.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:50:24.312+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:24.311+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:50:24.468+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:24.467+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:50:24.469+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:50:24.471+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:24.470+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:50:24.471+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:24.471+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:50:24.491+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:24.490+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:50:24.513+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:24.513+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:50:24.514+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:24.514+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:50:24.515+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:50:24.537+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:24.537+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:50:24.538+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:50:24.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.273 seconds
[2024-06-26T07:50:55.155+0000] {processor.py:161} INFO - Started process (PID=602) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:50:55.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:50:55.159+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:55.159+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:50:55.264+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:55.263+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:50:55.265+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:50:55.267+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:55.266+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:50:55.268+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:55.267+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:50:55.282+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:55.282+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:50:55.300+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:55.300+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:50:55.301+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:55.301+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:50:55.302+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:50:55.317+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:50:55.316+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:50:55.317+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:50:55.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.197 seconds
[2024-06-26T07:51:27.246+0000] {processor.py:161} INFO - Started process (PID=621) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:51:27.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:51:27.254+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:27.253+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:51:27.428+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:27.428+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:51:27.429+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:51:27.431+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:27.431+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:51:27.433+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:27.432+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:51:27.450+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:27.449+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:51:27.480+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:27.479+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:51:27.482+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:27.481+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:51:27.483+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:51:27.508+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:27.507+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:51:27.508+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:51:27.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.311 seconds
[2024-06-26T07:51:58.117+0000] {processor.py:161} INFO - Started process (PID=634) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:51:58.118+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:51:58.121+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:58.120+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:51:58.231+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:58.229+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:51:58.231+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:51:58.233+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:58.232+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:51:58.233+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:58.233+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:51:58.247+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:58.247+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:51:58.266+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:58.266+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:51:58.268+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:58.267+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:51:58.268+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:51:58.289+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:51:58.289+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:51:58.290+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:51:58.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.208 seconds
[2024-06-26T07:52:28.446+0000] {processor.py:161} INFO - Started process (PID=645) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:52:28.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:52:28.451+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:28.450+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:52:28.551+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:28.550+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:52:28.551+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:52:28.553+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:28.553+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:52:28.554+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:28.553+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:52:28.567+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:28.567+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:52:28.585+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:28.585+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:52:28.586+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:28.585+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:52:28.586+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:52:28.603+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:28.603+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:52:28.604+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:52:28.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.199 seconds
[2024-06-26T07:52:58.845+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:52:58.846+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:52:58.848+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:58.848+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:52:58.950+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:58.949+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:52:58.951+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:52:58.952+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:58.952+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:52:58.953+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:58.953+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:52:58.968+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:58.968+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:52:58.986+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:58.985+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:52:58.987+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:58.986+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:52:58.987+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:52:59.003+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:52:59.003+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:52:59.004+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:52:59.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.199 seconds
[2024-06-26T07:53:29.815+0000] {processor.py:161} INFO - Started process (PID=669) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:53:29.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:53:29.820+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:53:29.819+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:53:29.929+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:53:29.928+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:53:29.930+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:53:29.932+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:53:29.931+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:53:29.933+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:53:29.932+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:53:29.947+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:53:29.947+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:53:29.965+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:53:29.964+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:53:29.966+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:53:29.965+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:53:29.966+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:53:29.982+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:53:29.981+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:53:29.982+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:53:30.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.201 seconds
[2024-06-26T07:54:00.509+0000] {processor.py:161} INFO - Started process (PID=681) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:54:00.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:54:00.513+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:00.512+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:54:00.623+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:00.623+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:54:00.624+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:54:00.626+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:00.626+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:54:00.627+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:00.627+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:54:00.640+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:00.640+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:54:00.658+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:00.658+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:54:00.659+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:00.659+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:54:00.660+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:54:00.675+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:00.674+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:54:00.675+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:54:00.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.200 seconds
[2024-06-26T07:54:30.996+0000] {processor.py:161} INFO - Started process (PID=694) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:54:30.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:54:31.000+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:31.000+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:54:31.125+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:31.124+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:54:31.126+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:54:31.128+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:31.128+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:54:31.129+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:31.129+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:54:31.144+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:31.144+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:54:31.162+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:31.162+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:54:31.163+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:31.163+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:54:31.164+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:54:31.181+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:54:31.181+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:54:31.182+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:54:31.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.219 seconds
[2024-06-26T07:55:01.928+0000] {processor.py:161} INFO - Started process (PID=706) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:55:01.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:55:01.931+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:01.931+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:55:02.049+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:02.048+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:55:02.050+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:55:02.052+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:02.052+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:55:02.053+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:02.053+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:55:02.067+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:02.067+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:55:02.086+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:02.085+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:55:02.087+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:02.086+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:55:02.087+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:55:02.104+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:02.104+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:55:02.105+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:55:02.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.211 seconds
[2024-06-26T07:55:32.960+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:55:32.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:55:32.964+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:32.963+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:55:33.080+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:33.079+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:55:33.081+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:55:33.082+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:33.082+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:55:33.083+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:33.083+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:55:33.096+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:33.096+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:55:33.114+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:33.114+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:55:33.115+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:33.115+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:55:33.115+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:55:33.133+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:55:33.133+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:55:33.134+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:55:33.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.216 seconds
[2024-06-26T07:56:03.758+0000] {processor.py:161} INFO - Started process (PID=732) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:56:03.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:56:03.761+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:03.761+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:56:03.872+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:03.871+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:56:03.873+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:56:03.875+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:03.874+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:56:03.876+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:03.875+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:56:03.891+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:03.890+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:56:03.913+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:03.912+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:56:03.914+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:03.914+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:56:03.914+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:56:03.933+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:03.933+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:56:03.933+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:56:03.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.215 seconds
[2024-06-26T07:56:35.206+0000] {processor.py:161} INFO - Started process (PID=744) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:56:35.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:56:35.210+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:35.209+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:56:35.350+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:35.348+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:56:35.351+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:56:35.369+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:35.369+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:56:35.370+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:35.370+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:56:35.524+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:35.524+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:56:35.687+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:35.687+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:56:35.690+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:35.688+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:56:35.690+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:56:35.833+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:56:35.833+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:56:35.833+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:56:35.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.752 seconds
[2024-06-26T07:57:06.671+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:57:06.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:57:06.674+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:06.673+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:57:06.794+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:06.793+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:57:06.795+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:57:06.797+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:06.796+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:57:06.798+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:06.797+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:57:06.816+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:06.816+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:57:06.836+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:06.836+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:57:06.838+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:06.837+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:57:06.838+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:57:06.869+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:06.868+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:57:06.870+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:57:06.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.244 seconds
[2024-06-26T07:57:37.462+0000] {processor.py:161} INFO - Started process (PID=767) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:57:37.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:57:37.465+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:37.464+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:57:37.589+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:37.588+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:57:37.590+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:57:37.592+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:37.592+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:57:37.593+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:37.592+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:57:37.608+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:37.608+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:57:37.628+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:37.628+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:57:37.629+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:37.629+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:57:37.630+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:57:37.647+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:57:37.647+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:57:37.648+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:57:37.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.227 seconds
[2024-06-26T07:58:07.876+0000] {processor.py:161} INFO - Started process (PID=779) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:58:07.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:58:07.879+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:07.879+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:58:07.996+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:07.995+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:58:07.996+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:58:07.998+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:07.998+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:58:07.998+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:07.998+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:58:08.012+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:08.012+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:58:08.031+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:08.031+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:58:08.032+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:08.032+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:58:08.032+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:58:08.048+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:08.048+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:58:08.049+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:58:08.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.221 seconds
[2024-06-26T07:58:38.801+0000] {processor.py:161} INFO - Started process (PID=791) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:58:38.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:58:38.804+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:38.803+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:58:38.915+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:38.915+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:58:38.916+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:58:38.918+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:38.917+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:58:38.918+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:38.918+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:58:38.934+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:38.934+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:58:38.953+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:38.953+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:58:38.954+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:38.954+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:58:38.955+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:58:38.976+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:58:38.976+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:58:38.977+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:58:39.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.222 seconds
[2024-06-26T07:59:09.952+0000] {processor.py:161} INFO - Started process (PID=803) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:59:09.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:59:09.955+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:09.955+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:59:10.062+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:10.060+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:59:10.063+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:59:10.064+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:10.064+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:59:10.065+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:10.065+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:59:10.080+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:10.080+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:59:10.102+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:10.102+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:59:10.103+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:10.103+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:59:10.104+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:59:10.122+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:10.122+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:59:10.123+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:59:10.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.208 seconds
[2024-06-26T07:59:40.231+0000] {processor.py:161} INFO - Started process (PID=814) to work on /opt/airflow/dags/crawl.py
[2024-06-26T07:59:40.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T07:59:40.235+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:40.234+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T07:59:40.345+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:40.344+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T07:59:40.346+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T07:59:40.348+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:40.347+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T07:59:40.349+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:40.349+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T07:59:40.363+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:40.362+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T07:59:40.381+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:40.381+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T07:59:40.382+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:40.382+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T07:59:40.383+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T07:59:40.399+0000] {logging_mixin.py:188} INFO - [2024-06-26T07:59:40.399+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:59:40.400+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T07:59:40.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.204 seconds
[2024-06-26T08:00:11.122+0000] {processor.py:161} INFO - Started process (PID=827) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:00:11.123+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:00:11.124+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:11.124+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:00:11.237+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:11.236+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:00:11.237+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:00:11.239+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:11.239+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:00:11.240+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:11.240+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:00:11.255+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:11.255+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:00:11.274+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:11.274+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:00:11.275+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:11.275+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:00:11.275+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:00:11.292+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:11.292+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:00:11.293+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:00:11.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.209 seconds
[2024-06-26T08:00:41.490+0000] {processor.py:161} INFO - Started process (PID=838) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:00:41.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:00:41.493+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:41.493+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:00:41.607+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:41.606+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:00:41.607+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:00:41.609+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:41.608+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:00:41.609+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:41.609+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:00:41.624+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:41.624+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:00:41.643+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:41.642+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:00:41.643+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:41.643+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:00:41.644+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:00:41.661+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:00:41.661+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:00:41.662+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:00:41.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.212 seconds
[2024-06-26T08:01:12.136+0000] {processor.py:161} INFO - Started process (PID=851) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:01:12.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:01:12.138+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:12.138+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:01:12.255+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:12.253+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:01:12.256+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:01:12.257+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:12.257+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:01:12.258+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:12.258+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:01:12.274+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:12.273+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:01:12.293+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:12.292+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:01:12.294+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:12.294+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:01:12.295+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:01:12.314+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:12.313+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:01:12.315+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:01:12.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.222 seconds
[2024-06-26T08:01:42.723+0000] {processor.py:161} INFO - Started process (PID=863) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:01:42.724+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:01:42.726+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:42.725+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:01:42.848+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:42.847+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:01:42.849+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:01:42.851+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:42.850+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:01:42.851+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:42.851+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:01:42.866+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:42.865+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:01:42.884+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:42.884+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:01:42.885+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:42.885+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:01:42.885+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:01:42.904+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:01:42.904+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:01:42.905+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:01:42.936+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.224 seconds
[2024-06-26T08:02:13.444+0000] {processor.py:161} INFO - Started process (PID=875) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:02:13.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:02:13.448+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:13.447+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:02:13.565+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:13.564+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:02:13.565+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:02:13.568+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:13.567+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:02:13.569+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:13.568+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:02:13.585+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:13.584+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:02:13.605+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:13.605+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:02:13.606+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:13.606+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:02:13.607+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:02:13.623+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:13.623+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:02:13.624+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:02:13.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.223 seconds
[2024-06-26T08:02:44.209+0000] {processor.py:161} INFO - Started process (PID=887) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:02:44.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:02:44.212+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:44.211+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:02:44.325+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:44.325+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:02:44.326+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:02:44.328+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:44.327+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:02:44.328+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:44.328+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:02:44.343+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:44.343+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:02:44.370+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:44.370+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:02:44.371+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:44.371+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:02:44.372+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:02:44.392+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:02:44.391+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:02:44.392+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:02:44.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.225 seconds
[2024-06-26T08:03:14.693+0000] {processor.py:161} INFO - Started process (PID=898) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:03:14.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:03:14.696+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:14.696+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:03:14.812+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:14.811+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:03:14.813+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:03:14.814+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:14.814+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:03:14.815+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:14.815+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:03:14.829+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:14.829+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:03:14.848+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:14.848+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:03:14.850+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:14.849+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:03:14.851+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:03:14.867+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:14.866+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:03:14.868+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:03:14.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.211 seconds
[2024-06-26T08:03:45.235+0000] {processor.py:161} INFO - Started process (PID=910) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:03:45.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:03:45.239+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:45.238+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:03:45.354+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:45.353+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:03:45.355+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:03:45.356+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:45.356+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:03:45.357+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:45.357+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:03:45.372+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:45.371+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:03:45.393+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:45.393+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:03:45.394+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:45.394+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:03:45.395+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:03:45.411+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:03:45.411+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:03:45.412+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:03:45.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.215 seconds
[2024-06-26T08:04:15.885+0000] {processor.py:161} INFO - Started process (PID=922) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:04:15.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:04:15.889+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:15.888+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:04:16.004+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:16.004+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:04:16.005+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:04:16.007+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:16.007+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:04:16.008+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:16.008+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:04:16.022+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:16.022+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:04:16.041+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:16.041+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:04:16.042+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:16.042+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:04:16.043+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:04:16.060+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:16.059+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:04:16.061+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:04:16.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.215 seconds
[2024-06-26T08:04:46.490+0000] {processor.py:161} INFO - Started process (PID=934) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:04:46.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:04:46.495+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:46.494+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:04:46.630+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:46.630+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:04:46.631+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:04:46.633+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:46.632+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:04:46.633+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:46.633+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:04:46.650+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:46.650+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:04:46.670+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:46.670+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:04:46.671+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:46.671+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:04:46.672+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:04:46.688+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:04:46.688+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:04:46.689+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:04:46.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.237 seconds
[2024-06-26T08:05:17.385+0000] {processor.py:161} INFO - Started process (PID=947) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:05:17.387+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:05:17.389+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:17.388+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:05:17.501+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:17.500+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:05:17.501+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:05:17.502+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:17.502+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:05:17.503+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:17.503+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:05:17.517+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:17.516+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:05:17.534+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:17.534+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:05:17.535+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:17.535+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:05:17.536+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:05:17.552+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:17.551+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:05:17.552+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:05:17.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.209 seconds
[2024-06-26T08:05:47.899+0000] {processor.py:161} INFO - Started process (PID=960) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:05:47.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:05:47.903+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:47.902+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:05:48.053+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:48.052+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:05:48.053+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:05:48.055+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:48.055+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:05:48.055+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:48.055+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:05:48.074+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:48.074+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:05:48.101+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:48.101+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:05:48.102+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:48.102+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:05:48.103+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:05:48.122+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:05:48.121+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:05:48.122+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:05:48.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.266 seconds
[2024-06-26T08:06:18.644+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:06:18.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:06:18.647+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:18.646+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:06:18.785+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:18.784+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:06:18.785+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:06:18.787+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:18.786+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:06:18.788+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:18.787+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:06:18.807+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:18.806+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:06:18.835+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:18.834+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:06:18.835+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:18.835+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:06:18.836+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:06:18.865+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:18.865+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:06:18.866+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:06:19.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.481 seconds
[2024-06-26T08:06:49.540+0000] {processor.py:161} INFO - Started process (PID=984) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:06:49.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:06:49.542+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:49.542+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:06:49.650+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:49.649+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:06:49.651+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:06:49.653+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:49.653+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:06:49.654+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:49.654+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:06:49.668+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:49.668+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:06:49.687+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:49.686+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:06:49.688+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:49.687+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:06:49.688+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:06:49.704+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:06:49.703+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:06:49.705+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:06:49.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.202 seconds
[2024-06-26T08:07:19.792+0000] {processor.py:161} INFO - Started process (PID=995) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:07:19.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:07:19.794+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:19.794+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:07:19.927+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:19.926+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:07:19.929+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:07:19.931+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:19.930+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:07:19.932+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:19.931+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:07:19.953+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:19.952+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:07:19.982+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:19.981+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:07:19.983+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:19.983+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:07:19.984+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:07:20.005+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:20.004+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:07:20.006+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:07:20.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.259 seconds
[2024-06-26T08:07:50.825+0000] {processor.py:161} INFO - Started process (PID=1008) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:07:50.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:07:50.827+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:50.827+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:07:50.939+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:50.938+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:07:50.940+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:07:50.942+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:50.942+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:07:50.943+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:50.943+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:07:50.960+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:50.959+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:07:50.979+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:50.979+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:07:50.980+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:50.980+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:07:50.981+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:07:51.218+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:07:51.217+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:07:51.219+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:07:51.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.437 seconds
[2024-06-26T08:08:21.386+0000] {processor.py:161} INFO - Started process (PID=1019) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:08:21.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:08:21.389+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:21.389+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:08:21.509+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:21.507+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:08:21.510+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:08:21.512+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:21.511+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:08:21.513+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:21.512+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:08:21.526+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:21.526+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:08:21.547+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:21.546+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:08:21.548+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:21.547+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:08:21.548+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:08:21.578+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:21.577+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:08:21.578+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:08:21.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.237 seconds
[2024-06-26T08:08:51.934+0000] {processor.py:161} INFO - Started process (PID=1031) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:08:51.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:08:51.938+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:51.938+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:08:52.054+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:52.054+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:08:52.055+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:08:52.057+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:52.056+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:08:52.057+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:52.057+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:08:52.073+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:52.073+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:08:52.093+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:52.093+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:08:52.094+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:52.094+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:08:52.095+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:08:52.114+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:08:52.114+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:08:52.115+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:08:52.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.230 seconds
[2024-06-26T08:09:22.861+0000] {processor.py:161} INFO - Started process (PID=1044) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:09:22.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:09:22.864+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:22.863+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:09:22.993+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:22.993+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:09:22.994+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:09:22.996+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:22.996+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:09:22.997+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:22.996+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:09:23.013+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:23.013+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:09:23.040+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:23.040+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:09:23.041+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:23.041+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:09:23.042+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:09:23.060+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:23.060+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:09:23.061+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:09:23.243+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.390 seconds
[2024-06-26T08:09:53.491+0000] {processor.py:161} INFO - Started process (PID=1056) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:09:53.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:09:53.494+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:53.493+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:09:53.593+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:53.592+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:09:53.594+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:09:53.596+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:53.595+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:09:53.596+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:53.596+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:09:53.610+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:53.610+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:09:53.772+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:53.772+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:09:53.773+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:53.773+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:09:53.778+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:09:53.791+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:09:53.790+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:09:53.791+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:09:53.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.336 seconds
[2024-06-26T08:10:24.230+0000] {processor.py:161} INFO - Started process (PID=1068) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:10:24.231+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:10:24.232+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:24.232+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:10:24.349+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:24.348+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:10:24.350+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:10:24.351+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:24.351+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:10:24.352+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:24.352+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:10:24.366+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:24.366+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:10:24.383+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:24.383+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:10:24.384+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:24.384+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:10:24.385+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:10:24.400+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:24.400+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:10:24.401+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:10:24.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.209 seconds
[2024-06-26T08:10:55.181+0000] {processor.py:161} INFO - Started process (PID=1080) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:10:55.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:10:55.186+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:55.185+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:10:55.301+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:55.300+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:10:55.301+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:10:55.303+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:55.303+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:10:55.304+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:55.303+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:10:55.318+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:55.318+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:10:55.338+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:55.338+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:10:55.339+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:55.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:10:55.339+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:10:55.361+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:10:55.361+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:10:55.362+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:10:55.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.391 seconds
[2024-06-26T08:11:26.006+0000] {processor.py:161} INFO - Started process (PID=1092) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:11:26.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:11:26.010+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:26.009+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:11:26.117+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:26.116+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:11:26.118+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:11:26.120+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:26.120+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:11:26.121+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:26.121+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:11:26.136+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:26.136+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:11:26.298+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:26.298+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:11:26.299+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:26.299+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:11:26.300+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:11:26.313+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:26.312+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:11:26.314+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:11:26.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.350 seconds
[2024-06-26T08:11:56.847+0000] {processor.py:161} INFO - Started process (PID=1104) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:11:56.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:11:56.850+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:56.849+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:11:56.973+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:56.973+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:11:56.974+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:11:56.975+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:56.975+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:11:56.976+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:56.976+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:11:56.991+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:56.991+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:11:57.009+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:57.008+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:11:57.009+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:57.009+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:11:57.010+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:11:57.026+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:11:57.025+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:11:57.026+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:11:57.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.219 seconds
[2024-06-26T08:12:27.218+0000] {processor.py:161} INFO - Started process (PID=1115) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:12:27.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:12:27.221+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:27.220+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:12:27.324+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:27.324+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:12:27.325+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:12:27.327+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:27.326+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:12:27.327+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:27.327+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:12:27.341+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:27.341+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:12:27.359+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:27.358+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:12:27.360+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:27.359+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:12:27.360+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:12:27.378+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:27.378+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:12:27.378+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:12:27.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.363 seconds
[2024-06-26T08:12:57.701+0000] {processor.py:161} INFO - Started process (PID=1127) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:12:57.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:12:57.704+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:57.704+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:12:57.812+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:57.811+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:12:57.813+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:12:57.815+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:57.815+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:12:57.815+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:57.815+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:12:57.830+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:57.829+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:12:57.981+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:57.980+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:12:57.982+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:57.982+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:12:57.982+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:12:57.995+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:12:57.995+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:12:57.996+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:12:58.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.328 seconds
[2024-06-26T08:13:28.610+0000] {processor.py:161} INFO - Started process (PID=1145) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:13:28.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:13:28.613+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:28.613+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:13:28.849+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:28.848+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:13:28.850+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:13:28.851+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:28.851+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:13:28.852+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:28.852+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:13:28.863+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:28.863+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:13:28.879+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:28.879+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:13:28.880+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:28.880+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:13:28.881+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:13:28.894+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:28.893+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:13:28.894+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:13:28.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.321 seconds
[2024-06-26T08:13:59.572+0000] {processor.py:161} INFO - Started process (PID=1157) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:13:59.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:13:59.575+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:59.575+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:13:59.679+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:59.679+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:13:59.680+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:13:59.681+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:59.681+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:13:59.682+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:59.682+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:13:59.695+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:59.695+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:13:59.714+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:59.714+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:13:59.715+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:59.715+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:13:59.716+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:13:59.732+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:13:59.732+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:13:59.733+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:13:59.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.338 seconds
[2024-06-26T08:14:30.537+0000] {processor.py:161} INFO - Started process (PID=1169) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:14:30.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:14:30.540+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:14:30.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:14:30.647+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:14:30.645+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:14:30.648+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:14:30.649+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:14:30.649+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:14:30.650+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:14:30.650+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:14:30.663+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:14:30.663+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:14:30.820+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:14:30.820+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:14:30.821+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:14:30.821+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:14:30.822+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:14:30.836+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:14:30.835+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:14:30.837+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:14:30.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.341 seconds
[2024-06-26T08:15:01.444+0000] {processor.py:161} INFO - Started process (PID=1181) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:15:01.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:15:01.448+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:01.448+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:15:01.698+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:01.697+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:15:01.698+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:15:01.700+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:01.699+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:15:01.700+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:01.700+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:15:01.714+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:01.714+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:15:01.729+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:01.729+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:15:01.730+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:01.730+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:15:01.731+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:15:01.743+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:01.743+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:15:01.744+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:15:01.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.337 seconds
[2024-06-26T08:15:32.442+0000] {processor.py:161} INFO - Started process (PID=1193) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:15:32.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:15:32.445+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:32.445+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:15:32.690+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:32.689+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:15:32.690+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:15:32.692+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:32.691+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:15:32.692+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:32.692+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:15:32.704+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:32.704+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:15:32.720+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:32.719+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:15:32.721+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:32.720+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:15:32.721+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:15:32.735+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:15:32.735+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:15:32.736+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:15:32.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.334 seconds
[2024-06-26T08:16:03.354+0000] {processor.py:161} INFO - Started process (PID=1205) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:16:03.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:16:03.359+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:03.358+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:16:03.470+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:03.470+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:16:03.471+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:16:03.472+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:03.472+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:16:03.473+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:03.473+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:16:03.488+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:03.487+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:16:03.507+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:03.507+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:16:03.508+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:03.508+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:16:03.508+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:16:03.523+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:03.523+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:16:03.524+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:16:03.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.218 seconds
[2024-06-26T08:16:34.527+0000] {processor.py:161} INFO - Started process (PID=1218) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:16:34.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:16:34.530+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:34.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:16:34.645+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:34.644+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:16:34.645+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:16:34.647+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:34.647+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:16:34.648+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:34.648+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:16:34.671+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:34.671+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:16:34.726+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:34.726+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:16:34.727+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:34.727+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:16:34.728+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:16:34.762+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:16:34.762+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:16:34.763+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:16:34.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.285 seconds
[2024-06-26T08:17:05.010+0000] {processor.py:161} INFO - Started process (PID=1230) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:17:05.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:17:05.013+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:05.012+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:17:05.126+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:05.124+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:17:05.127+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:17:05.129+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:05.129+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:17:05.130+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:05.130+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:17:05.151+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:05.150+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:17:05.180+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:05.180+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:17:05.181+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:05.181+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:17:05.182+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:17:05.211+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:05.211+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:17:05.212+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:17:05.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.267 seconds
[2024-06-26T08:17:35.365+0000] {processor.py:161} INFO - Started process (PID=1242) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:17:35.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:17:35.370+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:35.369+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:17:35.479+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:35.478+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:17:35.480+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:17:35.481+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:35.481+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:17:35.482+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:35.482+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:17:35.498+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:35.497+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:17:35.516+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:35.516+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:17:35.517+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:35.517+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:17:35.518+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:17:35.535+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:17:35.534+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:17:35.535+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:17:35.568+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.210 seconds
[2024-06-26T08:18:05.889+0000] {processor.py:161} INFO - Started process (PID=1254) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:18:05.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:18:05.893+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:05.892+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:18:06.001+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:06.000+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:18:06.002+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:18:06.003+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:06.003+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:18:06.004+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:06.004+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:18:06.019+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:06.019+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:18:06.036+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:06.036+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:18:06.037+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:06.037+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:18:06.038+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:18:06.052+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:06.052+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:18:06.053+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:18:06.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.198 seconds
[2024-06-26T08:18:36.348+0000] {processor.py:161} INFO - Started process (PID=1265) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:18:36.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:18:36.351+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:36.351+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:18:36.459+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:36.458+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:18:36.460+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:18:36.461+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:36.461+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:18:36.462+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:36.462+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:18:36.476+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:36.476+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:18:36.494+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:36.494+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:18:36.495+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:36.495+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:18:36.496+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:18:36.510+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:18:36.510+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:18:36.511+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:18:36.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.197 seconds
[2024-06-26T08:19:08.491+0000] {processor.py:161} INFO - Started process (PID=1277) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:19:08.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:19:08.494+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:08.494+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:19:08.600+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:08.600+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:19:08.601+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:19:08.602+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:08.602+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:19:08.603+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:08.603+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:19:08.617+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:08.617+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:19:08.636+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:08.636+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:19:08.637+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:08.637+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:19:08.638+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:19:08.654+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:08.653+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:19:08.654+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:19:08.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.200 seconds
[2024-06-26T08:19:38.973+0000] {processor.py:161} INFO - Started process (PID=1288) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:19:38.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:19:38.976+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:38.975+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:19:39.087+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:39.086+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:19:39.087+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:19:39.089+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:39.089+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:19:39.090+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:39.090+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:19:39.103+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:39.103+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:19:39.122+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:39.121+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:19:39.123+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:39.123+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:19:39.125+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:19:39.144+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:19:39.144+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:19:39.145+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:19:39.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.214 seconds
[2024-06-26T08:20:09.552+0000] {processor.py:161} INFO - Started process (PID=1300) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:20:09.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:20:09.554+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:09.554+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:20:09.695+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:09.694+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:20:09.696+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:20:09.698+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:09.698+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:20:09.699+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:09.699+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:20:09.714+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:09.713+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:20:09.730+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:09.730+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:20:09.731+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:09.731+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:20:09.732+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:20:09.747+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:09.746+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:20:09.747+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:20:09.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.231 seconds
[2024-06-26T08:20:39.849+0000] {processor.py:161} INFO - Started process (PID=1311) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:20:39.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:20:39.852+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:39.852+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:20:39.963+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:39.962+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:20:39.964+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:20:39.966+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:39.965+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:20:39.967+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:39.967+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:20:39.986+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:39.986+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:20:40.007+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:40.006+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:20:40.007+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:40.007+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:20:40.008+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:20:40.030+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:20:40.030+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:20:40.031+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:20:40.058+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.216 seconds
[2024-06-26T08:21:10.174+0000] {processor.py:161} INFO - Started process (PID=1323) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:21:10.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:21:10.177+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:10.177+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:21:10.291+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:10.289+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:21:10.292+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:21:10.293+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:10.293+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:21:10.294+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:10.294+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:21:10.307+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:10.307+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:21:10.325+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:10.324+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:21:10.326+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:10.325+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:21:10.326+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:21:10.341+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:10.341+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:21:10.342+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:21:10.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.204 seconds
[2024-06-26T08:21:40.447+0000] {processor.py:161} INFO - Started process (PID=1335) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:21:40.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:21:40.451+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:40.450+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:21:40.568+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:40.567+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:21:40.568+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:21:40.570+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:40.570+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:21:40.571+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:40.571+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:21:40.585+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:40.585+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:21:40.603+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:40.602+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:21:40.603+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:40.603+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:21:40.604+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:21:40.619+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:21:40.619+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:21:40.620+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:21:40.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.208 seconds
[2024-06-26T08:22:10.834+0000] {processor.py:161} INFO - Started process (PID=1348) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:22:10.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:22:10.838+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:10.837+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:22:10.965+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:10.965+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:22:10.966+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:22:10.968+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:10.967+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:22:10.968+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:10.968+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:22:10.984+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:10.984+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:22:11.002+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:11.002+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:22:11.003+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:11.003+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:22:11.004+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:22:11.022+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:11.022+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:22:11.023+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:22:11.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.224 seconds
[2024-06-26T08:22:41.531+0000] {processor.py:161} INFO - Started process (PID=1360) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:22:41.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:22:41.534+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:41.533+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:22:41.640+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:41.639+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:22:41.641+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:22:41.643+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:41.642+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:22:41.643+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:41.643+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:22:41.657+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:41.657+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:22:41.675+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:41.675+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:22:41.676+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:41.676+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:22:41.677+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:22:41.694+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:22:41.694+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:22:41.695+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:22:41.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.201 seconds
[2024-06-26T08:23:11.824+0000] {processor.py:161} INFO - Started process (PID=1372) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:23:11.825+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:23:11.828+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:11.827+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:23:11.948+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:11.948+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:23:11.949+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:23:11.950+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:11.950+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:23:11.951+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:11.951+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:23:11.965+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:11.965+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:23:11.982+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:11.982+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:23:11.983+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:11.983+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:23:11.984+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:23:11.999+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:11.998+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:23:11.999+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:23:12.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.212 seconds
[2024-06-26T08:23:42.389+0000] {processor.py:161} INFO - Started process (PID=1384) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:23:42.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:23:42.391+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:42.391+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:23:42.499+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:42.498+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:23:42.500+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:23:42.502+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:42.502+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:23:42.503+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:42.502+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:23:42.516+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:42.516+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:23:42.534+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:42.533+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:23:42.535+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:42.534+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:23:42.535+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:23:42.555+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:23:42.554+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:23:42.556+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:23:42.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.206 seconds
[2024-06-26T08:24:13.090+0000] {processor.py:161} INFO - Started process (PID=1396) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:24:13.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:24:13.093+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:13.093+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:24:13.324+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:13.323+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:24:13.325+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:24:13.327+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:13.326+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:24:13.327+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:13.327+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:24:13.342+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:13.341+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:24:13.381+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:13.381+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:24:13.382+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:13.382+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:24:13.383+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:24:13.398+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:13.398+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:24:13.399+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:24:13.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.343 seconds
[2024-06-26T08:24:43.561+0000] {processor.py:161} INFO - Started process (PID=1408) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:24:43.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:24:43.564+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:43.564+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:24:43.678+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:43.678+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:24:43.679+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:24:43.680+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:43.680+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:24:43.681+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:43.681+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:24:43.696+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:43.696+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:24:43.716+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:43.716+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:24:43.717+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:43.717+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:24:43.718+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:24:43.733+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:24:43.732+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:24:43.733+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:24:43.757+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.206 seconds
[2024-06-26T08:25:14.414+0000] {processor.py:161} INFO - Started process (PID=1420) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:25:14.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:25:14.419+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:14.418+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:25:14.579+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:14.578+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:25:14.580+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:25:14.583+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:14.582+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:25:14.584+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:14.583+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:25:14.604+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:14.603+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:25:14.636+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:14.635+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:25:14.637+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:14.636+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:25:14.638+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:25:14.677+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:14.677+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:25:14.678+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:25:14.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.344 seconds
[2024-06-26T08:25:45.269+0000] {processor.py:161} INFO - Started process (PID=1432) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:25:45.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:25:45.273+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:45.272+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:25:45.384+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:45.383+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:25:45.385+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:25:45.387+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:45.387+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:25:45.388+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:45.388+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:25:45.402+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:45.401+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:25:45.423+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:45.422+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:25:45.424+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:45.423+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:25:45.424+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:25:45.443+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:25:45.442+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:25:45.444+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:25:45.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.209 seconds
[2024-06-26T08:26:15.635+0000] {processor.py:161} INFO - Started process (PID=1444) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:26:15.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:26:15.639+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:15.639+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:26:15.832+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:15.831+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:26:15.832+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:26:15.834+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:15.834+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:26:15.834+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:15.834+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:26:15.852+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:15.852+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:26:15.874+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:15.873+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:26:15.876+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:15.875+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:26:15.877+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:26:15.900+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:15.899+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:26:15.900+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:26:15.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.302 seconds
[2024-06-26T08:26:46.210+0000] {processor.py:161} INFO - Started process (PID=1456) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:26:46.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:26:46.213+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:46.213+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:26:46.323+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:46.323+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:26:46.324+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:26:46.326+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:46.326+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:26:46.327+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:46.327+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:26:46.340+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:46.340+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:26:46.358+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:46.358+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:26:46.359+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:46.359+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:26:46.360+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:26:46.377+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:26:46.376+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:26:46.377+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:26:46.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.203 seconds
[2024-06-26T08:27:16.608+0000] {processor.py:161} INFO - Started process (PID=1468) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:27:16.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:27:16.611+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:16.610+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:27:16.716+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:16.714+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:27:16.717+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:27:16.718+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:16.718+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:27:16.719+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:16.719+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:27:16.733+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:16.733+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:27:16.754+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:16.754+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:27:16.755+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:16.755+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:27:16.756+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:27:16.771+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:16.771+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:27:16.772+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:27:16.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.197 seconds
[2024-06-26T08:27:47.251+0000] {processor.py:161} INFO - Started process (PID=1480) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:27:47.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:27:47.254+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:47.254+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:27:47.363+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:47.363+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:27:47.364+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:27:47.366+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:47.365+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:27:47.366+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:47.366+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:27:47.380+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:47.379+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:27:47.398+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:47.397+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:27:47.399+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:47.399+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:27:47.400+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:27:47.414+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:27:47.414+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:27:47.415+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:27:47.447+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.204 seconds
[2024-06-26T08:28:18.106+0000] {processor.py:161} INFO - Started process (PID=1492) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:28:18.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:28:18.109+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:18.109+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:28:18.208+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:18.207+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:28:18.209+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:28:18.210+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:18.210+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:28:18.211+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:18.211+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:28:18.224+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:18.224+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:28:18.242+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:18.242+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:28:18.243+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:18.243+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:28:18.243+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:28:18.258+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:18.258+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:28:18.259+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:28:18.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.190 seconds
[2024-06-26T08:28:48.916+0000] {processor.py:161} INFO - Started process (PID=1504) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:28:48.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:28:48.919+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:48.918+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:28:49.030+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:49.030+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:28:49.031+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:28:49.033+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:49.033+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:28:49.034+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:49.034+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:28:49.048+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:49.047+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:28:49.067+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:49.066+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:28:49.068+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:49.067+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:28:49.068+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:28:49.083+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:28:49.083+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:28:49.084+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:28:49.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.200 seconds
[2024-06-26T08:29:25.723+0000] {processor.py:161} INFO - Started process (PID=1516) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:29:25.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:29:25.726+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:25.725+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:29:25.878+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:25.877+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:29:25.879+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:29:25.880+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:25.880+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:29:25.881+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:25.881+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:29:25.898+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:25.897+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:29:25.922+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:25.921+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:29:25.923+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:25.922+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:29:25.923+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:29:25.955+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:25.955+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:29:25.956+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:29:25.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.264 seconds
[2024-06-26T08:29:56.930+0000] {processor.py:161} INFO - Started process (PID=1529) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:29:56.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:29:56.933+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:56.932+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:29:57.039+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:57.038+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:29:57.039+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:29:57.041+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:57.041+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:29:57.042+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:57.042+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:29:57.060+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:57.059+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:29:57.078+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:57.078+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:29:57.080+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:57.079+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:29:57.080+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:29:57.098+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:29:57.097+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:29:57.098+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:29:57.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.205 seconds
[2024-06-26T08:30:28.601+0000] {processor.py:161} INFO - Started process (PID=1541) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:30:28.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:30:28.604+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:28.604+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:30:28.720+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:28.717+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:30:28.720+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:30:28.722+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:28.721+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:30:28.722+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:28.722+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:30:28.740+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:28.739+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:30:28.778+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:28.778+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:30:28.780+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:28.779+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:30:28.780+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:30:28.808+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:28.808+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:30:28.809+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:30:28.839+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.245 seconds
[2024-06-26T08:30:59.541+0000] {processor.py:161} INFO - Started process (PID=1553) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:30:59.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:30:59.546+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:59.545+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:30:59.658+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:59.657+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:30:59.658+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:30:59.661+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:59.660+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:30:59.662+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:59.662+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:30:59.676+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:59.675+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:30:59.697+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:59.697+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:30:59.698+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:59.698+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:30:59.698+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:30:59.719+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:30:59.719+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:30:59.720+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:30:59.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.215 seconds
[2024-06-26T08:31:30.669+0000] {processor.py:161} INFO - Started process (PID=1566) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:31:30.670+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:31:30.672+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:31:30.671+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:31:30.779+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:31:30.778+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:31:30.780+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:31:30.782+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:31:30.781+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:31:30.783+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:31:30.783+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:31:30.799+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:31:30.798+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:31:30.818+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:31:30.818+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:31:30.819+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:31:30.819+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:31:30.819+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:31:30.842+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:31:30.841+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:31:30.842+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:31:30.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.217 seconds
[2024-06-26T08:32:01.229+0000] {processor.py:161} INFO - Started process (PID=1584) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:32:01.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:32:01.231+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:01.231+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:32:01.382+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:01.380+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:32:01.384+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:32:01.387+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:01.387+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:32:01.388+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:01.388+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:32:01.410+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:01.409+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:32:01.439+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:01.438+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:32:01.439+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:01.439+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:32:01.440+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:32:01.463+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:01.463+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:32:01.464+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:32:01.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.290 seconds
[2024-06-26T08:32:32.098+0000] {processor.py:161} INFO - Started process (PID=1595) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:32:32.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:32:32.102+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:32.101+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:32:32.232+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:32.232+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:32:32.233+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:32:32.235+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:32.234+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:32:32.236+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:32.235+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:32:32.252+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:32.252+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:32:32.275+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:32.274+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:32:32.276+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:32.276+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:32:32.277+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:32:32.294+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:32:32.294+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:32:32.295+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:32:32.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.234 seconds
[2024-06-26T08:33:02.818+0000] {processor.py:161} INFO - Started process (PID=1607) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:33:02.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:33:02.821+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:02.820+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:33:02.954+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:02.953+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:33:02.955+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:33:02.956+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:02.956+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:33:02.957+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:02.957+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:33:02.971+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:02.971+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:33:02.990+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:02.990+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:33:02.991+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:02.991+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:33:02.992+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:33:03.010+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:03.010+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:33:03.011+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:33:03.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.237 seconds
[2024-06-26T08:33:33.869+0000] {processor.py:161} INFO - Started process (PID=1619) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:33:33.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:33:33.872+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:33.871+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:33:33.980+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:33.978+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:33:33.980+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:33:33.982+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:33.982+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:33:33.983+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:33.983+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:33:33.997+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:33.997+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:33:34.016+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:34.016+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:33:34.017+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:34.017+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:33:34.017+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:33:34.034+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:33:34.034+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:33:34.035+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:33:34.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.203 seconds
[2024-06-26T08:34:04.607+0000] {processor.py:161} INFO - Started process (PID=1631) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:34:04.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:34:04.611+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:04.611+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:34:04.748+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:04.747+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:34:04.748+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:34:04.750+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:04.750+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:34:04.751+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:04.751+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:34:04.768+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:04.768+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:34:04.790+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:04.790+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:34:04.791+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:04.791+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:34:04.792+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:34:04.813+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:04.813+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:34:04.814+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:34:04.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.260 seconds
[2024-06-26T08:34:36.459+0000] {processor.py:161} INFO - Started process (PID=1644) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:34:36.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:34:36.463+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:36.462+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:34:36.574+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:36.573+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:34:36.575+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:34:36.577+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:36.576+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:34:36.577+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:36.577+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:34:36.604+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:36.604+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:34:36.622+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:36.622+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:34:36.623+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:36.623+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:34:36.624+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:34:36.641+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:34:36.641+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:34:36.642+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:34:36.674+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.223 seconds
[2024-06-26T08:35:07.569+0000] {processor.py:161} INFO - Started process (PID=1656) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:35:07.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:35:07.572+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:07.571+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:35:07.701+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:07.700+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:35:07.701+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:35:07.702+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:07.702+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:35:07.703+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:07.703+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:35:07.716+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:07.715+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:35:07.733+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:07.733+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:35:07.734+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:07.734+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:35:07.735+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:35:07.750+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:07.750+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:35:07.751+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:35:07.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.235 seconds
[2024-06-26T08:35:38.886+0000] {processor.py:161} INFO - Started process (PID=1668) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:35:38.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:35:38.890+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:38.889+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:35:39.068+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:39.067+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:35:39.069+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:35:39.072+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:39.072+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:35:39.073+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:39.073+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:35:39.092+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:39.092+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:35:39.116+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:39.116+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:35:39.117+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:39.117+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:35:39.117+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:35:39.135+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:35:39.135+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:35:39.136+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:35:39.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.287 seconds
[2024-06-26T08:36:12.723+0000] {processor.py:161} INFO - Started process (PID=1680) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:36:12.746+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:36:12.780+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:12.779+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:36:13.375+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:13.371+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:36:13.381+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:36:13.396+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:13.395+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:36:13.409+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:13.409+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:36:13.461+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:13.460+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:36:13.535+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:13.534+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:36:13.544+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:13.543+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:36:13.545+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:36:13.634+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:13.634+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:36:13.637+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:36:13.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 1.159 seconds
[2024-06-26T08:36:44.107+0000] {processor.py:161} INFO - Started process (PID=1692) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:36:44.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:36:44.114+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:44.112+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:36:44.476+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:44.471+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:36:44.480+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:36:44.485+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:44.485+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:36:44.488+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:44.488+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:36:44.525+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:44.524+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:36:44.583+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:44.582+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:36:44.584+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:44.584+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:36:44.585+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:36:44.643+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:36:44.642+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:36:44.648+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:36:44.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.680 seconds
[2024-06-26T08:37:15.595+0000] {processor.py:161} INFO - Started process (PID=1704) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:37:15.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:37:15.599+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:15.598+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:37:15.727+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:15.726+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:37:15.728+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:37:15.730+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:15.729+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:37:15.731+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:15.730+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:37:15.752+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:15.751+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:37:15.781+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:15.781+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:37:15.783+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:15.782+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:37:15.783+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:37:15.801+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:15.801+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:37:15.802+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:37:15.834+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.248 seconds
[2024-06-26T08:37:46.637+0000] {processor.py:161} INFO - Started process (PID=1716) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:37:46.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:37:46.664+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:46.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:37:47.148+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:47.147+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:37:47.159+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:37:47.162+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:47.161+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:37:47.163+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:47.163+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:37:47.223+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:47.220+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:37:47.338+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:47.338+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:37:47.349+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:47.349+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:37:47.352+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:37:47.495+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:37:47.494+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:37:47.496+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:37:47.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.968 seconds
[2024-06-26T08:38:20.917+0000] {processor.py:161} INFO - Started process (PID=1728) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:38:20.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:38:20.955+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:20.953+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:38:21.447+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:21.446+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:38:21.448+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:38:21.459+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:21.459+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:38:21.464+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:21.464+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:38:21.566+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:21.565+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:38:21.649+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:21.648+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:38:21.651+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:21.650+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:38:21.651+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:38:21.823+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:21.822+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:38:21.824+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:38:21.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 1.039 seconds
[2024-06-26T08:38:52.509+0000] {processor.py:161} INFO - Started process (PID=1738) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:38:52.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:38:52.512+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:52.512+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:38:52.673+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:52.672+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:38:52.673+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:38:52.675+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:52.675+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:38:52.676+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:52.675+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:38:52.696+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:52.696+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:38:52.722+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:52.722+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:38:52.723+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:52.723+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:38:52.723+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:38:52.755+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:38:52.754+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:38:52.755+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:38:52.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.290 seconds
[2024-06-26T08:39:23.153+0000] {processor.py:161} INFO - Started process (PID=1750) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:39:23.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:39:23.158+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:23.158+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:39:23.317+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:23.316+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:39:23.317+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:39:23.319+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:23.319+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:39:23.319+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:23.319+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:39:23.337+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:23.337+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:39:23.364+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:23.363+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:39:23.366+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:23.365+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:39:23.367+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:39:23.389+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:23.388+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:39:23.389+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:39:23.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.287 seconds
[2024-06-26T08:39:53.707+0000] {processor.py:161} INFO - Started process (PID=1762) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:39:53.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:39:53.711+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:53.710+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:39:53.986+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:53.983+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:39:53.987+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:39:53.988+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:53.988+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:39:53.989+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:53.989+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:39:54.005+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:54.004+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:39:54.037+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:54.037+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:39:54.039+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:54.038+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:39:54.040+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:39:54.068+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:39:54.068+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:39:54.070+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:39:54.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.448 seconds
[2024-06-26T08:40:25.268+0000] {processor.py:161} INFO - Started process (PID=1774) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:40:25.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:40:25.279+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:25.278+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:40:25.990+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:25.989+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:40:25.992+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:40:25.996+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:25.995+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:40:25.997+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:25.997+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:40:26.016+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:26.016+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:40:26.040+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:26.040+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:40:26.041+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:26.041+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:40:26.042+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:40:26.069+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:26.069+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:40:26.070+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:40:26.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.896 seconds
[2024-06-26T08:40:56.681+0000] {processor.py:161} INFO - Started process (PID=1786) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:40:56.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:40:56.709+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:56.708+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:40:57.111+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:57.110+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:40:57.113+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:40:57.120+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:57.119+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:40:57.124+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:57.123+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:40:57.303+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:57.302+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:40:57.454+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:57.453+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:40:57.459+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:57.458+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:40:57.460+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:40:58.252+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:40:58.251+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:40:58.256+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:40:58.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 1.824 seconds
[2024-06-26T08:41:29.063+0000] {processor.py:161} INFO - Started process (PID=1798) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:41:29.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:41:29.067+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:41:29.066+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:41:29.253+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:41:29.251+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:41:29.254+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:41:29.256+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:41:29.256+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:41:29.257+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:41:29.256+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:41:29.275+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:41:29.274+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:41:29.301+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:41:29.300+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:41:29.302+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:41:29.301+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:41:29.302+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:41:29.326+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:41:29.325+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:41:29.327+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:41:29.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.316 seconds
[2024-06-26T08:41:59.809+0000] {processor.py:161} INFO - Started process (PID=1810) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:41:59.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:41:59.818+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:41:59.817+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:42:00.443+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:00.430+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:42:00.452+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:42:00.460+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:00.459+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:42:00.471+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:00.470+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:42:00.687+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:00.686+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:42:00.924+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:00.923+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:42:00.926+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:00.925+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:42:00.927+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:42:01.070+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:01.069+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:42:01.071+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:42:01.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 1.467 seconds
[2024-06-26T08:42:32.378+0000] {processor.py:161} INFO - Started process (PID=1822) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:42:32.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:42:32.394+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:32.393+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:42:33.447+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:33.446+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:42:33.460+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:42:33.479+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:33.478+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:42:33.544+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:33.544+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:42:33.723+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:33.715+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:42:33.954+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:33.952+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:42:33.992+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:33.991+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:42:34.007+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:42:34.115+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:42:34.109+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:42:34.177+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:42:34.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 2.173 seconds
[2024-06-26T08:43:04.677+0000] {processor.py:161} INFO - Started process (PID=1834) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:43:04.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:43:04.679+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:04.679+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:43:04.805+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:04.804+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:43:04.805+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:43:04.807+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:04.807+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:43:04.808+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:04.808+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:43:04.828+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:04.827+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:43:04.849+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:04.849+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:43:04.851+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:04.851+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:43:04.852+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:43:04.869+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:04.869+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:43:04.870+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:43:04.910+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.241 seconds
[2024-06-26T08:43:35.391+0000] {processor.py:161} INFO - Started process (PID=1846) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:43:35.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:43:35.404+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:35.403+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:43:35.611+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:35.610+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:43:35.612+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:43:35.616+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:35.615+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:43:35.617+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:35.617+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:43:35.638+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:35.638+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:43:35.661+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:35.661+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:43:35.662+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:35.662+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:43:35.663+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:43:35.684+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:43:35.684+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:43:35.685+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:43:35.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.357 seconds
[2024-06-26T08:44:06.050+0000] {processor.py:161} INFO - Started process (PID=1858) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:44:06.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:44:06.089+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:06.088+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:44:06.240+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:06.239+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:44:06.240+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:44:06.242+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:06.242+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:44:06.243+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:06.242+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:44:06.397+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:06.396+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:44:06.418+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:06.418+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:44:06.419+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:06.419+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:44:06.419+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:44:06.440+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:06.440+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:44:06.441+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:44:06.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.628 seconds
[2024-06-26T08:44:37.680+0000] {processor.py:161} INFO - Started process (PID=1871) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:44:37.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:44:37.684+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:37.683+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:44:37.909+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:37.908+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:44:37.910+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:44:37.912+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:37.912+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:44:37.914+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:37.913+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:44:37.951+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:37.950+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:44:38.049+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:38.048+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:44:38.050+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:38.049+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:44:38.050+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:44:38.085+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:44:38.085+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:44:38.086+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:44:38.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.476 seconds
[2024-06-26T08:45:08.439+0000] {processor.py:161} INFO - Started process (PID=1882) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:45:08.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:45:08.449+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:08.448+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:45:08.922+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:08.921+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:45:08.923+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:45:08.927+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:08.925+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:45:08.928+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:08.928+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:45:08.981+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:08.980+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:45:09.050+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:09.049+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:45:09.052+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:09.051+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:45:09.052+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:45:09.165+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:09.164+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:45:09.166+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:45:09.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.830 seconds
[2024-06-26T08:45:39.886+0000] {processor.py:161} INFO - Started process (PID=1895) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:45:39.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:45:39.889+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:39.888+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:45:39.994+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:39.994+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:45:39.995+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:45:39.997+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:39.996+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:45:39.998+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:39.997+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:45:40.012+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:40.011+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:45:40.030+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:40.029+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:45:40.031+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:40.031+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:45:40.032+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:45:40.051+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:45:40.051+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:45:40.052+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:45:40.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.201 seconds
[2024-06-26T08:46:10.156+0000] {processor.py:161} INFO - Started process (PID=1906) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:46:10.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:46:10.159+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:10.159+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:46:10.268+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:10.267+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:46:10.269+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:46:10.270+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:10.270+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:46:10.271+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:10.271+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:46:10.285+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:10.285+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:46:10.303+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:10.303+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:46:10.304+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:10.304+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:46:10.305+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:46:10.320+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:10.319+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:46:10.321+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:46:10.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.203 seconds
[2024-06-26T08:46:40.477+0000] {processor.py:161} INFO - Started process (PID=1918) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:46:40.479+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:46:40.480+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:40.480+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:46:40.585+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:40.585+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:46:40.586+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:46:40.588+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:40.588+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:46:40.589+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:40.588+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:46:40.603+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:40.603+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:46:40.623+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:40.623+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:46:40.624+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:40.624+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:46:40.625+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:46:40.641+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:46:40.640+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:46:40.642+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:46:40.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.209 seconds
[2024-06-26T08:47:10.866+0000] {processor.py:161} INFO - Started process (PID=1930) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:47:10.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:47:10.884+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:10.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:47:11.234+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:11.230+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:47:11.235+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:47:11.237+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:11.236+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:47:11.238+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:11.237+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:47:11.265+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:11.265+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:47:11.320+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:11.319+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:47:11.322+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:11.321+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:47:11.370+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:47:11.436+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:11.436+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:47:11.466+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:47:11.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.831 seconds
[2024-06-26T08:47:42.223+0000] {processor.py:161} INFO - Started process (PID=1943) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:47:42.225+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:47:42.228+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:42.228+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:47:42.353+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:42.352+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:47:42.354+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:47:42.356+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:42.356+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:47:42.357+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:42.356+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:47:42.371+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:42.371+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:47:42.392+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:42.392+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:47:42.393+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:42.393+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:47:42.394+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:47:42.413+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:47:42.412+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:47:42.414+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:47:42.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.246 seconds
[2024-06-26T08:48:12.984+0000] {processor.py:161} INFO - Started process (PID=1961) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:48:12.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:48:12.986+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:12.986+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:48:13.134+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:13.134+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:48:13.135+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:48:13.136+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:13.136+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:48:13.137+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:13.137+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:48:13.149+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:13.148+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:48:13.168+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:13.167+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:48:13.169+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:13.168+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:48:13.169+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:48:13.190+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:13.190+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:48:13.191+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:48:13.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.252 seconds
[2024-06-26T08:48:43.527+0000] {processor.py:161} INFO - Started process (PID=1973) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:48:43.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:48:43.529+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:43.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:48:43.662+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:43.662+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:48:43.663+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:48:43.665+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:43.665+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:48:43.666+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:43.666+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:48:43.681+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:43.680+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:48:43.702+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:43.702+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:48:43.703+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:43.703+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:48:43.703+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:48:43.721+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:48:43.720+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:48:43.721+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:48:43.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.230 seconds
[2024-06-26T08:49:13.809+0000] {processor.py:161} INFO - Started process (PID=1986) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:49:13.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:49:13.811+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:13.811+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:49:13.919+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:13.918+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:49:13.920+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:49:13.921+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:13.921+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:49:13.922+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:13.922+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:49:13.936+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:13.936+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:49:13.957+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:13.957+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:49:13.959+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:13.958+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:49:13.959+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:49:13.980+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:13.980+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:49:13.981+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:49:14.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.209 seconds
[2024-06-26T08:49:44.160+0000] {processor.py:161} INFO - Started process (PID=1998) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:49:44.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:49:44.167+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:44.167+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:49:44.405+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:44.404+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:49:44.406+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:49:44.408+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:44.408+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:49:44.409+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:44.409+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:49:44.435+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:44.435+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:49:44.470+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:44.470+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:49:44.472+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:44.471+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:49:44.473+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:49:44.504+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:49:44.503+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:49:44.505+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:49:44.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.399 seconds
[2024-06-26T08:50:14.868+0000] {processor.py:161} INFO - Started process (PID=2010) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:50:14.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:50:14.870+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:14.870+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:50:14.990+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:14.990+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:50:14.991+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:50:14.993+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:14.992+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:50:14.993+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:14.993+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:50:15.012+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:15.012+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:50:15.030+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:15.029+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:50:15.031+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:15.030+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:50:15.031+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:50:15.047+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:15.047+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:50:15.048+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:50:15.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.222 seconds
[2024-06-26T08:50:45.931+0000] {processor.py:161} INFO - Started process (PID=2022) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:50:45.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:50:45.934+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:45.933+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:50:46.036+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:46.035+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:50:46.037+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:50:46.038+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:46.038+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:50:46.039+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:46.039+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:50:46.053+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:46.053+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:50:46.070+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:46.070+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:50:46.071+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:46.071+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:50:46.072+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:50:46.087+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:50:46.086+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:50:46.087+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:50:46.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.191 seconds
[2024-06-26T08:51:16.809+0000] {processor.py:161} INFO - Started process (PID=2034) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:51:16.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:51:16.812+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:16.811+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:51:16.915+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:16.914+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:51:16.916+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:51:16.917+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:16.917+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:51:16.918+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:16.917+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:51:16.930+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:16.930+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:51:16.951+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:16.951+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:51:16.952+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:16.952+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:51:16.953+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:51:16.970+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:16.970+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:51:16.971+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:51:17.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.199 seconds
[2024-06-26T08:51:47.171+0000] {processor.py:161} INFO - Started process (PID=2045) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:51:47.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:51:47.174+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:47.173+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:51:47.281+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:47.280+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:51:47.282+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:51:47.284+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:47.284+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:51:47.285+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:47.284+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:51:47.307+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:47.307+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:51:47.325+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:47.325+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:51:47.326+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:47.326+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:51:47.327+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:51:47.342+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:51:47.341+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:51:47.343+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:51:47.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.209 seconds
[2024-06-26T08:52:17.466+0000] {processor.py:161} INFO - Started process (PID=2057) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:52:17.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:52:17.470+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:17.469+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:52:17.591+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:17.591+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:52:17.592+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:52:17.594+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:17.593+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:52:17.594+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:17.594+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:52:17.610+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:17.610+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:52:17.637+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:17.637+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:52:17.638+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:17.638+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:52:17.639+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:52:17.657+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:17.657+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:52:17.658+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:52:17.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.232 seconds
[2024-06-26T08:52:48.035+0000] {processor.py:161} INFO - Started process (PID=2069) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:52:48.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:52:48.038+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:48.038+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:52:48.143+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:48.142+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:52:48.144+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:52:48.145+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:48.145+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:52:48.146+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:48.146+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:52:48.160+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:48.160+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:52:48.178+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:48.178+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:52:48.179+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:48.179+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:52:48.179+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:52:48.196+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:52:48.196+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:52:48.197+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:52:48.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.199 seconds
[2024-06-26T08:53:19.022+0000] {processor.py:161} INFO - Started process (PID=2075) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:53:19.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:53:19.037+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:53:19.033+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:53:19.754+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:53:19.704+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:53:19.755+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:53:19.759+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:53:19.759+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:53:19.760+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:53:19.760+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:53:32.460+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:53:29.952+0000] {before_sleep.py:65} DEBUG - Retrying <unknown> in 0.05620495418270116 seconds as it raised OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8).
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 677, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-26T08:53:33.165+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:53:32.594+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 2 of 3
[2024-06-26T08:53:33.562+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:53:33.505+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:53:45.451+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:53:45.338+0000] {before_sleep.py:65} DEBUG - Retrying <unknown> in 0.6765439820701062 seconds as it raised OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8).
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 677, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-26T08:53:46.165+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:53:46.135+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 3 of 3
[2024-06-26T08:53:46.185+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:53:46.184+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:53:56.271+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 664, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 435, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 368, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 410, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 183, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 677, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-26T08:55:17.039+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:55:17.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:55:17.043+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:17.043+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:55:17.167+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:17.166+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:55:17.168+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:55:17.169+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:17.169+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:55:17.170+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:17.170+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:55:17.183+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:17.183+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:55:17.201+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:17.201+0000] {serialized_dag.py:180} DEBUG - Writing Serialized DAG: selenium to the DB
[2024-06-26T08:55:17.206+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:17.206+0000] {serialized_dag.py:182} DEBUG - DAG: selenium written to the DB
[2024-06-26T08:55:17.207+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:17.207+0000] {dagbag.py:701} DEBUG - Syncing DAG permissions: selenium to the DB
[2024-06-26T08:55:17.298+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:17.297+0000] {override.py:1090} DEBUG - Not syncing DAG-level permissions for DAG 'DAG:selenium' as access control is unset.
[2024-06-26T08:55:17.299+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:17.299+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:55:17.300+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:55:17.313+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:17.313+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:55:17.314+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:55:17.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.316 seconds
[2024-06-26T08:55:48.434+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:55:48.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:55:48.439+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:48.438+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:55:48.566+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:48.566+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:55:48.567+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:55:48.569+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:48.569+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:55:48.570+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:48.570+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:55:48.585+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:48.585+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:55:48.606+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:48.606+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:55:48.607+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:48.607+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:55:48.607+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:55:48.623+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:55:48.623+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:55:48.624+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:55:48.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.234 seconds
[2024-06-26T08:56:19.414+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:56:19.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:56:19.418+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:56:19.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:56:19.579+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:56:19.579+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:56:19.580+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:56:19.582+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:56:19.581+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:56:19.582+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:56:19.582+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:56:19.599+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:56:19.599+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:56:19.637+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:56:19.636+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:56:19.638+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:56:19.637+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:56:19.638+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:56:19.664+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:56:19.664+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:56:19.665+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:56:19.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.304 seconds
[2024-06-26T08:57:58.782+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:57:58.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:57:58.787+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:57:58.786+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:57:58.932+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:57:58.931+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:57:58.932+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:57:58.934+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:57:58.934+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:57:58.934+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:57:58.934+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:57:58.949+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:57:58.949+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:57:58.969+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:57:58.969+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:57:58.970+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:57:58.970+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:57:58.971+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:57:58.991+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:57:58.991+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:57:58.992+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:57:59.023+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.252 seconds
[2024-06-26T08:58:30.073+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:58:30.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:58:30.077+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:58:30.077+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:58:30.212+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:58:30.211+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:58:30.212+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:58:30.214+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:58:30.214+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:58:30.215+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:58:30.215+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:58:30.231+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:58:30.230+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:58:30.255+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:58:30.255+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:58:30.257+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:58:30.256+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:58:30.257+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:58:30.288+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:58:30.288+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:58:30.289+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:58:30.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.273 seconds
[2024-06-26T08:59:01.604+0000] {processor.py:161} INFO - Started process (PID=82) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:59:01.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:59:01.609+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:01.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:59:01.725+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:01.724+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:59:01.725+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:59:01.727+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:01.727+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:59:01.728+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:01.728+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:59:01.744+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:01.743+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:59:01.763+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:01.762+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:59:01.764+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:01.763+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:59:01.764+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:59:01.780+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:01.780+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:59:01.781+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:59:01.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.216 seconds
[2024-06-26T08:59:32.817+0000] {processor.py:161} INFO - Started process (PID=94) to work on /opt/airflow/dags/crawl.py
[2024-06-26T08:59:32.818+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T08:59:32.822+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:32.821+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T08:59:32.929+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:32.929+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T08:59:32.930+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T08:59:32.932+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:32.932+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T08:59:32.932+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:32.932+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T08:59:32.946+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:32.946+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T08:59:32.963+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:32.963+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T08:59:32.964+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:32.964+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T08:59:32.965+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T08:59:32.981+0000] {logging_mixin.py:188} INFO - [2024-06-26T08:59:32.981+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:59:32.982+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T08:59:33.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.200 seconds
[2024-06-26T09:00:03.879+0000] {processor.py:161} INFO - Started process (PID=106) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:00:03.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:00:03.883+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:03.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:00:03.993+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:03.993+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:00:03.994+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:00:03.995+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:03.995+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:00:03.996+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:03.996+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:00:04.010+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:04.010+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:00:04.033+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:04.033+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:00:04.034+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:04.034+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:00:04.034+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:00:04.052+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:04.051+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:00:04.052+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:00:04.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.211 seconds
[2024-06-26T09:00:35.374+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:00:35.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:00:35.384+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:35.383+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:00:35.494+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:35.493+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:00:35.495+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:00:35.496+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:35.496+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:00:35.497+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:35.497+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:00:35.511+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:35.510+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:00:35.529+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:35.528+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:00:35.530+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:35.529+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:00:35.530+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:00:35.547+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:00:35.546+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:00:35.547+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:00:35.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.213 seconds
[2024-06-26T09:01:06.363+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:01:06.365+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:01:06.370+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:06.369+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:01:06.481+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:06.480+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:01:06.482+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:01:06.483+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:06.483+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:01:06.484+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:06.484+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:01:06.499+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:06.499+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:01:06.519+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:06.519+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:01:06.520+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:06.520+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:01:06.521+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:01:06.540+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:06.540+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:01:06.541+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:01:06.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.221 seconds
[2024-06-26T09:01:37.503+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:01:37.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:01:37.507+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:37.506+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:01:37.620+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:37.619+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:01:37.621+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:01:37.622+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:37.622+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:01:37.623+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:37.623+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:01:37.638+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:37.638+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:01:37.659+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:37.658+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:01:37.660+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:37.659+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:01:37.660+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:01:37.677+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:01:37.677+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:01:37.678+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:01:37.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.209 seconds
[2024-06-26T09:02:09.562+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:02:09.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:02:09.568+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:09.567+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:02:09.690+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:09.689+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:02:09.691+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:02:09.693+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:09.693+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:02:09.694+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:09.693+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:02:09.708+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:09.707+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:02:09.726+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:09.725+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:02:09.727+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:09.726+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:02:09.727+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:02:09.744+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:09.743+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:02:09.744+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:02:09.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.218 seconds
[2024-06-26T09:02:41.461+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:02:41.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:02:41.467+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:41.466+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:02:41.626+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:41.624+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:02:41.627+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:02:41.629+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:41.629+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:02:41.631+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:41.630+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:02:41.654+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:41.654+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:02:41.678+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:41.678+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:02:41.679+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:41.679+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:02:41.680+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:02:41.711+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:02:41.710+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:02:41.711+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:02:41.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.294 seconds
[2024-06-26T09:03:12.311+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:03:12.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:03:12.315+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:12.314+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:03:12.432+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:12.430+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:03:12.433+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:03:12.435+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:12.435+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:03:12.436+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:12.436+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:03:12.449+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:12.449+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:03:12.468+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:12.467+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:03:12.469+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:12.468+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:03:12.469+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:03:12.485+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:12.484+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:03:12.485+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:03:12.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.211 seconds
[2024-06-26T09:03:43.911+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:03:43.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:03:43.918+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:43.917+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:03:44.107+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:44.106+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:03:44.108+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:03:44.110+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:44.109+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:03:44.111+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:44.110+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:03:44.139+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:44.138+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:03:44.168+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:44.167+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:03:44.168+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:44.168+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:03:44.169+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:03:44.194+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:03:44.194+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:03:44.195+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:03:44.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.323 seconds
[2024-06-26T09:04:59.452+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:04:59.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:04:59.459+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:04:59.455+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:05:00.017+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:00.000+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:05:00.019+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:05:00.022+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:00.021+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:05:00.023+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:00.023+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:05:00.562+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:00.562+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:05:00.688+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:00.687+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:05:00.689+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:00.688+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:05:00.689+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:05:00.724+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:00.723+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:05:00.726+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:05:00.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 1.382 seconds
[2024-06-26T09:05:33.470+0000] {processor.py:161} INFO - Started process (PID=52) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:05:33.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:05:33.474+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:33.474+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:05:33.582+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:33.582+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:05:33.583+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:05:33.585+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:33.585+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:05:33.586+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:33.585+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:05:33.600+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:33.600+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:05:33.619+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:33.618+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:05:33.620+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:33.619+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:05:33.620+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:05:33.635+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:05:33.635+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:05:33.636+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:05:33.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.204 seconds
[2024-06-26T09:06:04.672+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:06:04.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:06:04.678+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:04.677+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:06:04.815+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:04.814+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:06:04.815+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:06:04.817+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:04.817+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:06:04.817+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:04.817+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:06:04.834+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:04.833+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:06:04.853+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:04.853+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:06:04.854+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:04.854+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:06:04.855+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:06:04.870+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:04.870+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:06:04.871+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:06:04.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.237 seconds
[2024-06-26T09:06:36.165+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:06:36.166+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:06:36.170+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:36.170+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:06:36.309+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:36.308+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:06:36.311+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:06:36.313+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:36.313+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:06:36.314+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:36.314+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:06:36.332+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:36.332+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:06:36.352+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:36.352+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:06:36.353+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:36.353+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:06:36.354+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:06:36.373+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:06:36.372+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:06:36.373+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:06:36.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.247 seconds
[2024-06-26T09:07:07.494+0000] {processor.py:161} INFO - Started process (PID=95) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:07:07.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:07:07.502+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:07.501+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:07:07.628+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:07.627+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:07:07.629+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:07:07.631+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:07.631+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:07:07.632+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:07.632+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:07:07.648+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:07.647+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:07:07.669+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:07.669+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:07:07.670+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:07.670+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:07:07.670+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:07:07.687+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:07.687+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:07:07.688+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:07:07.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.246 seconds
[2024-06-26T09:07:38.769+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:07:38.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:07:38.772+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:38.772+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:07:38.883+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:38.883+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:07:38.884+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:07:38.886+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:38.885+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:07:38.887+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:38.886+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:07:38.901+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:38.901+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:07:38.922+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:38.922+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:07:38.923+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:38.923+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:07:38.924+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:07:38.943+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:07:38.943+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:07:38.944+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:07:38.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.213 seconds
[2024-06-26T09:09:22.562+0000] {processor.py:161} INFO - Started process (PID=114) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:09:22.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:09:22.575+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:09:22.569+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:09:27.284+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:09:27.233+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:09:27.372+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:09:28.912+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:09:27.793+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:09:29.369+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:09:29.362+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:09:49.402+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:09:41.625+0000] {before_sleep.py:65} DEBUG - Retrying <unknown> in 0.1791282918764548 seconds as it raised OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8).
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 677, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-26T09:09:51.798+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:09:49.727+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 2 of 3
[2024-06-26T09:09:52.370+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:09:51.839+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:10:04.640+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:10:04.272+0000] {before_sleep.py:65} DEBUG - Retrying <unknown> in 0.744174524317661 seconds as it raised OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8).
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 677, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-26T09:10:05.460+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:10:05.417+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 3 of 3
[2024-06-26T09:10:05.463+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:10:05.463+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:10:15.809+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 664, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 435, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 368, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 410, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 183, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 677, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-26T09:14:00.558+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:14:00.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:14:00.563+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:00.562+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:14:00.684+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:00.684+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:14:00.685+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:14:00.686+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:00.686+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:14:00.687+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:00.687+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:14:00.700+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:00.700+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:14:00.729+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:00.729+0000] {serialized_dag.py:180} DEBUG - Writing Serialized DAG: selenium to the DB
[2024-06-26T09:14:00.738+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:00.737+0000] {serialized_dag.py:182} DEBUG - DAG: selenium written to the DB
[2024-06-26T09:14:00.739+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:00.738+0000] {dagbag.py:701} DEBUG - Syncing DAG permissions: selenium to the DB
[2024-06-26T09:14:00.977+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:00.976+0000] {override.py:1090} DEBUG - Not syncing DAG-level permissions for DAG 'DAG:selenium' as access control is unset.
[2024-06-26T09:14:00.977+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:00.977+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:14:00.978+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:14:00.995+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:00.995+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:14:00.996+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:14:01.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.479 seconds
[2024-06-26T09:14:31.493+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:14:31.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:14:31.498+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:31.497+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:14:31.628+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:31.627+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:14:31.629+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:14:31.631+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:31.631+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:14:31.632+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:31.631+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:14:31.646+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:31.645+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:14:31.666+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:31.666+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:14:31.667+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:31.667+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:14:31.667+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:14:31.688+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:14:31.687+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:14:31.689+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:14:31.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.248 seconds
[2024-06-26T09:15:03.054+0000] {processor.py:161} INFO - Started process (PID=82) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:15:03.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:15:03.058+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:15:03.058+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:15:03.178+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:15:03.178+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:15:03.179+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:15:03.180+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:15:03.180+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:15:03.181+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:15:03.181+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:15:03.194+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:15:03.194+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:15:03.217+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:15:03.217+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:15:03.218+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:15:03.218+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:15:03.219+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:15:03.241+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:15:03.240+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:15:03.241+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:15:03.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.243 seconds
[2024-06-26T09:19:02.998+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:19:03.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:19:03.029+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:03.017+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:19:03.973+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:03.957+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:19:03.974+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:19:03.977+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:03.977+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:19:03.979+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:03.978+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:19:05.516+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:05.502+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:19:05.630+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:05.629+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:19:05.631+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:05.631+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:19:05.632+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:19:05.682+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:05.682+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:19:05.684+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:19:05.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 2.916 seconds
[2024-06-26T09:19:36.462+0000] {processor.py:161} INFO - Started process (PID=100) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:19:36.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:19:36.465+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:36.464+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:19:36.612+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:36.611+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:19:36.612+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:19:36.614+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:36.614+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:19:36.615+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:36.614+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:19:36.632+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:36.631+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:19:36.652+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:36.652+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:19:36.653+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:36.653+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:19:36.654+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:19:36.669+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:19:36.669+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:19:36.670+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:19:36.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.250 seconds
[2024-06-26T09:20:07.679+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:20:07.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:20:07.682+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:07.682+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:20:07.816+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:07.816+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:20:07.817+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:20:07.819+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:07.818+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:20:07.819+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:07.819+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:20:07.835+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:07.835+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:20:07.863+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:07.862+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:20:07.863+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:07.863+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:20:07.864+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:20:07.880+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:07.880+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:20:07.881+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:20:07.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.238 seconds
[2024-06-26T09:20:38.750+0000] {processor.py:161} INFO - Started process (PID=124) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:20:38.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:20:38.753+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:38.752+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:20:38.889+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:38.888+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:20:38.890+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:20:38.893+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:38.893+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:20:38.894+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:38.894+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:20:38.911+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:38.910+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:20:38.930+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:38.930+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:20:38.932+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:38.931+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:20:38.932+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:20:38.952+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:20:38.952+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:20:38.953+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:20:38.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.241 seconds
[2024-06-26T09:21:10.012+0000] {processor.py:161} INFO - Started process (PID=136) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:21:10.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:21:10.016+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:10.015+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:21:10.146+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:10.146+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:21:10.148+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:21:10.151+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:10.150+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:21:10.152+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:10.152+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:21:10.168+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:10.167+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:21:10.188+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:10.188+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:21:10.189+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:10.189+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:21:10.190+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:21:10.208+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:10.208+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:21:10.209+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:21:10.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.235 seconds
[2024-06-26T09:21:41.076+0000] {processor.py:161} INFO - Started process (PID=148) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:21:41.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:21:41.078+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:41.078+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:21:41.213+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:41.212+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:21:41.214+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:21:41.215+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:41.215+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:21:41.217+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:41.216+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:21:41.235+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:41.234+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:21:41.256+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:41.255+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:21:41.256+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:41.256+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:21:41.257+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:21:41.277+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:21:41.276+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:21:41.277+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:21:41.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.238 seconds
[2024-06-26T09:22:12.214+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:22:12.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:22:12.218+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:12.217+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:22:12.341+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:12.340+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:22:12.341+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:22:12.343+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:12.343+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:22:12.343+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:12.343+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:22:12.361+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:12.360+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:22:12.380+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:12.380+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:22:12.381+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:12.381+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:22:12.382+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:22:12.398+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:12.398+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:22:12.399+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:22:12.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.230 seconds
[2024-06-26T09:22:43.365+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:22:43.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:22:43.367+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:43.367+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:22:43.601+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:43.599+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:22:43.602+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:22:43.610+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:43.610+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:22:43.619+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:43.619+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:22:43.658+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:43.658+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:22:43.694+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:43.693+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:22:43.695+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:43.694+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:22:43.695+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:22:43.713+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:22:43.713+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:22:43.714+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:22:43.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.390 seconds
[2024-06-26T09:23:14.252+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:23:14.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:23:14.262+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:14.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:23:14.775+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:14.771+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:23:14.777+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:23:14.784+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:14.783+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:23:14.787+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:14.786+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:23:14.862+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:14.860+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:23:14.908+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:14.907+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:23:14.910+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:14.909+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:23:14.911+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:23:14.951+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:14.950+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:23:14.952+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:23:15.004+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.783 seconds
[2024-06-26T09:23:45.921+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:23:45.923+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:23:45.926+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:45.925+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:23:46.277+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:46.273+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:23:46.281+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:23:46.286+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:46.285+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:23:46.287+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:46.287+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:23:46.365+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:46.357+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:23:46.538+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:46.537+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:23:46.540+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:46.540+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:23:46.547+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:23:46.706+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:23:46.706+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:23:46.708+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:23:46.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.887 seconds
[2024-06-26T09:24:18.510+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:24:18.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:24:18.518+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:18.517+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:24:18.886+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:18.884+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:24:18.888+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:24:18.892+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:18.891+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:24:18.894+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:18.894+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:24:18.936+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:18.935+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:24:18.991+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:18.991+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:24:18.995+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:18.994+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:24:18.997+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:24:19.047+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:19.047+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:24:19.049+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:24:19.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.649 seconds
[2024-06-26T09:24:50.402+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:24:50.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:24:50.409+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:50.408+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:24:50.710+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:50.707+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:24:50.713+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:24:50.718+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:50.717+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:24:50.722+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:50.721+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:24:50.792+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:50.791+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:24:50.882+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:50.880+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:24:50.885+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:50.885+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:24:50.887+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:24:50.934+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:24:50.934+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:24:50.935+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:24:51.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.642 seconds
[2024-06-26T09:25:21.820+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:25:21.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:25:21.826+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:21.825+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:25:22.110+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:22.109+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:25:22.112+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:25:22.117+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:22.116+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:25:22.119+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:22.119+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:25:22.159+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:22.158+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:25:22.214+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:22.214+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:25:22.217+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:22.216+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:25:22.219+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:25:22.263+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:22.262+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:25:22.265+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:25:22.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.553 seconds
[2024-06-26T09:25:52.899+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:25:52.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:25:52.903+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:52.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:25:53.063+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:53.062+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:25:53.064+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:25:53.066+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:53.065+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:25:53.067+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:53.067+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:25:53.088+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:53.087+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:25:53.117+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:53.116+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:25:53.118+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:53.118+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:25:53.119+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:25:53.158+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:25:53.157+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:25:53.159+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:25:53.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.365 seconds
[2024-06-26T09:26:23.929+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:26:23.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:26:23.932+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:23.932+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:26:24.101+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:24.100+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:26:24.102+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:26:24.104+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:24.103+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:26:24.105+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:24.104+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:26:24.124+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:24.124+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:26:24.152+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:24.152+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:26:24.154+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:24.153+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:26:24.155+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:26:24.177+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:24.177+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:26:24.178+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:26:24.226+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.309 seconds
[2024-06-26T09:26:55.856+0000] {processor.py:161} INFO - Started process (PID=268) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:26:55.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:26:55.863+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:55.862+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:26:56.071+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:56.070+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:26:56.072+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:26:56.074+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:56.073+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:26:56.075+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:56.074+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:26:56.094+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:56.094+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:26:56.125+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:56.124+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:26:56.126+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:56.126+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:26:56.127+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:26:56.153+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:26:56.152+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:26:56.154+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:26:56.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.394 seconds
[2024-06-26T09:27:26.706+0000] {processor.py:161} INFO - Started process (PID=280) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:27:26.708+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:27:26.710+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:26.709+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:27:26.936+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:26.934+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:27:26.938+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:27:26.945+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:26.944+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:27:26.948+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:26.947+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:27:27.010+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:27.007+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:27:27.092+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:27.091+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:27:27.096+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:27.095+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:27:27.098+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:27:27.157+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:27.156+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:27:27.159+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:27:27.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.562 seconds
[2024-06-26T09:27:57.426+0000] {processor.py:161} INFO - Started process (PID=291) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:27:57.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:27:57.432+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:57.431+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:27:57.687+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:57.686+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:27:57.688+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:27:57.691+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:57.691+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:27:57.692+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:57.692+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:27:57.716+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:57.716+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:27:57.753+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:57.752+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:27:57.754+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:57.754+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:27:57.755+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:27:57.785+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:27:57.785+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:27:57.787+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:27:57.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.429 seconds
[2024-06-26T09:28:28.733+0000] {processor.py:161} INFO - Started process (PID=303) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:28:28.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:28:28.737+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:28.736+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:28:28.926+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:28.924+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:28:28.927+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:28:28.930+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:28.930+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:28:28.933+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:28.932+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:28:28.963+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:28.962+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:28:29.005+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:29.004+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:28:29.007+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:29.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:28:29.008+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:28:29.044+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:29.044+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:28:29.046+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:28:29.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.382 seconds
[2024-06-26T09:28:59.654+0000] {processor.py:161} INFO - Started process (PID=315) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:28:59.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:28:59.658+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:59.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:28:59.866+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:59.865+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:28:59.867+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:28:59.871+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:59.870+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:28:59.872+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:59.872+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:28:59.902+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:59.901+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:28:59.944+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:59.943+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:28:59.946+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:28:59.945+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:28:59.948+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:29:00.018+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:29:00.017+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:29:00.021+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:29:00.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.492 seconds
[2024-06-26T09:29:30.474+0000] {processor.py:161} INFO - Started process (PID=327) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:29:30.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:29:30.478+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:29:30.477+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:29:30.633+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:29:30.633+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:29:30.634+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:29:30.636+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:29:30.636+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:29:30.637+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:29:30.637+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:29:30.658+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:29:30.657+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:29:30.694+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:29:30.693+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:29:30.695+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:29:30.694+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:29:30.695+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:29:30.717+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:29:30.717+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:29:30.718+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:29:30.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.288 seconds
[2024-06-26T09:30:01.646+0000] {processor.py:161} INFO - Started process (PID=339) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:30:01.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:30:01.650+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:01.649+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:30:01.845+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:01.844+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:30:01.846+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:30:01.848+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:01.848+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:30:01.849+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:01.849+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:30:01.868+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:01.868+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:30:01.896+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:01.896+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:30:01.897+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:01.897+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:30:01.898+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:30:01.921+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:01.920+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:30:01.922+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:30:01.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.326 seconds
[2024-06-26T09:30:32.224+0000] {processor.py:161} INFO - Started process (PID=350) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:30:32.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:30:32.235+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:32.233+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:30:32.549+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:32.548+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:30:32.550+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:30:32.554+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:32.554+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:30:32.556+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:32.556+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:30:32.599+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:32.598+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:30:32.652+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:32.649+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:30:32.654+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:32.653+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:30:32.655+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:30:32.682+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:30:32.682+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:30:32.683+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:30:32.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.530 seconds
[2024-06-26T09:31:02.963+0000] {processor.py:161} INFO - Started process (PID=361) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:31:02.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:31:02.974+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:02.972+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:31:03.314+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:03.312+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:31:03.315+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:31:03.319+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:03.318+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:31:03.321+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:03.320+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:31:03.353+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:03.353+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:31:03.398+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:03.397+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:31:03.400+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:03.399+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:31:03.401+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:31:03.450+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:03.449+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:31:03.452+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:31:03.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.612 seconds
[2024-06-26T09:31:34.730+0000] {processor.py:161} INFO - Started process (PID=374) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:31:34.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:31:34.742+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:34.741+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:31:35.009+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:35.008+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:31:35.010+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:31:35.012+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:35.012+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:31:35.013+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:35.013+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:31:35.037+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:35.037+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:31:35.061+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:35.061+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:31:35.062+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:35.062+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:31:35.063+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:31:35.086+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:31:35.086+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:31:35.087+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:31:35.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.421 seconds
[2024-06-26T09:32:06.128+0000] {processor.py:161} INFO - Started process (PID=386) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:32:06.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:32:06.148+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:06.147+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:32:06.336+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:06.335+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:32:06.337+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:32:06.339+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:06.339+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:32:06.341+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:06.340+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:32:06.365+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:06.365+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:32:06.391+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:06.390+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:32:06.392+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:06.392+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:32:06.393+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:32:06.422+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:06.422+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:32:06.423+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:32:06.466+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.362 seconds
[2024-06-26T09:32:36.593+0000] {processor.py:161} INFO - Started process (PID=397) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:32:36.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:32:36.596+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:36.595+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:32:36.730+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:36.729+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:32:36.730+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:32:36.732+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:36.732+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:32:36.732+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:36.732+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:32:36.748+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:36.748+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:32:36.768+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:36.768+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:32:36.769+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:36.769+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:32:36.770+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:32:36.786+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:32:36.785+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:32:36.786+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:32:36.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.228 seconds
[2024-06-26T09:33:07.282+0000] {processor.py:161} INFO - Started process (PID=410) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:33:07.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:33:07.285+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:07.284+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:33:07.413+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:07.412+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:33:07.414+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:33:07.416+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:07.415+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:33:07.417+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:07.416+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:33:07.431+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:07.431+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:33:07.450+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:07.450+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:33:07.451+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:07.451+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:33:07.452+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:33:07.473+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:07.473+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:33:07.473+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:33:07.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.245 seconds
[2024-06-26T09:33:37.888+0000] {processor.py:161} INFO - Started process (PID=422) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:33:37.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:33:37.891+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:37.890+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:33:38.011+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:38.010+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:33:38.013+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:33:38.016+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:38.016+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:33:38.017+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:38.017+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:33:38.036+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:38.036+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:33:38.060+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:38.060+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:33:38.062+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:38.061+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:33:38.064+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:33:38.089+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:33:38.089+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:33:38.090+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:33:38.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.243 seconds
[2024-06-26T09:34:08.972+0000] {processor.py:161} INFO - Started process (PID=434) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:34:08.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:34:08.974+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:08.974+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:34:09.088+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:09.087+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:34:09.088+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:34:09.090+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:09.090+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:34:09.091+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:09.091+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:34:09.115+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:09.115+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:34:09.144+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:09.143+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:34:09.145+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:09.145+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:34:09.146+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:34:09.168+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:09.168+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:34:09.169+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:34:09.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.245 seconds
[2024-06-26T09:34:39.535+0000] {processor.py:161} INFO - Started process (PID=446) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:34:39.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:34:39.538+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:39.538+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:34:39.665+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:39.665+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:34:39.666+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:34:39.668+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:39.668+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:34:39.669+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:39.669+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:34:39.684+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:39.684+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:34:39.703+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:39.702+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:34:39.704+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:39.703+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:34:39.704+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:34:39.722+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:34:39.722+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:34:39.723+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:34:39.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.228 seconds
[2024-06-26T09:35:10.102+0000] {processor.py:161} INFO - Started process (PID=464) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:35:10.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:35:10.104+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:10.104+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:35:10.220+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:10.220+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:35:10.229+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:35:10.231+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:10.231+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:35:10.244+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:10.244+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:35:10.267+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:10.267+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:35:10.286+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:10.286+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:35:10.287+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:10.287+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:35:10.288+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:35:10.307+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:10.306+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:35:10.307+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:35:10.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.246 seconds
[2024-06-26T09:35:40.703+0000] {processor.py:161} INFO - Started process (PID=476) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:35:40.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:35:40.706+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:40.705+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:35:40.812+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:40.811+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:35:40.813+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:35:40.815+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:40.814+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:35:40.815+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:40.815+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:35:40.830+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:40.829+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:35:40.848+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:40.847+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:35:40.849+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:40.848+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:35:40.849+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:35:40.864+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:35:40.864+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:35:40.865+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:35:40.893+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.197 seconds
[2024-06-26T09:36:11.111+0000] {processor.py:161} INFO - Started process (PID=488) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:36:11.112+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:36:11.114+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:11.113+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:36:11.215+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:11.215+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:36:11.216+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:36:11.217+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:11.217+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:36:11.218+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:11.218+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:36:11.232+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:11.232+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:36:11.250+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:11.250+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:36:11.251+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:11.251+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:36:11.252+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:36:11.273+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:11.272+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:36:11.273+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:36:11.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.198 seconds
[2024-06-26T09:36:41.415+0000] {processor.py:161} INFO - Started process (PID=499) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:36:41.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:36:41.418+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:41.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:36:41.537+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:41.536+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:36:41.538+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:36:41.539+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:41.539+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:36:41.540+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:41.540+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:36:41.554+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:41.554+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:36:41.575+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:41.574+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:36:41.576+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:41.575+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:36:41.576+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:36:41.593+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:36:41.592+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:36:41.593+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:36:41.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.215 seconds
[2024-06-26T09:37:11.934+0000] {processor.py:161} INFO - Started process (PID=511) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:37:11.935+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:37:11.937+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:11.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:37:12.047+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:12.046+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:37:12.047+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:37:12.050+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:12.049+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:37:12.051+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:12.050+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:37:12.068+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:12.068+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:37:12.089+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:12.089+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:37:12.090+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:12.089+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:37:12.090+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:37:12.106+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:12.106+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:37:12.107+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:37:12.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.207 seconds
[2024-06-26T09:37:43.231+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:37:43.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:37:43.233+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:43.233+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:37:43.347+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:43.346+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:37:43.348+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:37:43.350+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:43.349+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:37:43.350+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:43.350+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:37:43.365+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:43.365+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:37:43.384+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:43.383+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:37:43.385+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:43.385+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:37:43.386+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:37:43.403+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:37:43.403+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:37:43.403+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:37:43.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.219 seconds
[2024-06-26T09:38:13.677+0000] {processor.py:161} INFO - Started process (PID=536) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:38:13.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:38:13.679+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:13.679+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:38:13.783+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:13.782+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:38:13.784+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:38:13.785+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:13.785+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:38:13.786+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:13.786+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:38:13.800+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:13.800+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:38:13.818+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:13.817+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:38:13.819+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:13.818+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:38:13.819+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:38:13.835+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:13.834+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:38:13.835+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:38:13.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.194 seconds
[2024-06-26T09:38:44.190+0000] {processor.py:161} INFO - Started process (PID=547) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:38:44.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:38:44.192+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:44.192+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:38:44.306+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:44.305+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:38:44.307+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:38:44.309+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:44.308+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:38:44.310+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:44.310+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:38:44.324+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:44.324+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:38:44.342+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:44.341+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:38:44.343+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:44.342+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:38:44.343+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:38:44.360+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:38:44.359+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:38:44.360+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:38:44.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.208 seconds
[2024-06-26T09:39:14.714+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:39:14.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:39:14.719+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:14.718+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:39:14.836+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:14.835+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:39:14.836+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:39:14.839+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:14.838+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:39:14.839+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:14.839+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:39:14.855+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:14.855+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:39:14.873+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:14.873+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:39:14.874+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:14.874+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:39:14.875+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:39:14.891+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:14.890+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:39:14.891+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:39:14.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.220 seconds
[2024-06-26T09:39:45.734+0000] {processor.py:161} INFO - Started process (PID=571) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:39:45.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:39:45.737+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:45.736+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:39:45.853+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:45.852+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:39:45.854+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:39:45.855+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:45.855+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:39:45.856+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:45.856+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:39:45.869+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:45.869+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:39:45.886+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:45.885+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:39:45.886+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:45.886+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:39:45.887+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:39:45.902+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:39:45.902+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:39:45.903+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:39:45.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.209 seconds
[2024-06-26T09:40:16.308+0000] {processor.py:161} INFO - Started process (PID=583) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:40:16.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:40:16.310+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:16.310+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:40:16.420+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:16.419+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:40:16.420+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:40:16.422+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:16.422+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:40:16.423+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:16.423+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:40:16.441+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:16.440+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:40:16.471+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:16.471+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:40:16.472+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:16.472+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:40:16.473+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:40:16.491+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:16.491+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:40:16.492+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:40:16.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.220 seconds
[2024-06-26T09:40:47.281+0000] {processor.py:161} INFO - Started process (PID=595) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:40:47.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:40:47.284+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:47.284+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:40:47.416+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:47.415+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:40:47.417+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:40:47.420+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:47.419+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:40:47.421+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:47.420+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:40:47.438+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:47.437+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:40:47.461+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:47.461+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:40:47.462+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:47.461+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:40:47.462+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:40:47.479+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:40:47.478+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:40:47.479+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:40:47.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.242 seconds
[2024-06-26T09:41:17.883+0000] {processor.py:161} INFO - Started process (PID=607) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:41:17.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:41:17.885+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:17.885+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:41:17.987+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:17.986+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:41:17.987+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:41:17.989+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:17.989+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:41:17.990+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:17.990+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:41:18.005+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:18.004+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:41:18.023+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:18.022+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:41:18.023+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:18.023+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:41:18.024+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:41:18.041+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:18.040+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:41:18.041+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:41:18.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.195 seconds
[2024-06-26T09:41:48.474+0000] {processor.py:161} INFO - Started process (PID=619) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:41:48.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:41:48.477+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:48.477+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:41:48.578+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:48.578+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:41:48.579+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:41:48.581+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:48.580+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:41:48.581+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:48.581+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:41:48.609+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:48.609+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:41:48.627+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:48.627+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:41:48.628+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:48.628+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:41:48.629+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:41:48.647+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:41:48.647+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:41:48.647+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:41:48.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.213 seconds
[2024-06-26T09:42:18.808+0000] {processor.py:161} INFO - Started process (PID=630) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:42:18.812+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:42:18.814+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:18.813+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:42:19.042+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:19.040+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:42:19.043+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:42:19.050+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:19.050+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:42:19.052+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:19.051+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:42:19.068+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:19.068+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:42:19.097+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:19.097+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:42:19.098+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:19.098+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:42:19.099+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:42:19.123+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:19.122+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:42:19.123+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:42:19.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.356 seconds
[2024-06-26T09:42:49.209+0000] {processor.py:161} INFO - Started process (PID=642) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:42:49.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:42:49.212+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:49.211+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:42:49.306+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:49.305+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:42:49.307+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:42:49.309+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:49.308+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:42:49.310+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:49.309+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:42:49.323+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:49.323+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:42:49.341+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:49.341+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:42:49.342+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:49.342+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:42:49.343+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:42:49.359+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:42:49.358+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:42:49.359+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:42:49.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.187 seconds
[2024-06-26T09:43:19.599+0000] {processor.py:161} INFO - Started process (PID=654) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:43:19.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:43:19.604+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:19.603+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:43:19.760+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:19.760+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:43:19.761+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:43:19.765+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:19.763+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:43:19.766+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:19.766+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:43:19.787+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:19.787+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:43:19.810+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:19.810+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:43:19.811+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:19.811+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:43:19.812+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:43:19.832+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:19.832+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:43:19.833+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:43:19.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.274 seconds
[2024-06-26T09:43:49.940+0000] {processor.py:161} INFO - Started process (PID=666) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:43:49.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:43:49.942+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:49.942+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:43:50.064+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:50.063+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:43:50.065+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:43:50.067+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:50.067+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:43:50.068+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:50.067+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:43:50.081+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:50.080+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:43:50.098+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:50.097+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:43:50.099+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:50.099+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:43:50.099+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:43:50.114+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:43:50.114+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:43:50.115+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:43:50.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.218 seconds
[2024-06-26T09:44:20.527+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:44:20.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:44:20.529+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:20.529+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:44:20.683+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:20.682+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:44:20.684+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:44:20.686+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:20.686+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:44:20.687+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:20.687+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:44:20.704+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:20.703+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:44:20.726+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:20.726+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:44:20.727+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:20.727+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:44:20.728+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:44:20.746+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:20.746+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:44:20.746+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:44:20.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.265 seconds
[2024-06-26T09:44:50.978+0000] {processor.py:161} INFO - Started process (PID=690) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:44:50.979+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:44:50.981+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:50.980+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:44:51.082+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:51.081+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:44:51.083+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:44:51.084+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:51.084+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:44:51.085+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:51.085+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:44:51.099+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:51.098+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:44:51.116+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:51.115+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:44:51.116+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:51.116+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:44:51.117+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:44:51.134+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:44:51.133+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:44:51.134+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:44:51.164+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.194 seconds
[2024-06-26T09:45:21.683+0000] {processor.py:161} INFO - Started process (PID=702) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:45:21.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:45:21.686+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:21.686+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:45:21.801+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:21.800+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:45:21.802+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:45:21.803+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:21.803+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:45:21.804+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:21.804+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:45:21.819+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:21.819+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:45:21.838+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:21.838+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:45:21.839+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:21.839+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:45:21.840+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:45:21.856+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:21.855+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:45:21.856+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:45:21.893+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.217 seconds
[2024-06-26T09:45:52.154+0000] {processor.py:161} INFO - Started process (PID=714) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:45:52.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:45:52.157+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:52.156+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:45:52.283+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:52.283+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:45:52.284+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:45:52.286+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:52.286+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:45:52.287+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:52.286+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:45:52.302+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:52.302+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:45:52.322+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:52.321+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:45:52.323+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:52.322+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:45:52.323+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:45:52.340+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:45:52.340+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:45:52.341+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:45:52.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.227 seconds
[2024-06-26T09:46:22.691+0000] {processor.py:161} INFO - Started process (PID=726) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:46:22.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:46:22.694+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:22.694+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:46:22.804+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:22.804+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:46:22.805+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:46:22.807+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:22.806+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:46:22.807+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:22.807+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:46:22.822+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:22.821+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:46:22.839+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:22.839+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:46:22.840+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:22.840+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:46:22.841+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:46:22.858+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:22.857+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:46:22.858+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:46:22.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.211 seconds
[2024-06-26T09:46:53.647+0000] {processor.py:161} INFO - Started process (PID=738) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:46:53.649+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:46:53.650+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:53.650+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:46:53.762+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:53.761+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:46:53.762+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:46:53.763+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:53.763+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:46:53.764+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:53.764+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:46:53.777+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:53.776+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:46:53.794+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:53.794+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:46:53.795+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:53.795+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:46:53.796+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:46:53.811+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:46:53.810+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:46:53.811+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:46:53.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.207 seconds
[2024-06-26T09:47:24.569+0000] {processor.py:161} INFO - Started process (PID=750) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:47:24.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:47:24.572+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:24.572+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:47:24.685+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:24.684+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:47:24.686+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:47:24.689+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:24.688+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:47:24.690+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:24.689+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:47:24.707+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:24.707+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:47:24.728+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:24.728+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:47:24.729+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:24.729+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:47:24.730+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:47:24.748+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:24.748+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:47:24.749+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:47:24.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.228 seconds
[2024-06-26T09:47:55.599+0000] {processor.py:161} INFO - Started process (PID=762) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:47:55.600+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:47:55.601+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:55.601+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:47:55.712+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:55.712+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:47:55.713+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:47:55.715+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:55.714+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:47:55.715+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:55.715+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:47:55.730+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:55.729+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:47:55.748+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:55.747+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:47:55.748+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:55.748+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:47:55.749+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:47:55.767+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:47:55.767+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:47:55.768+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:47:55.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.216 seconds
[2024-06-26T09:48:26.553+0000] {processor.py:161} INFO - Started process (PID=774) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:48:26.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:48:26.556+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:26.556+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:48:26.674+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:26.673+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:48:26.675+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:48:26.677+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:26.677+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:48:26.678+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:26.678+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:48:26.694+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:26.694+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:48:26.714+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:26.714+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:48:26.715+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:26.715+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:48:26.715+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:48:26.733+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:26.732+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:48:26.733+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:48:26.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.226 seconds
[2024-06-26T09:48:57.552+0000] {processor.py:161} INFO - Started process (PID=786) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:48:57.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:48:57.555+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:57.555+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:48:57.685+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:57.685+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:48:57.686+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:48:57.688+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:57.687+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:48:57.688+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:57.688+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:48:57.705+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:57.705+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:48:57.730+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:57.729+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:48:57.731+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:57.731+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:48:57.731+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:48:57.750+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:48:57.750+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:48:57.751+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:48:57.795+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.253 seconds
[2024-06-26T09:49:27.905+0000] {processor.py:161} INFO - Started process (PID=798) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:49:27.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:49:27.908+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:27.908+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:49:28.021+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:28.020+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:49:28.021+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:49:28.023+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:28.023+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:49:28.024+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:28.024+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:49:28.038+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:28.038+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:49:28.058+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:28.057+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:49:28.059+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:28.058+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:49:28.059+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:49:28.074+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:28.074+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:49:28.075+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:49:28.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.218 seconds
[2024-06-26T09:49:58.384+0000] {processor.py:161} INFO - Started process (PID=810) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:49:58.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:49:58.387+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:58.386+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:49:58.509+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:58.508+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:49:58.510+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:49:58.511+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:58.511+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:49:58.512+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:58.512+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:49:58.526+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:58.525+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:49:58.543+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:58.543+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:49:58.544+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:58.544+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:49:58.545+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:49:58.562+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:49:58.562+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:49:58.563+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:49:58.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.238 seconds
[2024-06-26T09:50:28.719+0000] {processor.py:161} INFO - Started process (PID=821) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:50:28.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:50:28.723+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:28.722+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:50:28.829+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:28.828+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:50:28.829+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:50:28.831+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:28.830+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:50:28.831+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:28.831+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:50:28.846+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:28.845+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:50:28.866+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:28.866+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:50:28.867+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:28.867+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:50:28.869+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:50:28.886+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:28.886+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:50:28.887+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:50:28.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.232 seconds
[2024-06-26T09:50:59.699+0000] {processor.py:161} INFO - Started process (PID=833) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:50:59.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:50:59.703+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:59.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:50:59.810+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:59.809+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:50:59.811+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:50:59.812+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:59.812+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:50:59.813+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:59.813+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:50:59.826+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:59.826+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:50:59.845+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:59.844+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:50:59.846+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:59.845+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:50:59.846+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:50:59.861+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:50:59.861+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:50:59.862+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:50:59.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.200 seconds
[2024-06-26T09:51:30.651+0000] {processor.py:161} INFO - Started process (PID=845) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:51:30.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:51:30.655+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:51:30.655+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:51:30.827+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:51:30.825+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:51:30.835+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:51:30.837+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:51:30.837+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:51:30.839+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:51:30.838+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:51:30.866+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:51:30.865+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:51:30.934+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:51:30.934+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:51:30.935+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:51:30.935+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:51:30.955+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:51:30.997+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:51:30.996+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:51:31.010+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:51:31.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.470 seconds
[2024-06-26T09:52:01.549+0000] {processor.py:161} INFO - Started process (PID=857) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:52:01.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:52:01.552+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:01.552+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:52:01.674+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:01.673+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:52:01.675+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:52:01.676+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:01.676+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:52:01.679+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:01.678+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:52:01.696+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:01.696+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:52:01.717+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:01.716+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:52:01.717+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:01.717+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:52:01.718+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:52:01.738+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:01.738+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:52:01.739+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:52:01.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.237 seconds
[2024-06-26T09:52:32.248+0000] {processor.py:161} INFO - Started process (PID=869) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:52:32.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:52:32.251+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:32.250+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:52:32.356+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:32.355+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:52:32.357+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:52:32.359+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:32.358+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:52:32.359+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:32.359+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:52:32.378+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:32.377+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:52:32.396+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:32.396+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:52:32.397+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:32.397+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:52:32.398+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:52:32.413+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:52:32.413+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:52:32.414+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:52:32.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.202 seconds
[2024-06-26T09:53:02.618+0000] {processor.py:161} INFO - Started process (PID=881) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:53:02.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:53:02.621+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:02.621+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:53:02.750+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:02.749+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:53:02.751+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:53:02.752+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:02.752+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:53:02.753+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:02.753+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:53:02.768+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:02.768+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:53:02.786+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:02.786+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:53:02.787+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:02.787+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:53:02.788+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:53:02.808+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:02.808+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:53:02.809+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:53:02.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.228 seconds
[2024-06-26T09:53:33.431+0000] {processor.py:161} INFO - Started process (PID=893) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:53:33.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:53:33.434+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:33.434+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:53:33.601+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:33.600+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:53:33.602+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:53:33.604+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:33.604+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:53:33.606+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:33.605+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:53:33.623+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:33.622+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:53:33.645+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:33.645+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:53:33.647+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:33.646+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:53:33.650+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:53:33.674+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:53:33.673+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:53:33.675+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:53:33.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.295 seconds
[2024-06-26T09:54:04.549+0000] {processor.py:161} INFO - Started process (PID=905) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:54:04.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:54:04.553+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:04.552+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:54:04.674+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:04.674+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:54:04.675+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:54:04.676+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:04.676+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:54:04.677+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:04.677+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:54:04.693+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:04.692+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:54:04.713+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:04.713+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:54:04.714+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:04.714+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:54:04.715+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:54:04.890+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:04.889+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:54:04.891+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:54:04.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.380 seconds
[2024-06-26T09:54:35.018+0000] {processor.py:161} INFO - Started process (PID=917) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:54:35.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:54:35.023+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:35.022+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:54:35.136+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:35.136+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:54:35.138+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:54:35.140+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:35.140+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:54:35.141+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:35.141+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:54:35.155+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:35.155+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:54:35.175+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:35.174+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:54:35.175+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:35.175+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:54:35.176+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:54:35.193+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:54:35.193+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:54:35.194+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:54:35.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.215 seconds
[2024-06-26T09:55:05.425+0000] {processor.py:161} INFO - Started process (PID=929) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:55:05.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:55:05.429+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:05.428+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:55:05.604+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:05.603+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:55:05.604+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:55:05.606+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:05.606+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:55:05.608+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:05.607+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:55:05.623+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:05.622+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:55:05.645+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:05.645+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:55:05.646+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:05.646+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:55:05.647+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:55:05.665+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:05.664+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:55:05.665+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:55:05.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.277 seconds
[2024-06-26T09:55:35.994+0000] {processor.py:161} INFO - Started process (PID=940) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:55:36.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:55:36.004+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:36.004+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:55:36.154+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:36.153+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:55:36.155+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:55:36.157+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:36.156+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:55:36.158+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:36.157+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:55:36.175+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:36.175+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:55:36.203+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:36.203+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:55:36.204+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:36.203+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:55:36.204+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:55:36.470+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:55:36.469+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:55:36.471+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:55:36.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.560 seconds
[2024-06-26T09:56:06.671+0000] {processor.py:161} INFO - Started process (PID=952) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:56:06.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:56:06.674+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:06.674+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:56:06.946+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:06.793+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:56:06.947+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:56:06.949+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:06.949+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:56:06.950+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:06.950+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:56:06.963+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:06.962+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:56:06.979+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:06.979+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:56:06.980+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:06.980+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:56:06.981+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:56:06.994+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:06.994+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:56:06.995+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:56:07.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.359 seconds
[2024-06-26T09:56:37.613+0000] {processor.py:161} INFO - Started process (PID=964) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:56:37.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:56:37.617+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:37.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:56:37.733+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:37.733+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:56:37.734+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:56:37.736+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:37.735+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:56:37.736+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:37.736+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:56:37.750+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:37.750+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:56:37.767+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:37.767+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:56:37.768+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:37.768+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:56:37.769+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:56:37.784+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:56:37.784+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:56:37.785+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:56:37.814+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.207 seconds
[2024-06-26T09:57:08.149+0000] {processor.py:161} INFO - Started process (PID=976) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:57:08.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:57:08.153+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:08.152+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:57:08.282+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:08.281+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:57:08.283+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:57:08.285+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:08.285+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:57:08.286+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:08.286+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:57:08.301+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:08.301+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:57:08.320+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:08.319+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:57:08.321+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:08.320+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:57:08.321+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:57:08.521+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:08.521+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:57:08.535+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:57:08.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.429 seconds
[2024-06-26T09:57:38.993+0000] {processor.py:161} INFO - Started process (PID=988) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:57:38.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:57:38.996+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:38.996+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:57:39.250+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:39.094+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:57:39.251+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:57:39.252+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:39.252+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:57:39.253+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:39.253+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:57:39.266+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:39.266+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:57:39.282+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:39.282+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:57:39.283+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:39.283+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:57:39.284+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:57:39.297+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:57:39.296+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:57:39.297+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:57:39.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.343 seconds
[2024-06-26T09:58:09.742+0000] {processor.py:161} INFO - Started process (PID=1000) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:58:09.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:58:09.745+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:09.745+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:58:09.857+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:09.857+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:58:09.858+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:58:09.860+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:09.859+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:58:09.860+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:09.860+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:58:09.875+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:09.875+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:58:09.893+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:09.893+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:58:09.894+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:09.894+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:58:09.895+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:58:09.912+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:09.911+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:58:09.913+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:58:09.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.207 seconds
[2024-06-26T09:58:40.216+0000] {processor.py:161} INFO - Started process (PID=1012) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:58:40.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:58:40.220+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:40.219+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:58:40.346+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:40.344+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:58:40.347+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:58:40.348+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:40.348+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:58:40.349+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:40.349+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:58:40.364+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:40.363+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:58:40.382+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:40.382+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:58:40.383+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:40.383+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:58:40.384+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:58:40.543+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:58:40.543+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:58:40.544+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:58:40.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.364 seconds
[2024-06-26T09:59:10.773+0000] {processor.py:161} INFO - Started process (PID=1024) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:59:10.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:59:10.776+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:10.775+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:59:11.040+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:10.895+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:59:11.041+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:59:11.043+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:11.042+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:59:11.044+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:11.043+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:59:11.057+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:11.057+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:59:11.074+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:11.073+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:59:11.075+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:11.074+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:59:11.075+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:59:11.089+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:11.089+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:59:11.090+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:59:11.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.350 seconds
[2024-06-26T09:59:41.607+0000] {processor.py:161} INFO - Started process (PID=1036) to work on /opt/airflow/dags/crawl.py
[2024-06-26T09:59:41.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T09:59:41.610+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:41.609+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T09:59:41.871+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:41.870+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T09:59:41.871+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T09:59:41.873+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:41.872+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T09:59:41.873+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:41.873+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T09:59:41.887+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:41.887+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T09:59:41.907+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:41.907+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T09:59:41.908+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:41.908+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T09:59:41.909+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T09:59:41.923+0000] {logging_mixin.py:188} INFO - [2024-06-26T09:59:41.923+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:59:41.924+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T09:59:41.952+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.353 seconds
[2024-06-26T10:00:12.442+0000] {processor.py:161} INFO - Started process (PID=1048) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:00:12.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:00:12.445+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:12.444+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:00:12.561+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:12.561+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:00:12.562+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:00:12.563+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:12.563+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:00:12.564+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:12.564+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:00:12.580+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:12.579+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:00:12.602+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:12.602+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:00:12.603+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:12.603+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:00:12.604+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:00:12.794+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:12.793+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:00:12.794+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:00:12.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.391 seconds
[2024-06-26T10:00:42.952+0000] {processor.py:161} INFO - Started process (PID=1066) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:00:42.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:00:42.955+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:42.955+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:00:43.215+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:43.067+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:00:43.216+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:00:43.218+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:43.218+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:00:43.219+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:43.219+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:00:43.235+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:43.234+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:00:43.255+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:43.254+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:00:43.256+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:43.255+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:00:43.256+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:00:43.273+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:00:43.273+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:00:43.274+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:00:43.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.361 seconds
[2024-06-26T10:02:40.340+0000] {processor.py:161} INFO - Started process (PID=63) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:02:40.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:02:40.358+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:02:40.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:02:41.479+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:02:41.477+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:02:41.481+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:02:41.487+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:02:41.487+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:02:41.489+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:02:41.488+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:02:41.632+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:02:41.632+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:02:41.668+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:02:41.667+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:02:41.669+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:02:41.669+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:02:41.670+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:02:41.700+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:02:41.700+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:02:41.701+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:02:41.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 1.418 seconds
[2024-06-26T10:03:13.476+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:03:13.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:03:13.482+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:13.481+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:03:13.598+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:13.598+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:03:13.599+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:03:13.601+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:13.601+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:03:13.602+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:13.602+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:03:13.620+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:13.619+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:03:13.651+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:13.650+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:03:13.652+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:13.652+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:03:13.654+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:03:13.687+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:13.687+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:03:13.688+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:03:13.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.266 seconds
[2024-06-26T10:03:44.348+0000] {processor.py:161} INFO - Started process (PID=87) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:03:44.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:03:44.352+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:44.352+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:03:44.462+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:44.461+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:03:44.462+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:03:44.464+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:44.464+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:03:44.465+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:44.464+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:03:44.479+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:44.479+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:03:44.498+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:44.498+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:03:44.499+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:44.499+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:03:44.500+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:03:44.516+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:03:44.515+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:03:44.516+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:03:44.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.210 seconds
[2024-06-26T10:04:15.380+0000] {processor.py:161} INFO - Started process (PID=99) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:04:15.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:04:15.385+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:15.385+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:04:15.501+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:15.501+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:04:15.502+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:04:15.504+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:15.503+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:04:15.504+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:15.504+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:04:15.520+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:15.520+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:04:15.541+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:15.540+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:04:15.542+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:15.541+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:04:15.542+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:04:15.559+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:15.559+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:04:15.560+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:04:15.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.216 seconds
[2024-06-26T10:04:46.924+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:04:46.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:04:46.929+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:46.929+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:04:47.048+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:47.047+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:04:47.049+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:04:47.050+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:47.050+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:04:47.051+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:47.051+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:04:47.066+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:47.065+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:04:47.084+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:47.084+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:04:47.085+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:47.085+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:04:47.086+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:04:47.102+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:04:47.101+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:04:47.102+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:04:47.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.218 seconds
[2024-06-26T10:05:18.000+0000] {processor.py:161} INFO - Started process (PID=123) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:05:18.003+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:05:18.005+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:18.005+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:05:18.122+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:18.121+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:05:18.123+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:05:18.125+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:18.124+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:05:18.126+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:18.125+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:05:18.142+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:18.142+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:05:18.163+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:18.163+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:05:18.164+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:18.164+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:05:18.165+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:05:18.181+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:18.181+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:05:18.182+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:05:18.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.214 seconds
[2024-06-26T10:05:49.707+0000] {processor.py:161} INFO - Started process (PID=135) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:05:49.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:05:49.713+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:49.712+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:05:49.859+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:49.859+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:05:49.860+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:05:49.862+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:49.861+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:05:49.862+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:49.862+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:05:49.879+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:49.878+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:05:49.907+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:49.907+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:05:49.908+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:49.908+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:05:49.909+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:05:49.935+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:05:49.935+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:05:49.936+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:05:49.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.285 seconds
[2024-06-26T10:06:20.344+0000] {processor.py:161} INFO - Started process (PID=147) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:06:20.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:06:20.348+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:20.347+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:06:20.445+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:20.445+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:06:20.446+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:06:20.447+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:20.447+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:06:20.448+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:20.448+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:06:20.462+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:20.461+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:06:20.479+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:20.479+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:06:20.480+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:20.480+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:06:20.481+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:06:20.497+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:20.497+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:06:20.498+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:06:20.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.189 seconds
[2024-06-26T10:06:53.711+0000] {processor.py:161} INFO - Started process (PID=159) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:06:53.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:06:53.715+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:53.715+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:06:53.855+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:53.854+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:06:53.856+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:06:53.857+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:53.857+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:06:53.858+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:53.858+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:06:53.872+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:53.872+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:06:53.889+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:53.889+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:06:53.890+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:53.890+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:06:53.891+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:06:53.906+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:06:53.906+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:06:53.907+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:06:53.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.236 seconds
[2024-06-26T10:07:25.580+0000] {processor.py:161} INFO - Started process (PID=171) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:07:25.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:07:25.584+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:25.584+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:07:25.728+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:25.727+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:07:25.728+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:07:25.730+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:25.730+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:07:25.731+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:25.730+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:07:25.753+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:25.753+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:07:25.783+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:25.783+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:07:25.784+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:25.784+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:07:25.785+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:07:25.810+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:25.810+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:07:25.811+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:07:25.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.341 seconds
[2024-06-26T10:07:56.538+0000] {processor.py:161} INFO - Started process (PID=183) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:07:56.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:07:56.542+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:56.542+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:07:56.642+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:56.641+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:07:56.642+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:07:56.644+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:56.644+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:07:56.645+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:56.644+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:07:56.659+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:56.659+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:07:56.677+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:56.677+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:07:56.678+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:56.678+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:07:56.679+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:07:56.694+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:07:56.694+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:07:56.695+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:07:56.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.195 seconds
[2024-06-26T10:08:27.020+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:08:27.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:08:27.024+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:27.023+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:08:27.133+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:27.132+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:08:27.133+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:08:27.135+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:27.135+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:08:27.136+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:27.135+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:08:27.155+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:27.155+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:08:27.235+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:27.235+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:08:27.237+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:27.236+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:08:27.237+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:08:27.300+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:27.299+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:08:27.301+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:08:27.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.344 seconds
[2024-06-26T10:08:58.066+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:08:58.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:08:58.071+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:58.070+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:08:58.175+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:58.174+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:08:58.176+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:08:58.178+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:58.178+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:08:58.179+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:58.179+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:08:58.192+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:58.192+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:08:58.211+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:58.211+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:08:58.212+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:58.211+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:08:58.212+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:08:58.227+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:08:58.227+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:08:58.228+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:08:58.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.204 seconds
[2024-06-26T10:09:28.959+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:09:28.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:09:28.963+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:28.962+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:09:29.063+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:29.062+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:09:29.064+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:09:29.065+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:29.065+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:09:29.066+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:29.066+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:09:29.079+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:29.079+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:09:29.097+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:29.096+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:09:29.098+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:29.097+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:09:29.098+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:09:29.113+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:29.113+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:09:29.114+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:09:29.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.191 seconds
[2024-06-26T10:09:59.621+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:09:59.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:09:59.625+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:59.624+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:09:59.737+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:59.737+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:09:59.738+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:09:59.740+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:59.739+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:09:59.740+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:59.740+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:09:59.755+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:59.754+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:09:59.771+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:59.771+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:09:59.772+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:59.772+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:09:59.773+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:09:59.790+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:09:59.789+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:09:59.790+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:09:59.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.206 seconds
[2024-06-26T10:10:30.348+0000] {processor.py:161} INFO - Started process (PID=248) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:10:30.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:10:30.352+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:10:30.352+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:10:30.465+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:10:30.463+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:10:30.466+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:10:30.467+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:10:30.467+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:10:30.468+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:10:30.467+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:10:30.480+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:10:30.480+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:10:30.498+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:10:30.498+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:10:30.499+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:10:30.499+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:10:30.500+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:10:30.517+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:10:30.517+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:10:30.518+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:10:30.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.208 seconds
[2024-06-26T10:11:00.861+0000] {processor.py:161} INFO - Started process (PID=260) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:11:00.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:11:00.865+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:00.864+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:11:00.969+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:00.969+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:11:00.970+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:11:00.972+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:00.972+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:11:00.973+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:00.973+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:11:00.987+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:00.987+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:11:01.004+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:01.004+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:11:01.006+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:01.005+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:11:01.006+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:11:01.022+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:01.021+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:11:01.022+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:11:01.050+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.196 seconds
[2024-06-26T10:11:31.390+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:11:31.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:11:31.394+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:31.394+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:11:31.506+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:31.505+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:11:31.506+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:11:31.508+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:31.508+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:11:31.509+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:31.508+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:11:31.523+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:31.523+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:11:31.541+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:31.540+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:11:31.542+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:31.541+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:11:31.542+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:11:31.562+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:11:31.562+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:11:31.563+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:11:31.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.211 seconds
[2024-06-26T10:12:02.329+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:12:02.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:12:02.333+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:02.333+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:12:02.439+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:02.437+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:12:02.439+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:12:02.441+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:02.441+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:12:02.442+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:02.441+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:12:02.456+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:02.456+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:12:02.477+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:02.477+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:12:02.478+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:02.478+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:12:02.479+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:12:02.495+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:02.494+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:12:02.495+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:12:02.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.204 seconds
[2024-06-26T10:12:33.259+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:12:33.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:12:33.263+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:33.263+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:12:33.384+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:33.384+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:12:33.385+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:12:33.387+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:33.387+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:12:33.388+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:33.388+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:12:33.402+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:33.402+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:12:33.424+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:33.423+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:12:33.425+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:33.424+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:12:33.425+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:12:33.441+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:12:33.441+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:12:33.442+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:12:33.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.221 seconds
[2024-06-26T10:13:03.941+0000] {processor.py:161} INFO - Started process (PID=308) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:13:03.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:13:03.945+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:03.944+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:13:04.049+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:04.048+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:13:04.050+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:13:04.051+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:04.051+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:13:04.052+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:04.051+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:13:04.065+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:04.065+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:13:04.083+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:04.083+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:13:04.084+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:04.084+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:13:04.085+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:13:04.104+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:04.104+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:13:04.105+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:13:04.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.201 seconds
[2024-06-26T10:13:34.463+0000] {processor.py:161} INFO - Started process (PID=320) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:13:34.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:13:34.466+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:34.466+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:13:34.598+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:34.597+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:13:34.599+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:13:34.601+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:34.600+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:13:34.601+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:34.601+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:13:34.617+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:34.616+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:13:34.635+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:34.635+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:13:34.636+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:34.636+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:13:34.636+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:13:34.652+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:13:34.652+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:13:34.652+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:13:34.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.229 seconds
[2024-06-26T10:14:05.579+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:14:05.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:14:05.583+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:05.583+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:14:05.710+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:05.709+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:14:05.711+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:14:05.713+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:05.712+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:14:05.714+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:05.713+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:14:05.729+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:05.729+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:14:05.748+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:05.747+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:14:05.748+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:05.748+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:14:05.749+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:14:05.765+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:05.765+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:14:05.766+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:14:05.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.223 seconds
[2024-06-26T10:14:36.704+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:14:36.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:14:36.707+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:36.707+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:14:36.818+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:36.817+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:14:36.818+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:14:36.820+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:36.820+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:14:36.821+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:36.821+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:14:36.840+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:36.839+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:14:36.861+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:36.861+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:14:36.862+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:36.862+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:14:36.862+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:14:36.881+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:14:36.880+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:14:36.881+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:14:36.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.217 seconds
[2024-06-26T10:15:07.167+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:15:07.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:15:07.170+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:07.170+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:15:07.274+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:07.272+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:15:07.274+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:15:07.276+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:07.276+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:15:07.277+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:07.277+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:15:07.291+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:07.291+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:15:07.310+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:07.309+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:15:07.310+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:07.310+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:15:07.311+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:15:07.328+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:07.327+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:15:07.328+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:15:07.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.197 seconds
[2024-06-26T10:15:38.262+0000] {processor.py:161} INFO - Started process (PID=368) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:15:38.263+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:15:38.265+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:38.265+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:15:38.371+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:38.370+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:15:38.372+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:15:38.374+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:38.374+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:15:38.375+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:38.375+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:15:38.391+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:38.391+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:15:38.409+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:38.409+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:15:38.410+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:38.410+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:15:38.411+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:15:38.427+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:15:38.427+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:15:38.428+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:15:38.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.202 seconds
[2024-06-26T10:16:09.412+0000] {processor.py:161} INFO - Started process (PID=380) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:16:09.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:16:09.416+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:09.415+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:16:09.520+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:09.520+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:16:09.521+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:16:09.523+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:09.522+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:16:09.523+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:09.523+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:16:09.537+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:09.537+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:16:09.554+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:09.554+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:16:09.555+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:09.555+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:16:09.556+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:16:09.572+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:09.572+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:16:09.573+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:16:09.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.194 seconds
[2024-06-26T10:16:40.464+0000] {processor.py:161} INFO - Started process (PID=392) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:16:40.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:16:40.469+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:40.468+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:16:40.589+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:40.587+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:16:40.590+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:16:40.592+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:40.591+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:16:40.592+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:40.592+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:16:40.607+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:40.606+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:16:40.624+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:40.623+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:16:40.625+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:40.625+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:16:40.625+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:16:40.641+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:16:40.640+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:16:40.641+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:16:40.666+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.211 seconds
[2024-06-26T10:17:11.221+0000] {processor.py:161} INFO - Started process (PID=404) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:17:11.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:17:11.224+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:11.224+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:17:11.340+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:11.339+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:17:11.341+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:17:11.343+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:11.343+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:17:11.344+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:11.344+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:17:11.363+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:11.361+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:17:11.382+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:11.381+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:17:11.382+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:11.382+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:17:11.383+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:17:11.400+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:11.400+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:17:11.401+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:17:11.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.216 seconds
[2024-06-26T10:17:42.202+0000] {processor.py:161} INFO - Started process (PID=416) to work on /opt/airflow/dags/crawl.py
[2024-06-26T10:17:42.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-26T10:17:42.206+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:42.205+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-26T10:17:42.316+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:42.316+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-26T10:17:42.317+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-26T10:17:42.319+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:42.319+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-26T10:17:42.320+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:42.319+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-26T10:17:42.334+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:42.334+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-26T10:17:42.352+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:42.352+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-26T10:17:42.353+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:42.353+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-26T10:17:42.354+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-26T10:17:42.370+0000] {logging_mixin.py:188} INFO - [2024-06-26T10:17:42.370+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:17:42.371+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-26T10:17:42.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.206 seconds
