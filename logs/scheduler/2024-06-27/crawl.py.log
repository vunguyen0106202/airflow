[2024-06-27T01:49:38.725+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:49:38.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:49:38.730+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:49:38.730+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:49:38.888+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:49:38.887+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:49:38.889+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:49:38.891+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:49:38.891+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:49:38.892+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:49:38.892+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:49:38.910+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:49:38.909+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:49:38.953+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:49:38.953+0000] {serialized_dag.py:180} DEBUG - Writing Serialized DAG: selenium to the DB
[2024-06-27T01:49:38.962+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:49:38.961+0000] {serialized_dag.py:182} DEBUG - DAG: selenium written to the DB
[2024-06-27T01:49:38.963+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:49:38.962+0000] {dagbag.py:701} DEBUG - Syncing DAG permissions: selenium to the DB
[2024-06-27T01:49:39.093+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:49:39.093+0000] {override.py:1090} DEBUG - Not syncing DAG-level permissions for DAG 'DAG:selenium' as access control is unset.
[2024-06-27T01:49:39.095+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:49:39.094+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:49:39.096+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:49:39.116+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:49:39.115+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:49:39.117+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:49:39.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.437 seconds
[2024-06-27T01:50:09.817+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:50:09.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:50:09.847+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:09.846+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:50:09.987+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:09.986+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:50:09.989+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:50:09.991+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:09.990+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:50:09.993+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:09.992+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:50:10.015+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:10.015+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:50:10.058+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:10.057+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:50:10.059+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:10.059+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:50:10.060+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:50:10.097+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:10.096+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:50:10.097+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:50:10.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.379 seconds
[2024-06-27T01:50:40.413+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:50:40.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:50:40.418+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:40.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:50:40.519+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:40.518+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:50:40.520+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:50:40.521+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:40.521+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:50:40.522+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:40.522+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:50:40.534+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:40.534+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:50:40.552+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:40.552+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:50:40.553+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:40.553+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:50:40.554+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:50:40.570+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:50:40.570+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:50:40.571+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:50:40.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.191 seconds
[2024-06-27T01:51:11.095+0000] {processor.py:161} INFO - Started process (PID=100) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:51:11.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:51:11.099+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:11.099+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:51:11.202+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:11.202+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:51:11.203+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:51:11.204+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:11.204+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:51:11.205+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:11.205+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:51:11.217+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:11.217+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:51:11.237+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:11.237+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:51:11.238+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:11.238+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:51:11.239+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:51:11.257+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:11.257+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:51:11.259+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:51:11.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.196 seconds
[2024-06-27T01:51:41.472+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:51:41.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:51:41.476+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:41.476+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:51:41.588+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:41.588+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:51:41.589+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:51:41.591+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:41.590+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:51:41.591+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:41.591+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:51:41.606+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:41.606+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:51:41.624+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:41.623+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:51:41.625+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:41.624+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:51:41.625+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:51:41.641+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:51:41.641+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:51:41.642+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:51:41.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.211 seconds
[2024-06-27T01:52:13.132+0000] {processor.py:161} INFO - Started process (PID=124) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:52:13.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:52:13.136+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:13.135+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:52:13.272+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:13.272+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:52:13.273+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:52:13.275+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:13.275+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:52:13.276+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:13.276+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:52:13.293+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:13.293+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:52:13.324+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:13.323+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:52:13.325+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:13.324+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:52:13.326+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:52:13.347+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:13.347+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:52:13.348+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:52:13.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.257 seconds
[2024-06-27T01:52:44.335+0000] {processor.py:161} INFO - Started process (PID=136) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:52:44.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:52:44.339+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:44.338+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:52:44.444+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:44.444+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:52:44.445+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:52:44.447+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:44.447+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:52:44.448+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:44.448+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:52:44.461+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:44.461+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:52:44.479+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:44.479+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:52:44.480+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:44.480+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:52:44.481+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:52:44.498+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:52:44.498+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:52:44.499+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:52:44.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.201 seconds
[2024-06-27T01:53:14.797+0000] {processor.py:161} INFO - Started process (PID=148) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:53:14.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:53:14.801+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:14.800+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:53:14.905+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:14.905+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:53:14.906+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:53:14.907+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:14.907+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:53:14.908+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:14.908+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:53:14.920+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:14.920+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:53:14.939+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:14.939+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:53:14.940+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:14.940+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:53:14.941+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:53:14.956+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:14.956+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:53:14.957+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:53:14.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.191 seconds
[2024-06-27T01:53:46.240+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:53:46.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:53:46.244+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:46.243+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:53:46.340+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:46.340+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:53:46.341+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:53:46.342+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:46.342+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:53:46.343+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:46.343+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:53:46.354+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:46.354+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:53:46.372+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:46.372+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:53:46.373+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:46.373+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:53:46.374+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:53:46.389+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:53:46.389+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:53:46.389+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:53:46.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.188 seconds
[2024-06-27T01:54:16.985+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:54:16.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:54:16.995+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:16.994+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:54:17.120+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:17.120+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:54:17.121+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:54:17.123+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:17.123+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:54:17.124+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:17.124+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:54:17.137+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:17.136+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:54:17.154+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:17.154+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:54:17.155+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:17.155+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:54:17.156+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:54:17.172+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:17.172+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:54:17.173+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:54:17.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.238 seconds
[2024-06-27T01:54:47.963+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:54:47.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:54:47.967+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:47.966+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:54:48.067+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:48.066+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:54:48.067+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:54:48.069+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:48.068+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:54:48.069+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:48.069+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:54:48.082+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:48.082+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:54:48.101+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:48.101+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:54:48.102+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:48.102+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:54:48.103+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:54:48.123+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:54:48.123+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:54:48.124+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:54:48.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.199 seconds
[2024-06-27T01:55:18.937+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:55:18.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:55:18.941+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:18.941+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:55:19.054+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:19.054+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:55:19.055+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:55:19.057+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:19.057+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:55:19.058+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:19.058+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:55:19.071+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:19.071+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:55:19.095+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:19.095+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:55:19.096+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:19.096+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:55:19.097+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:55:19.115+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:19.114+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:55:19.115+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:55:19.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.219 seconds
[2024-06-27T01:55:49.869+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:55:49.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:55:49.873+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:49.873+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:55:49.975+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:49.974+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:55:49.976+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:55:49.978+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:49.978+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:55:49.979+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:49.979+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:55:49.994+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:49.994+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:55:50.015+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:50.015+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:55:50.016+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:50.016+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:55:50.017+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:55:50.032+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:55:50.032+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:55:50.033+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:55:50.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.198 seconds
[2024-06-27T01:56:20.209+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:56:20.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:56:20.215+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:20.214+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:56:20.396+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:20.395+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:56:20.396+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:56:20.398+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:20.398+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:56:20.399+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:20.399+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:56:20.420+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:20.419+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:56:20.448+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:20.447+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:56:20.450+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:20.449+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:56:20.451+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:56:20.470+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:20.470+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:56:20.471+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:56:20.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.311 seconds
[2024-06-27T01:56:51.261+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:56:51.263+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:56:51.266+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:51.265+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:56:51.407+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:51.406+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:56:51.408+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:56:51.410+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:51.410+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:56:51.411+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:51.411+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:56:51.429+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:51.429+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:56:51.467+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:51.466+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:56:51.468+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:51.468+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:56:51.469+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:56:51.504+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:56:51.504+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:56:51.505+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:56:51.553+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.301 seconds
[2024-06-27T01:57:22.180+0000] {processor.py:161} INFO - Started process (PID=250) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:57:22.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:57:22.184+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:22.183+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:57:22.284+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:22.284+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:57:22.285+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:57:22.286+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:22.286+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:57:22.287+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:22.287+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:57:22.299+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:22.299+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:57:22.316+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:22.316+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:57:22.317+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:22.317+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:57:22.317+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:57:22.332+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:22.331+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:57:22.332+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:57:22.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.188 seconds
[2024-06-27T01:57:53.060+0000] {processor.py:161} INFO - Started process (PID=262) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:57:53.062+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:57:53.064+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:53.064+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:57:53.188+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:53.187+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:57:53.189+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:57:53.191+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:53.190+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:57:53.192+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:53.191+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:57:53.205+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:53.205+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:57:53.225+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:53.225+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:57:53.227+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:53.226+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:57:53.228+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:57:53.244+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:57:53.244+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:57:53.245+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:57:53.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.221 seconds
[2024-06-27T01:58:23.856+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:58:23.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:58:23.861+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:23.860+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:58:23.975+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:23.974+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:58:23.975+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:58:23.977+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:23.977+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:58:23.979+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:23.978+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:58:23.992+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:23.992+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:58:24.014+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:24.014+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:58:24.015+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:24.015+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:58:24.016+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:58:24.033+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:24.032+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:58:24.033+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:58:24.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.210 seconds
[2024-06-27T01:58:54.432+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:58:54.433+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:58:54.435+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:54.435+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:58:54.538+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:54.536+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:58:54.538+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:58:54.540+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:54.540+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:58:54.541+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:54.540+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:58:54.556+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:54.556+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:58:54.573+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:54.573+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:58:54.574+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:54.574+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:58:54.575+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:58:54.591+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:58:54.591+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:58:54.592+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:58:54.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.196 seconds
[2024-06-27T01:59:25.338+0000] {processor.py:161} INFO - Started process (PID=298) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:59:25.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:59:25.342+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:25.341+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:59:25.444+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:25.444+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:59:25.445+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:59:25.446+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:25.446+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:59:25.447+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:25.447+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:59:25.460+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:25.459+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:59:25.477+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:25.477+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:59:25.478+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:25.478+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:59:25.479+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:59:25.497+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:25.497+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:59:25.498+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:59:25.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.195 seconds
[2024-06-27T01:59:56.513+0000] {processor.py:161} INFO - Started process (PID=310) to work on /opt/airflow/dags/crawl.py
[2024-06-27T01:59:56.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T01:59:56.518+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:56.517+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T01:59:56.643+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:56.642+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T01:59:56.643+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T01:59:56.645+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:56.645+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T01:59:56.646+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:56.645+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T01:59:56.658+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:56.658+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T01:59:56.675+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:56.674+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T01:59:56.676+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:56.676+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T01:59:56.676+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T01:59:56.693+0000] {logging_mixin.py:188} INFO - [2024-06-27T01:59:56.693+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:59:56.694+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T01:59:56.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.220 seconds
[2024-06-27T02:00:27.132+0000] {processor.py:161} INFO - Started process (PID=322) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:00:27.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:00:27.135+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:27.135+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:00:27.253+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:27.253+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:00:27.254+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:00:27.256+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:27.256+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:00:27.257+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:27.257+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:00:27.273+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:27.273+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:00:27.292+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:27.291+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:00:27.293+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:27.292+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:00:27.293+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:00:27.310+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:27.309+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:00:27.310+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:00:27.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.212 seconds
[2024-06-27T02:00:57.984+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:00:57.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:00:57.987+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:57.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:00:58.095+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:58.094+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:00:58.096+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:00:58.097+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:58.097+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:00:58.098+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:58.098+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:00:58.113+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:58.113+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:00:58.133+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:58.133+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:00:58.135+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:58.134+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:00:58.136+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:00:58.152+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:00:58.151+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:00:58.153+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:00:58.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.208 seconds
[2024-06-27T02:01:28.798+0000] {processor.py:161} INFO - Started process (PID=346) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:01:28.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:01:28.801+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:28.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:01:28.912+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:28.911+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:01:28.912+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:01:28.914+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:28.914+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:01:28.915+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:28.915+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:01:28.931+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:28.931+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:01:28.950+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:28.949+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:01:28.950+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:28.950+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:01:28.951+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:01:28.968+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:28.967+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:01:28.968+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:01:28.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.200 seconds
[2024-06-27T02:01:59.236+0000] {processor.py:161} INFO - Started process (PID=364) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:01:59.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:01:59.239+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:59.239+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:01:59.336+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:59.335+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:01:59.337+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:01:59.338+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:59.338+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:01:59.339+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:59.339+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:01:59.351+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:59.351+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:01:59.367+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:59.367+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:01:59.368+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:59.368+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:01:59.369+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:01:59.391+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:01:59.391+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:01:59.392+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:01:59.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.191 seconds
[2024-06-27T02:02:29.757+0000] {processor.py:161} INFO - Started process (PID=375) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:02:29.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:02:29.760+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:02:29.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:02:29.870+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:02:29.869+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:02:29.871+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:02:29.872+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:02:29.872+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:02:29.873+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:02:29.873+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:02:29.885+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:02:29.884+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:02:29.902+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:02:29.902+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:02:29.903+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:02:29.903+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:02:29.904+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:02:29.918+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:02:29.918+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:02:29.919+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:02:29.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.203 seconds
[2024-06-27T02:03:00.216+0000] {processor.py:161} INFO - Started process (PID=387) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:03:00.217+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:03:00.219+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:00.219+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:03:00.323+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:00.323+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:03:00.324+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:03:00.326+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:00.325+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:03:00.326+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:00.326+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:03:00.339+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:00.339+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:03:00.356+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:00.355+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:03:00.356+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:00.356+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:03:00.357+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:03:00.372+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:00.372+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:03:00.373+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:03:00.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.189 seconds
[2024-06-27T02:03:31.074+0000] {processor.py:161} INFO - Started process (PID=399) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:03:31.075+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:03:31.077+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:31.077+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:03:31.178+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:31.178+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:03:31.179+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:03:31.180+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:31.180+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:03:31.181+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:31.181+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:03:31.193+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:31.193+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:03:31.209+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:31.209+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:03:31.210+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:31.210+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:03:31.211+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:03:31.225+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:03:31.225+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:03:31.226+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:03:31.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.189 seconds
[2024-06-27T02:04:01.573+0000] {processor.py:161} INFO - Started process (PID=411) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:04:01.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:04:01.576+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:01.576+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:04:01.684+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:01.683+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:04:01.685+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:04:01.686+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:01.686+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:04:01.687+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:01.687+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:04:01.700+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:01.700+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:04:01.718+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:01.718+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:04:01.719+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:01.719+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:04:01.720+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:04:01.735+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:01.734+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:04:01.735+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:04:01.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.197 seconds
[2024-06-27T02:04:32.442+0000] {processor.py:161} INFO - Started process (PID=423) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:04:32.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:04:32.446+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:32.445+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:04:32.547+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:32.546+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:04:32.548+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:04:32.549+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:32.549+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:04:32.550+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:32.550+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:04:32.563+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:32.562+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:04:32.579+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:32.578+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:04:32.580+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:32.579+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:04:32.580+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:04:32.594+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:04:32.594+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:04:32.595+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:04:32.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.196 seconds
[2024-06-27T02:05:03.257+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:05:03.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:05:03.261+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:03.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:05:03.394+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:03.393+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:05:03.395+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:05:03.396+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:03.396+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:05:03.397+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:03.397+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:05:03.409+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:03.409+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:05:03.431+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:03.431+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:05:03.432+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:03.432+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:05:03.432+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:05:03.450+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:03.450+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:05:03.451+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:05:03.482+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.232 seconds
[2024-06-27T02:05:34.418+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:05:34.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:05:34.421+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:34.421+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:05:34.530+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:34.529+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:05:34.530+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:05:34.532+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:34.532+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:05:34.534+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:34.534+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:05:34.548+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:34.547+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:05:34.569+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:34.569+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:05:34.570+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:34.570+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:05:34.571+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:05:34.587+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:05:34.587+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:05:34.588+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:05:34.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.205 seconds
[2024-06-27T02:06:04.976+0000] {processor.py:161} INFO - Started process (PID=459) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:06:04.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:06:04.980+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:04.979+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:06:05.078+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:05.077+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:06:05.079+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:06:05.080+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:05.080+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:06:05.081+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:05.081+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:06:05.092+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:05.092+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:06:05.108+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:05.108+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:06:05.109+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:05.109+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:06:05.110+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:06:05.124+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:05.124+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:06:05.125+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:06:05.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.190 seconds
[2024-06-27T02:06:35.968+0000] {processor.py:161} INFO - Started process (PID=471) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:06:35.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:06:35.972+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:35.972+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:06:36.075+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:36.075+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:06:36.076+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:06:36.077+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:36.077+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:06:36.078+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:36.078+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:06:36.091+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:36.090+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:06:36.108+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:36.107+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:06:36.109+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:36.108+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:06:36.109+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:06:36.126+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:06:36.125+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:06:36.126+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:06:36.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.214 seconds
[2024-06-27T02:07:07.028+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:07:07.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:07:07.031+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:07.031+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:07:07.143+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:07.142+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:07:07.144+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:07:07.145+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:07.145+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:07:07.146+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:07.145+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:07:07.160+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:07.159+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:07:07.178+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:07.178+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:07:07.179+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:07.179+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:07:07.180+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:07:07.196+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:07.195+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:07:07.196+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:07:07.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.204 seconds
[2024-06-27T02:07:38.180+0000] {processor.py:161} INFO - Started process (PID=495) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:07:38.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:07:38.183+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:38.183+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:07:38.299+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:38.299+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:07:38.300+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:07:38.303+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:38.303+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:07:38.304+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:38.304+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:07:38.316+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:38.316+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:07:38.334+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:38.334+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:07:38.335+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:38.335+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:07:38.336+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:07:38.351+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:07:38.350+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:07:38.351+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:07:38.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.201 seconds
[2024-06-27T02:08:08.896+0000] {processor.py:161} INFO - Started process (PID=506) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:08:08.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:08:08.900+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:08.899+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:08:09.011+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:09.010+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:08:09.011+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:08:09.013+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:09.013+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:08:09.015+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:09.014+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:08:09.035+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:09.035+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:08:09.055+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:09.055+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:08:09.056+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:09.056+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:08:09.057+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:08:09.074+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:09.074+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:08:09.075+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:08:09.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.213 seconds
[2024-06-27T02:08:50.923+0000] {processor.py:161} INFO - Started process (PID=518) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:08:50.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:08:50.931+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:50.931+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:08:51.243+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:51.240+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:08:51.245+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:08:51.247+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:51.246+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:08:51.248+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:51.248+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:08:51.273+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:51.272+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:08:51.309+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:51.308+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:08:51.313+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:51.312+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:08:51.316+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:08:51.354+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:08:51.353+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:08:51.363+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:08:51.446+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.543 seconds
[2024-06-27T02:09:21.593+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:09:21.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:09:21.598+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:21.597+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:09:21.745+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:21.744+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:09:21.745+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:09:21.747+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:21.746+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:09:21.747+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:21.747+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:09:21.758+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:21.758+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:09:21.776+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:21.776+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:09:21.777+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:21.777+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:09:21.778+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:09:21.794+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:21.794+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:09:21.795+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:09:21.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.235 seconds
[2024-06-27T02:09:52.563+0000] {processor.py:161} INFO - Started process (PID=543) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:09:52.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:09:52.570+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:52.569+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:09:52.675+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:52.674+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:09:52.676+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:09:52.677+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:52.677+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:09:52.678+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:52.678+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:09:52.691+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:52.690+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:09:52.708+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:52.708+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:09:52.709+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:52.708+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:09:52.709+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:09:52.725+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:09:52.725+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:09:52.726+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:09:52.754+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.197 seconds
[2024-06-27T02:10:23.184+0000] {processor.py:161} INFO - Started process (PID=555) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:10:23.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:10:23.191+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:23.190+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:10:23.306+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:23.305+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:10:23.306+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:10:23.308+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:23.308+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:10:23.308+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:23.308+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:10:23.321+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:23.321+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:10:23.338+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:23.338+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:10:23.339+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:23.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:10:23.340+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:10:23.356+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:23.355+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:10:23.356+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:10:23.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.226 seconds
[2024-06-27T02:10:53.593+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:10:53.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:10:53.597+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:53.596+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:10:53.695+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:53.695+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:10:53.696+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:10:53.697+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:53.697+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:10:53.698+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:53.698+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:10:53.712+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:53.712+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:10:53.728+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:53.728+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:10:53.729+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:53.729+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:10:53.730+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:10:53.744+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:10:53.744+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:10:53.745+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:10:53.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.186 seconds
[2024-06-27T02:11:24.131+0000] {processor.py:161} INFO - Started process (PID=578) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:11:24.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:11:24.135+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:24.135+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:11:24.248+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:24.247+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:11:24.249+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:11:24.251+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:24.250+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:11:24.251+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:24.251+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:11:24.266+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:24.266+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:11:24.283+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:24.283+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:11:24.284+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:24.284+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:11:24.285+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:11:24.302+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:24.301+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:11:24.303+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:11:24.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.207 seconds
[2024-06-27T02:11:54.635+0000] {processor.py:161} INFO - Started process (PID=590) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:11:54.636+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:11:54.638+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:54.638+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:11:54.758+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:54.755+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:11:54.759+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:11:54.761+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:54.760+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:11:54.762+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:54.761+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:11:54.774+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:54.774+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:11:54.790+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:54.790+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:11:54.791+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:54.791+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:11:54.791+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:11:54.805+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:11:54.805+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:11:54.806+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:11:54.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.205 seconds
[2024-06-27T02:12:25.945+0000] {processor.py:161} INFO - Started process (PID=602) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:12:25.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:12:25.948+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:25.948+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:12:26.058+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:26.058+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:12:26.059+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:12:26.060+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:26.060+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:12:26.061+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:26.061+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:12:26.074+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:26.073+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:12:26.090+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:26.090+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:12:26.091+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:26.091+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:12:26.092+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:12:26.107+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:26.106+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:12:26.107+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:12:26.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.194 seconds
[2024-06-27T02:12:56.911+0000] {processor.py:161} INFO - Started process (PID=614) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:12:56.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:12:56.915+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:56.914+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:12:57.046+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:57.046+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:12:57.047+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:12:57.048+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:57.048+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:12:57.049+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:57.049+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:12:57.061+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:57.061+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:12:57.079+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:57.079+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:12:57.080+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:57.080+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:12:57.080+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:12:57.097+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:12:57.097+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:12:57.098+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:12:57.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.230 seconds
[2024-06-27T02:13:27.916+0000] {processor.py:161} INFO - Started process (PID=626) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:13:27.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:13:27.918+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:27.918+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:13:28.042+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:28.041+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:13:28.043+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:13:28.045+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:28.045+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:13:28.046+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:28.046+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:13:28.061+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:28.060+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:13:28.081+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:28.081+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:13:28.082+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:28.082+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:13:28.083+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:13:28.106+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:28.105+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:13:28.107+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:13:28.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.230 seconds
[2024-06-27T02:13:58.914+0000] {processor.py:161} INFO - Started process (PID=638) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:13:58.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:13:58.918+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:58.917+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:13:59.084+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:59.083+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:13:59.084+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:13:59.085+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:59.085+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:13:59.086+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:59.086+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:13:59.101+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:59.100+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:13:59.120+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:59.120+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:13:59.121+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:59.121+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:13:59.122+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:13:59.140+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:13:59.140+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:13:59.140+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:13:59.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.260 seconds
[2024-06-27T02:14:29.408+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:14:29.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:14:29.411+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:14:29.411+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:14:29.531+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:14:29.530+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:14:29.532+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:14:29.533+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:14:29.533+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:14:29.534+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:14:29.533+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:14:29.547+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:14:29.547+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:14:29.566+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:14:29.566+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:14:29.567+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:14:29.567+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:14:29.568+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:14:29.585+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:14:29.585+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:14:29.586+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:14:29.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.210 seconds
[2024-06-27T02:15:00.570+0000] {processor.py:161} INFO - Started process (PID=662) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:15:00.572+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:15:00.574+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:00.573+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:15:00.712+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:00.711+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:15:00.713+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:15:00.715+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:00.714+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:15:00.715+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:00.715+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:15:00.734+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:00.733+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:15:00.760+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:00.759+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:15:00.761+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:00.761+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:15:00.761+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:15:00.783+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:00.782+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:15:00.784+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:15:00.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.276 seconds
[2024-06-27T02:15:31.291+0000] {processor.py:161} INFO - Started process (PID=674) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:15:31.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:15:31.294+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:31.294+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:15:31.397+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:31.397+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:15:31.398+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:15:31.399+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:31.399+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:15:31.400+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:31.400+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:15:31.413+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:31.412+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:15:31.429+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:31.428+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:15:31.430+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:31.429+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:15:31.430+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:15:31.445+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:15:31.445+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:15:31.446+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:15:31.482+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.198 seconds
[2024-06-27T02:16:01.671+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:16:01.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:16:01.674+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:01.674+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:16:01.783+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:01.782+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:16:01.784+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:16:01.785+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:01.785+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:16:01.786+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:01.786+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:16:01.800+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:01.799+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:16:01.817+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:01.816+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:16:01.818+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:01.818+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:16:01.819+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:16:01.835+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:01.835+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:16:01.836+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:16:01.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.202 seconds
[2024-06-27T02:16:32.207+0000] {processor.py:161} INFO - Started process (PID=697) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:16:32.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:16:32.210+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:32.210+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:16:32.371+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:32.369+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:16:32.371+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:16:32.373+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:32.372+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:16:32.373+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:32.373+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:16:32.385+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:32.385+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:16:32.406+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:32.406+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:16:32.407+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:32.407+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:16:32.407+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:16:32.424+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:16:32.424+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:16:32.425+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:16:32.464+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.263 seconds
[2024-06-27T02:17:02.883+0000] {processor.py:161} INFO - Started process (PID=709) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:17:02.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:17:02.887+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:02.886+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:17:02.993+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:02.992+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:17:02.994+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:17:02.995+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:02.995+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:17:02.996+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:02.996+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:17:03.009+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:03.009+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:17:03.027+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:03.026+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:17:03.028+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:03.028+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:17:03.028+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:17:03.045+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:03.045+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:17:03.046+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:17:03.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.204 seconds
[2024-06-27T02:17:33.483+0000] {processor.py:161} INFO - Started process (PID=721) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:17:33.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:17:33.486+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:33.485+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:17:33.595+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:33.594+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:17:33.595+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:17:33.597+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:33.597+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:17:33.598+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:33.598+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:17:33.615+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:33.614+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:17:33.640+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:33.639+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:17:33.641+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:33.641+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:17:33.642+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:17:33.663+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:17:33.663+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:17:33.664+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:17:33.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.212 seconds
[2024-06-27T02:18:03.901+0000] {processor.py:161} INFO - Started process (PID=732) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:18:03.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:18:03.903+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:03.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:18:04.003+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:04.002+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:18:04.004+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:18:04.006+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:04.005+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:18:04.007+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:04.006+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:18:04.019+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:04.019+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:18:04.037+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:04.036+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:18:04.038+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:04.037+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:18:04.038+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:18:04.055+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:04.055+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:18:04.056+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:18:04.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.282 seconds
[2024-06-27T02:18:34.616+0000] {processor.py:161} INFO - Started process (PID=745) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:18:34.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:18:34.619+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:34.619+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:18:34.731+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:34.730+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:18:34.731+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:18:34.733+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:34.733+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:18:34.734+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:34.733+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:18:34.747+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:34.746+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:18:34.763+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:34.762+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:18:34.764+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:34.763+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:18:34.764+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:18:34.780+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:18:34.780+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:18:34.781+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:18:34.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.199 seconds
[2024-06-27T02:19:05.084+0000] {processor.py:161} INFO - Started process (PID=757) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:19:05.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:19:05.089+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:05.088+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:19:05.212+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:05.212+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:19:05.213+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:19:05.215+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:05.215+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:19:05.216+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:05.216+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:19:05.228+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:05.228+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:19:05.246+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:05.245+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:19:05.247+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:05.246+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:19:05.247+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:19:05.263+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:05.263+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:19:05.264+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:19:05.293+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.219 seconds
[2024-06-27T02:19:35.957+0000] {processor.py:161} INFO - Started process (PID=769) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:19:35.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:19:35.960+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:35.960+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:19:36.110+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:36.109+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:19:36.111+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:19:36.112+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:36.112+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:19:36.113+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:36.113+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:19:36.124+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:36.124+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:19:36.140+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:36.139+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:19:36.140+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:36.140+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:19:36.141+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:19:36.155+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:19:36.155+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:19:36.155+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:19:36.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.229 seconds
[2024-06-27T02:20:06.677+0000] {processor.py:161} INFO - Started process (PID=787) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:20:06.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:20:06.680+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:06.679+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:20:06.779+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:06.778+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:20:06.779+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:20:06.781+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:06.781+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:20:06.782+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:06.781+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:20:06.794+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:06.794+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:20:06.810+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:06.810+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:20:06.811+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:06.811+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:20:06.812+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:20:06.825+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:06.825+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:20:06.826+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:20:06.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.181 seconds
[2024-06-27T02:20:37.077+0000] {processor.py:161} INFO - Started process (PID=799) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:20:37.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:20:37.080+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:37.079+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:20:37.180+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:37.179+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:20:37.181+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:20:37.182+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:37.182+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:20:37.183+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:37.183+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:20:37.198+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:37.198+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:20:37.217+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:37.217+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:20:37.219+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:37.218+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:20:37.219+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:20:37.243+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:20:37.242+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:20:37.244+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:20:37.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.207 seconds
[2024-06-27T02:21:07.741+0000] {processor.py:161} INFO - Started process (PID=811) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:21:07.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:21:07.743+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:07.743+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:21:07.846+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:07.844+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:21:07.846+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:21:07.848+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:07.848+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:21:07.849+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:07.848+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:21:07.861+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:07.861+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:21:07.878+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:07.878+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:21:07.879+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:07.879+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:21:07.880+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:21:07.894+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:07.894+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:21:07.895+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:21:07.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.190 seconds
[2024-06-27T02:21:38.370+0000] {processor.py:161} INFO - Started process (PID=823) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:21:38.371+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:21:38.372+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:38.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:21:38.477+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:38.476+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:21:38.477+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:21:38.479+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:38.479+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:21:38.480+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:38.480+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:21:38.493+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:38.493+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:21:38.510+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:38.510+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:21:38.511+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:38.510+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:21:38.511+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:21:38.528+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:21:38.528+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:21:38.529+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:21:38.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.269 seconds
[2024-06-27T02:22:08.914+0000] {processor.py:161} INFO - Started process (PID=835) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:22:08.915+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:22:08.917+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:08.916+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:22:09.015+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:09.014+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:22:09.016+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:22:09.017+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:09.017+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:22:09.018+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:09.018+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:22:09.032+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:09.031+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:22:09.050+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:09.050+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:22:09.051+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:09.051+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:22:09.052+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:22:09.074+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:09.074+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:22:09.075+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:22:09.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.195 seconds
[2024-06-27T02:22:39.363+0000] {processor.py:161} INFO - Started process (PID=847) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:22:39.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:22:39.367+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:39.366+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:22:39.538+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:39.536+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:22:39.538+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:22:39.540+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:39.539+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:22:39.540+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:39.540+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:22:39.560+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:39.559+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:22:39.594+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:39.593+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:22:39.595+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:39.595+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:22:39.596+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:22:39.645+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:22:39.644+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:22:39.646+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:22:39.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.468 seconds
[2024-06-27T02:23:09.898+0000] {processor.py:161} INFO - Started process (PID=858) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:23:09.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:23:09.903+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:09.902+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:23:10.046+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:10.046+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:23:10.047+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:23:10.048+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:10.048+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:23:10.049+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:10.049+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:23:10.061+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:10.061+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:23:10.079+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:10.079+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:23:10.080+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:10.080+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:23:10.080+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:23:10.096+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:10.096+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:23:10.097+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:23:10.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.240 seconds
[2024-06-27T02:23:40.306+0000] {processor.py:161} INFO - Started process (PID=870) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:23:40.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:23:40.309+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:40.308+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:23:40.420+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:40.419+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:23:40.421+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:23:40.422+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:40.422+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:23:40.423+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:40.423+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:23:40.436+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:40.436+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:23:40.452+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:40.452+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:23:40.453+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:40.453+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:23:40.454+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:23:40.470+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:23:40.469+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:23:40.471+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:23:40.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.201 seconds
[2024-06-27T02:24:10.838+0000] {processor.py:161} INFO - Started process (PID=882) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:24:10.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:24:10.842+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:10.842+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:24:10.933+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:10.933+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:24:10.934+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:24:10.935+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:10.935+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:24:10.936+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:10.936+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:24:10.949+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:10.949+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:24:10.969+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:10.968+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:24:10.970+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:10.969+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:24:10.970+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:24:10.985+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:10.985+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:24:10.986+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:24:11.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.183 seconds
[2024-06-27T02:24:41.375+0000] {processor.py:161} INFO - Started process (PID=894) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:24:41.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:24:41.378+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:41.378+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:24:41.491+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:41.490+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:24:41.492+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:24:41.494+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:41.493+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:24:41.494+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:41.494+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:24:41.507+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:41.507+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:24:41.525+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:41.525+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:24:41.526+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:41.526+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:24:41.526+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:24:41.541+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:24:41.541+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:24:41.542+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:24:41.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.201 seconds
[2024-06-27T02:25:11.964+0000] {processor.py:161} INFO - Started process (PID=906) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:25:11.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:25:11.966+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:11.966+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:25:12.066+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:12.065+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:25:12.067+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:25:12.068+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:12.068+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:25:12.069+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:12.069+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:25:12.082+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:12.082+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:25:12.099+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:12.098+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:25:12.099+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:12.099+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:25:12.100+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:25:12.116+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:12.116+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:25:12.117+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:25:12.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.188 seconds
[2024-06-27T02:25:42.243+0000] {processor.py:161} INFO - Started process (PID=918) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:25:42.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:25:42.246+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:42.246+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:25:42.350+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:42.349+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:25:42.351+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:25:42.353+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:42.353+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:25:42.354+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:42.354+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:25:42.367+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:42.367+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:25:42.383+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:42.383+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:25:42.384+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:42.384+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:25:42.385+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:25:42.400+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:25:42.399+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:25:42.400+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:25:42.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.190 seconds
[2024-06-27T02:26:12.643+0000] {processor.py:161} INFO - Started process (PID=930) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:26:12.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:26:12.646+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:12.645+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:26:12.745+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:12.745+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:26:12.746+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:26:12.748+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:12.748+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:26:12.749+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:12.749+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:26:12.761+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:12.761+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:26:12.779+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:12.779+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:26:12.780+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:12.780+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:26:12.780+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:26:12.795+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:12.795+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:26:12.796+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:26:12.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.188 seconds
[2024-06-27T02:26:43.339+0000] {processor.py:161} INFO - Started process (PID=942) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:26:43.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:26:43.342+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:43.342+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:26:43.611+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:43.609+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:26:43.611+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:26:43.612+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:43.612+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:26:43.613+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:43.613+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:26:43.626+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:43.626+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:26:43.642+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:43.642+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:26:43.643+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:43.643+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:26:43.644+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:26:43.661+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:26:43.660+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:26:43.661+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:26:43.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.355 seconds
[2024-06-27T02:27:14.101+0000] {processor.py:161} INFO - Started process (PID=955) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:27:14.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:27:14.104+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:14.103+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:27:14.254+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:14.252+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:27:14.255+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:27:14.256+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:14.256+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:27:14.257+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:14.257+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:27:14.274+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:14.273+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:27:14.298+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:14.297+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:27:14.298+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:14.298+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:27:14.299+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:27:14.318+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:14.317+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:27:14.318+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:27:14.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.260 seconds
[2024-06-27T02:27:44.749+0000] {processor.py:161} INFO - Started process (PID=967) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:27:44.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:27:44.752+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:44.752+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:27:44.867+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:44.867+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:27:44.868+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:27:44.870+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:44.869+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:27:44.871+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:44.870+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:27:44.887+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:44.887+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:27:44.907+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:44.907+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:27:44.908+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:44.908+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:27:44.909+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:27:44.927+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:27:44.927+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:27:44.928+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:27:44.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.234 seconds
[2024-06-27T02:28:15.447+0000] {processor.py:161} INFO - Started process (PID=979) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:28:15.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:28:15.450+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:15.449+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:28:15.552+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:15.551+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:28:15.552+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:28:15.554+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:15.553+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:28:15.554+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:15.554+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:28:15.566+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:15.566+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:28:15.583+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:15.583+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:28:15.584+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:15.584+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:28:15.584+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:28:15.602+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:15.602+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:28:15.603+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:28:15.639+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.199 seconds
[2024-06-27T02:28:45.736+0000] {processor.py:161} INFO - Started process (PID=990) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:28:45.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:28:45.843+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:45.842+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:28:46.185+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:46.183+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:28:46.201+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:28:46.217+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:46.216+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:28:46.227+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:46.227+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:28:46.280+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:46.275+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:28:46.338+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:46.337+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:28:46.349+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:46.349+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:28:46.363+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:28:46.434+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:28:46.433+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:28:46.435+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:28:46.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.810 seconds
[2024-06-27T02:29:16.834+0000] {processor.py:161} INFO - Started process (PID=1003) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:29:16.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:29:16.838+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:16.837+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:29:16.986+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:16.982+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:29:16.987+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:29:16.990+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:16.989+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:29:16.991+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:16.990+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:29:17.018+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:17.018+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:29:17.059+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:17.059+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:29:17.061+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:17.060+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:29:17.062+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:29:17.094+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:17.093+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:29:17.094+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:29:17.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.298 seconds
[2024-06-27T02:29:47.231+0000] {processor.py:161} INFO - Started process (PID=1015) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:29:47.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:29:47.243+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:47.243+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:29:47.371+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:47.370+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:29:47.371+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:29:47.373+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:47.373+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:29:47.373+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:47.373+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:29:47.385+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:47.385+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:29:47.406+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:47.406+0000] {serialized_dag.py:180} DEBUG - Writing Serialized DAG: selenium to the DB
[2024-06-27T02:29:47.413+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:47.413+0000] {serialized_dag.py:182} DEBUG - DAG: selenium written to the DB
[2024-06-27T02:29:47.414+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:47.414+0000] {dagbag.py:701} DEBUG - Syncing DAG permissions: selenium to the DB
[2024-06-27T02:29:47.706+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:47.706+0000] {override.py:1090} DEBUG - Not syncing DAG-level permissions for DAG 'DAG:selenium' as access control is unset.
[2024-06-27T02:29:47.708+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:47.707+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:29:47.709+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:29:47.748+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:29:47.748+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:29:47.750+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:29:47.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.569 seconds
[2024-06-27T02:30:18.142+0000] {processor.py:161} INFO - Started process (PID=1027) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:30:18.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:30:18.145+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:18.145+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:30:18.241+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:18.241+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:30:18.242+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:30:18.245+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:18.244+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:30:18.245+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:18.245+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:30:18.258+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:18.258+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:30:18.278+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:18.278+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:30:18.279+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:18.279+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:30:18.280+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:30:18.296+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:18.296+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:30:18.296+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:30:18.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.187 seconds
[2024-06-27T02:30:48.771+0000] {processor.py:161} INFO - Started process (PID=1038) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:30:48.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:30:48.775+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:48.775+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:30:48.897+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:48.896+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:30:48.898+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:30:48.899+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:48.899+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:30:48.900+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:48.900+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:30:48.913+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:48.913+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:30:48.931+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:48.931+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:30:48.932+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:48.932+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:30:48.932+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:30:48.946+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:30:48.946+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:30:48.947+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:30:48.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.209 seconds
[2024-06-27T02:31:19.246+0000] {processor.py:161} INFO - Started process (PID=1051) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:31:19.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:31:19.251+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:19.250+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:31:19.390+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:19.389+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:31:19.391+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:31:19.393+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:19.393+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:31:19.394+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:19.394+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:31:19.408+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:19.407+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:31:19.428+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:19.428+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:31:19.429+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:19.429+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:31:19.430+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:31:19.452+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:19.451+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:31:19.452+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:31:19.477+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.240 seconds
[2024-06-27T02:31:50.114+0000] {processor.py:161} INFO - Started process (PID=1063) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:31:50.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:31:50.118+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:50.117+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:31:50.234+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:50.233+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:31:50.235+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:31:50.237+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:50.237+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:31:50.238+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:50.237+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:31:50.250+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:50.250+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:31:50.267+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:50.266+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:31:50.268+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:50.267+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:31:50.268+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:31:50.284+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:31:50.284+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:31:50.285+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:31:50.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.203 seconds
[2024-06-27T02:32:20.418+0000] {processor.py:161} INFO - Started process (PID=1075) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:32:20.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:32:20.422+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:20.422+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:32:20.523+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:20.523+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:32:20.524+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:32:20.526+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:20.525+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:32:20.526+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:20.526+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:32:20.539+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:20.539+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:32:20.561+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:20.560+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:32:20.562+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:20.561+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:32:20.562+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:32:20.580+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:20.580+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:32:20.581+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:32:20.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.197 seconds
[2024-06-27T02:32:50.749+0000] {processor.py:161} INFO - Started process (PID=1087) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:32:50.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:32:50.753+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:50.752+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:32:50.862+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:50.861+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:32:50.863+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:32:50.864+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:50.864+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:32:50.865+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:50.865+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:32:50.879+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:50.879+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:32:50.903+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:50.902+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:32:50.904+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:50.904+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:32:50.905+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:32:50.926+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:32:50.926+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:32:50.927+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:32:50.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.224 seconds
[2024-06-27T02:33:21.806+0000] {processor.py:161} INFO - Started process (PID=1100) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:33:21.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:33:21.810+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:21.809+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:33:21.964+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:21.962+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:33:21.965+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:33:21.967+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:21.966+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:33:21.968+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:21.968+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:33:21.991+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:21.991+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:33:22.026+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:22.026+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:33:22.029+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:22.028+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:33:22.030+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:33:22.060+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:22.060+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:33:22.062+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:33:22.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.327 seconds
[2024-06-27T02:33:52.660+0000] {processor.py:161} INFO - Started process (PID=1112) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:33:52.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:33:52.665+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:52.664+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:33:52.905+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:52.904+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:33:52.907+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:33:52.909+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:52.909+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:33:52.910+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:52.910+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:33:52.935+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:52.935+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:33:52.973+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:52.973+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:33:52.975+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:52.974+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:33:52.976+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:33:53.025+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:33:53.024+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:33:53.027+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:33:53.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.467 seconds
[2024-06-27T02:34:23.681+0000] {processor.py:161} INFO - Started process (PID=1124) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:34:23.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:34:23.685+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:23.685+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:34:23.796+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:23.795+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:34:23.796+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:34:23.798+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:23.798+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:34:23.799+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:23.799+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:34:23.812+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:23.812+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:34:23.830+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:23.829+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:34:23.831+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:23.831+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:34:23.832+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:34:23.847+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:23.847+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:34:23.848+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:34:24.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.354 seconds
[2024-06-27T02:34:54.225+0000] {processor.py:161} INFO - Started process (PID=1136) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:34:54.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:34:54.229+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:54.228+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:34:54.366+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:54.365+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:34:54.367+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:34:54.369+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:54.368+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:34:54.370+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:54.370+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:34:54.384+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:54.383+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:34:54.404+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:54.403+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:34:54.405+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:54.404+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:34:54.405+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:34:54.423+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:34:54.423+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:34:54.424+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:34:54.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.235 seconds
[2024-06-27T02:35:24.723+0000] {processor.py:161} INFO - Started process (PID=1149) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:35:24.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:35:24.728+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:24.728+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:35:24.872+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:24.870+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:35:24.874+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:35:24.879+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:24.879+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:35:24.881+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:24.880+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:35:24.902+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:24.902+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:35:24.931+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:24.931+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:35:24.932+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:24.932+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:35:24.933+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:35:24.959+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:24.959+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:35:24.960+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:35:24.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.280 seconds
[2024-06-27T02:35:55.301+0000] {processor.py:161} INFO - Started process (PID=1161) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:35:55.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:35:55.304+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:55.304+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:35:55.435+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:55.435+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:35:55.436+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:35:55.438+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:55.438+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:35:55.439+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:55.438+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:35:55.453+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:55.453+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:35:55.472+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:55.471+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:35:55.473+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:55.472+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:35:55.473+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:35:55.494+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:35:55.494+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:35:55.495+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:35:55.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.394 seconds
[2024-06-27T02:36:26.311+0000] {processor.py:161} INFO - Started process (PID=1173) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:36:26.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:36:26.315+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:26.314+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:36:26.426+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:26.425+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:36:26.427+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:36:26.428+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:26.428+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:36:26.429+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:26.429+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:36:26.442+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:26.442+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:36:26.461+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:26.460+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:36:26.462+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:26.461+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:36:26.462+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:36:26.478+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:26.478+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:36:26.479+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:36:26.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.204 seconds
[2024-06-27T02:36:56.571+0000] {processor.py:161} INFO - Started process (PID=1185) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:36:56.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:36:56.575+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:56.575+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:36:56.761+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:56.760+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:36:56.761+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:36:56.765+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:56.763+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:36:56.766+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:56.766+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:36:56.786+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:56.785+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:36:56.816+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:56.816+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:36:56.817+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:56.817+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:36:56.817+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:36:56.835+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:36:56.834+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:36:56.836+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:36:56.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.318 seconds
[2024-06-27T02:37:27.238+0000] {processor.py:161} INFO - Started process (PID=1197) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:37:27.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:37:27.242+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:27.241+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:37:27.377+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:27.376+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:37:27.378+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:37:27.379+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:27.379+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:37:27.380+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:27.379+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:37:27.394+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:27.394+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:37:27.413+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:27.413+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:37:27.414+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:27.414+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:37:27.415+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:37:27.432+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:27.432+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:37:27.433+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:37:27.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.502 seconds
[2024-06-27T02:37:57.899+0000] {processor.py:161} INFO - Started process (PID=1209) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:37:57.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:37:57.903+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:57.902+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:37:58.022+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:58.022+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:37:58.023+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:37:58.025+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:58.025+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:37:58.026+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:58.025+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:37:58.039+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:58.039+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:37:58.067+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:58.066+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:37:58.068+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:58.068+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:37:58.069+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:37:58.086+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:37:58.085+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:37:58.086+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:37:58.115+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.223 seconds
[2024-06-27T02:38:28.254+0000] {processor.py:161} INFO - Started process (PID=1221) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:38:28.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:38:28.258+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:28.257+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:38:28.365+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:28.364+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:38:28.366+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:38:28.367+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:28.367+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:38:28.368+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:28.368+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:38:28.382+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:28.381+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:38:28.402+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:28.402+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:38:28.403+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:28.403+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:38:28.404+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:38:28.421+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:28.420+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:38:28.421+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:38:28.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.202 seconds
[2024-06-27T02:38:58.506+0000] {processor.py:161} INFO - Started process (PID=1233) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:38:58.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:38:58.511+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:58.510+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:38:58.632+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:58.631+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:38:58.633+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:38:58.635+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:58.634+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:38:58.637+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:58.636+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:38:58.656+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:58.656+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:38:58.678+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:58.678+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:38:58.680+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:58.679+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:38:58.681+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:38:58.699+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:38:58.698+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:38:58.699+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:38:58.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.404 seconds
[2024-06-27T02:39:29.342+0000] {processor.py:161} INFO - Started process (PID=1245) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:39:29.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:39:29.345+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:39:29.345+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:39:29.456+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:39:29.455+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:39:29.456+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:39:29.458+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:39:29.458+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:39:29.459+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:39:29.459+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:39:29.471+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:39:29.471+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:39:29.490+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:39:29.490+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:39:29.491+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:39:29.490+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:39:29.491+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:39:29.508+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:39:29.508+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:39:29.508+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:39:29.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.211 seconds
[2024-06-27T02:40:00.023+0000] {processor.py:161} INFO - Started process (PID=1257) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:40:00.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:40:00.026+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:00.026+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:40:00.125+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:00.125+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:40:00.126+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:40:00.127+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:00.127+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:40:00.128+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:00.128+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:40:00.141+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:00.141+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:40:00.163+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:00.162+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:40:00.163+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:00.163+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:40:00.164+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:40:00.180+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:00.179+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:40:00.180+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:40:00.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.193 seconds
[2024-06-27T02:40:31.022+0000] {processor.py:161} INFO - Started process (PID=1269) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:40:31.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:40:31.030+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:31.027+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:40:31.232+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:31.230+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:40:31.238+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:40:31.244+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:31.243+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:40:31.245+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:31.245+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:40:31.269+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:31.268+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:40:31.294+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:31.294+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:40:31.295+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:31.295+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:40:31.295+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:40:31.314+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:40:31.314+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:40:31.315+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:40:31.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.513 seconds
[2024-06-27T02:41:35.988+0000] {processor.py:161} INFO - Started process (PID=1280) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:41:35.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:41:35.991+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:41:35.991+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:41:36.557+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:41:36.556+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:41:36.558+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:41:36.560+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:41:36.560+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:41:36.561+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:41:36.560+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:41:37.559+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:41:37.559+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:41:37.692+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:41:37.691+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:41:37.696+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:41:37.696+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:41:37.698+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:41:41.323+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:41:41.258+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:41:41.342+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:42:10.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 34.381 seconds
[2024-06-27T02:42:40.461+0000] {processor.py:161} INFO - Started process (PID=1287) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:42:40.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:42:40.464+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:42:40.463+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:42:40.598+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:42:40.598+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:42:40.599+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:42:40.601+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:42:40.601+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:42:40.604+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:42:40.604+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:42:40.628+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:42:40.628+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:42:40.653+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:42:40.652+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:42:40.654+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:42:40.653+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:42:40.654+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:42:40.680+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:42:40.679+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:42:40.681+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:42:40.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.264 seconds
[2024-06-27T02:43:10.951+0000] {processor.py:161} INFO - Started process (PID=1298) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:43:10.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:43:10.954+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:43:10.953+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:43:11.091+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:43:11.090+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:43:11.091+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:43:11.093+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:43:11.092+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:43:11.093+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:43:11.093+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:43:11.105+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:43:11.104+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:43:11.121+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:43:11.121+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:43:11.122+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:43:11.122+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:43:11.122+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:43:11.137+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:43:11.137+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:43:11.138+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:43:11.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.232 seconds
[2024-06-27T02:44:24.496+0000] {processor.py:161} INFO - Started process (PID=1310) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:44:24.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:44:24.501+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:44:24.500+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:44:24.975+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:44:24.974+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:44:24.975+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:44:24.978+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:44:24.977+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:44:24.978+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:44:24.978+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:44:25.515+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:44:25.515+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:44:25.959+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:44:25.938+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:44:25.960+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:44:25.960+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:44:25.961+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:44:25.997+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:44:25.996+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:44:25.997+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:44:26.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 1.783 seconds
[2024-06-27T02:45:07.588+0000] {processor.py:161} INFO - Started process (PID=1316) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:45:07.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:45:07.592+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:45:07.592+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:45:07.732+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:45:07.731+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:45:07.733+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:45:07.735+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:45:07.734+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:45:07.735+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:45:07.735+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:45:07.751+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:45:07.751+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:45:07.771+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:45:07.771+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:45:07.772+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:45:07.772+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:45:07.773+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:45:07.793+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:45:07.793+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:45:07.794+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:45:07.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.248 seconds
[2024-06-27T02:46:59.856+0000] {processor.py:161} INFO - Started process (PID=1323) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:46:59.861+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:46:59.869+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:46:59.862+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:47:01.047+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:01.033+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:47:01.048+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:47:01.050+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:01.050+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:47:01.051+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:01.051+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:47:10.090+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:10.078+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:47:10.205+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:10.205+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:47:10.206+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:10.206+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:47:10.207+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:47:10.233+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:10.232+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:47:10.234+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:47:10.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 10.545 seconds
[2024-06-27T02:47:40.548+0000] {processor.py:161} INFO - Started process (PID=1334) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:47:40.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:47:40.551+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:40.551+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:47:40.673+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:40.673+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:47:40.674+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:47:40.676+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:40.675+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:47:40.676+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:40.676+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:47:40.690+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:40.690+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:47:40.715+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:40.714+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:47:40.717+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:40.716+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:47:40.718+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:47:40.791+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:47:40.790+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:47:40.792+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:47:41.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.493 seconds
[2024-06-27T02:48:11.718+0000] {processor.py:161} INFO - Started process (PID=1346) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:48:11.719+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:48:11.720+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:48:11.720+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:48:11.828+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:48:11.825+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:48:11.828+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:48:11.830+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:48:11.829+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:48:11.830+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:48:11.830+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:48:11.846+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:48:11.845+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:48:12.027+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:48:12.027+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:48:12.028+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:48:12.028+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:48:12.028+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:48:12.049+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:48:12.049+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:48:12.050+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:48:12.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.368 seconds
[2024-06-27T02:49:44.593+0000] {processor.py:161} INFO - Started process (PID=1352) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:49:44.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:49:44.598+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:49:44.598+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:49:45.284+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:49:45.280+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:49:45.285+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:49:45.288+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:49:45.287+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:49:45.289+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:49:45.289+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:49:55.425+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:49:55.311+0000] {before_sleep.py:65} DEBUG - Retrying <unknown> in 0.06399291707258964 seconds as it raised OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8).
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 677, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-27T02:49:55.494+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:49:55.493+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 2 of 3
[2024-06-27T02:49:55.495+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:49:55.495+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:50:05.565+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:05.513+0000] {before_sleep.py:65} DEBUG - Retrying <unknown> in 0.23350902155603592 seconds as it raised OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8).
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 677, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-27T02:50:05.801+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:05.801+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 3 of 3
[2024-06-27T02:50:05.802+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:05.802+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:50:06.385+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:06.384+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:50:06.584+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:06.583+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:50:06.589+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:06.588+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:50:06.590+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:50:06.839+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:06.839+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:50:06.840+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:50:06.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 22.194 seconds
[2024-06-27T02:50:11.796+0000] {processor.py:161} INFO - Started process (PID=1359) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:50:11.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:50:11.799+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:11.798+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:50:11.946+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:11.943+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:50:11.946+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:50:11.949+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:11.948+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:50:11.950+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:11.949+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:50:11.977+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:11.976+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:50:12.016+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:12.015+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:50:12.018+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:12.017+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:50:12.019+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:50:12.057+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:12.056+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:50:12.058+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:50:12.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.315 seconds
[2024-06-27T02:50:44.169+0000] {processor.py:161} INFO - Started process (PID=1371) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:50:44.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:50:44.172+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:44.172+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:50:44.278+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:44.276+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:50:44.279+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:50:44.280+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:44.280+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:50:44.281+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:44.280+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:50:44.292+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:44.292+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:50:44.314+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:44.313+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:50:44.314+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:44.314+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:50:44.315+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:50:44.332+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:50:44.332+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:50:44.333+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:50:44.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.196 seconds
[2024-06-27T02:52:42.104+0000] {processor.py:161} INFO - Started process (PID=1381) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:52:42.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:52:42.112+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:52:42.108+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:52:42.620+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:52:42.601+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:52:42.627+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:52:42.639+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:52:42.638+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:52:42.640+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:52:42.639+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:52:53.032+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:52:52.713+0000] {before_sleep.py:65} DEBUG - Retrying <unknown> in 0.33421515909472604 seconds as it raised OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8).
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 677, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 642, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 158, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 145, in _do_get
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2024-06-27T02:52:53.525+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:52:53.419+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 2 of 3
[2024-06-27T02:52:53.774+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:52:53.699+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:57:39.266+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:57:39.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:57:39.275+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:57:39.274+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:57:39.447+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:57:39.446+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:57:39.448+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:57:39.449+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:57:39.449+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:57:39.450+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:57:39.450+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:57:39.466+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:57:39.466+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:57:39.495+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:57:39.495+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:57:39.496+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:57:39.496+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:57:39.497+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:57:39.520+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:57:39.520+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:57:39.521+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:57:39.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.321 seconds
[2024-06-27T02:58:10.495+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:58:10.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:58:10.517+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:10.515+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:58:10.689+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:10.688+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:58:10.690+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:58:10.692+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:10.692+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:58:10.693+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:10.693+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:58:10.711+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:10.711+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:58:10.754+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:10.753+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:58:10.755+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:10.754+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:58:10.755+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:58:10.776+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:10.776+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:58:10.777+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:58:10.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.367 seconds
[2024-06-27T02:58:41.907+0000] {processor.py:161} INFO - Started process (PID=82) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:58:41.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:58:41.911+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:41.910+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:58:42.010+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:42.009+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:58:42.011+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:58:42.013+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:42.013+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:58:42.014+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:42.014+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:58:42.027+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:42.027+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:58:42.044+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:42.044+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:58:42.045+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:42.045+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:58:42.046+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:58:42.060+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:58:42.060+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:58:42.061+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:58:42.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.189 seconds
[2024-06-27T02:59:13.745+0000] {processor.py:161} INFO - Started process (PID=95) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:59:13.746+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:59:13.749+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:13.748+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:59:13.848+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:13.848+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:59:13.849+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:59:13.850+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:13.850+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:59:13.851+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:13.851+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:59:13.862+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:13.862+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:59:13.880+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:13.880+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:59:13.881+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:13.881+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:59:13.881+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:59:13.897+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:13.897+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:59:13.897+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:59:13.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.189 seconds
[2024-06-27T02:59:44.715+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/crawl.py
[2024-06-27T02:59:44.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T02:59:44.718+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:44.718+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T02:59:44.838+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:44.838+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T02:59:44.839+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T02:59:44.841+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:44.841+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T02:59:44.842+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:44.842+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T02:59:44.858+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:44.858+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T02:59:44.882+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:44.881+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T02:59:44.883+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:44.883+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T02:59:44.884+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T02:59:44.903+0000] {logging_mixin.py:188} INFO - [2024-06-27T02:59:44.902+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:59:44.903+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T02:59:44.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.249 seconds
[2024-06-27T03:00:16.250+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:00:16.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:00:16.253+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:16.253+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:00:16.376+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:16.376+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:00:16.378+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:00:16.379+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:16.379+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:00:16.381+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:16.381+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:00:16.394+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:16.394+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:00:16.413+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:16.412+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:00:16.414+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:16.414+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:00:16.415+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:00:16.431+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:16.431+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:00:16.432+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:00:16.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.217 seconds
[2024-06-27T03:00:48.782+0000] {processor.py:161} INFO - Started process (PID=131) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:00:48.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:00:48.788+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:48.787+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:00:48.897+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:48.896+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:00:48.897+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:00:48.899+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:48.898+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:00:48.899+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:48.899+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:00:48.913+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:48.913+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:00:48.933+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:48.933+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:00:48.934+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:48.934+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:00:48.934+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:00:48.950+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:00:48.950+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:00:48.951+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:00:48.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.213 seconds
[2024-06-27T03:01:19.520+0000] {processor.py:161} INFO - Started process (PID=143) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:01:19.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:01:19.524+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:19.524+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:01:19.625+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:19.624+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:01:19.626+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:01:19.627+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:19.627+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:01:19.628+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:19.628+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:01:19.642+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:19.642+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:01:19.661+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:19.660+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:01:19.662+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:19.661+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:01:19.662+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:01:19.677+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:19.676+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:01:19.678+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:01:19.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.192 seconds
[2024-06-27T03:01:50.584+0000] {processor.py:161} INFO - Started process (PID=155) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:01:50.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:01:50.599+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:50.598+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:01:50.815+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:50.814+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:01:50.815+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:01:50.817+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:50.817+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:01:50.818+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:50.818+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:01:50.842+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:50.842+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:01:50.878+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:50.878+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:01:50.879+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:50.879+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:01:50.880+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:01:50.902+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:01:50.902+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:01:50.903+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:01:50.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.378 seconds
[2024-06-27T03:02:21.368+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:02:21.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:02:21.371+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:21.370+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:02:21.475+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:21.474+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:02:21.476+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:02:21.478+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:21.477+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:02:21.478+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:21.478+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:02:21.492+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:21.492+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:02:21.510+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:21.510+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:02:21.512+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:21.511+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:02:21.512+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:02:21.528+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:21.528+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:02:21.529+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:02:21.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.197 seconds
[2024-06-27T03:02:52.572+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:02:52.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:02:52.576+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:52.576+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:02:52.710+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:52.709+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:02:52.711+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:02:52.712+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:52.712+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:02:52.712+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:52.712+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:02:52.724+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:52.724+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:02:52.742+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:52.742+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:02:52.743+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:52.743+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:02:52.743+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:02:52.761+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:02:52.761+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:02:52.762+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:02:52.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.229 seconds
[2024-06-27T03:03:23.892+0000] {processor.py:161} INFO - Started process (PID=191) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:03:23.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:03:23.897+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:23.896+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:03:24.048+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:24.047+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:03:24.049+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:03:24.050+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:24.050+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:03:24.051+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:24.051+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:03:24.066+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:24.066+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:03:24.086+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:24.085+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:03:24.087+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:24.086+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:03:24.087+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:03:24.105+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:24.105+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:03:24.105+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:03:24.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.254 seconds
[2024-06-27T03:03:54.737+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:03:54.739+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:03:54.741+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:54.741+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:03:54.854+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:54.853+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:03:54.855+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:03:54.857+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:54.857+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:03:54.858+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:54.858+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:03:54.879+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:54.879+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:03:54.904+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:54.904+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:03:54.905+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:54.905+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:03:54.906+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:03:54.928+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:03:54.927+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:03:54.928+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:03:54.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.223 seconds
[2024-06-27T03:04:25.239+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:04:25.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:04:25.243+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:25.243+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:04:25.344+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:25.344+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:04:25.345+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:04:25.346+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:25.346+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:04:25.347+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:25.347+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:04:25.361+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:25.360+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:04:25.377+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:25.376+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:04:25.378+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:25.377+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:04:25.378+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:04:25.393+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:25.393+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:04:25.394+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:04:25.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.189 seconds
[2024-06-27T03:04:56.460+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:04:56.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:04:56.463+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:56.463+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:04:56.576+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:56.576+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:04:56.577+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:04:56.579+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:56.578+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:04:56.580+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:56.579+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:04:56.593+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:56.592+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:04:56.610+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:56.610+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:04:56.611+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:56.611+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:04:56.611+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:04:56.626+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:04:56.626+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:04:56.627+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:04:56.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.205 seconds
[2024-06-27T03:05:27.295+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:05:27.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:05:27.298+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:27.297+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:05:27.413+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:27.412+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:05:27.414+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:05:27.415+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:27.415+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:05:27.416+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:27.416+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:05:27.431+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:27.431+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:05:27.451+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:27.451+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:05:27.452+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:27.452+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:05:27.453+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:05:27.469+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:27.469+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:05:27.470+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:05:27.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.221 seconds
[2024-06-27T03:05:58.026+0000] {processor.py:161} INFO - Started process (PID=252) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:05:58.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:05:58.030+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:58.029+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:05:58.155+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:58.155+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:05:58.156+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:05:58.158+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:58.157+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:05:58.158+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:58.158+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:05:58.173+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:58.173+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:05:58.191+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:58.191+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:05:58.192+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:58.192+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:05:58.193+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:05:58.214+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:05:58.213+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:05:58.215+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:05:58.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.237 seconds
[2024-06-27T03:07:07.839+0000] {processor.py:161} INFO - Started process (PID=264) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:07:07.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:07:07.921+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:07:07.901+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:07:08.817+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:07:08.781+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:07:08.819+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:07:08.822+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:07:08.822+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:07:08.823+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:07:08.823+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:07:11.742+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:07:11.729+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:07:11.831+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:07:11.831+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:07:11.833+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:07:11.832+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:07:11.833+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:07:11.855+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:07:11.855+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:07:11.856+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:07:11.908+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 4.138 seconds
[2024-06-27T03:08:01.227+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:08:01.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:08:01.231+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:01.230+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:08:01.695+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:01.691+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:08:01.697+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:08:01.699+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:01.699+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:08:01.700+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:01.700+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:08:01.731+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:01.730+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:08:01.763+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:01.762+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:08:01.764+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:01.763+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:08:01.764+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:08:01.797+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:01.797+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:08:01.798+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:08:01.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.627 seconds
[2024-06-27T03:08:33.247+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:08:33.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:08:33.251+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:33.250+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:08:33.375+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:33.374+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:08:33.375+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:08:33.377+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:33.376+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:08:33.377+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:33.377+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:08:33.391+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:33.391+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:08:33.411+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:33.411+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:08:33.412+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:33.412+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:08:33.413+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:08:33.429+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:08:33.429+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:08:33.430+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:08:33.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.218 seconds
[2024-06-27T03:09:04.412+0000] {processor.py:161} INFO - Started process (PID=82) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:09:04.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:09:04.416+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:04.415+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:09:04.518+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:04.518+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:09:04.519+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:09:04.520+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:04.520+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:09:04.521+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:04.521+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:09:04.534+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:04.534+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:09:04.551+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:04.550+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:09:04.552+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:04.551+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:09:04.552+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:09:04.568+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:04.567+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:09:04.568+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:09:04.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.361 seconds
[2024-06-27T03:09:35.566+0000] {processor.py:161} INFO - Started process (PID=94) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:09:35.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:09:35.569+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:35.569+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:09:35.678+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:35.677+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:09:35.679+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:09:35.680+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:35.680+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:09:35.681+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:35.681+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:09:35.694+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:35.694+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:09:35.712+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:35.711+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:09:35.713+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:35.712+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:09:35.713+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:09:35.728+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:09:35.728+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:09:35.729+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:09:35.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.198 seconds
[2024-06-27T03:10:07.285+0000] {processor.py:161} INFO - Started process (PID=106) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:10:07.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:10:07.292+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:07.291+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:10:07.557+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:07.556+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:10:07.557+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:10:07.559+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:07.559+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:10:07.559+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:07.559+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:10:07.573+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:07.572+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:10:07.597+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:07.597+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:10:07.598+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:07.597+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:10:07.598+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:10:07.617+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:07.616+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:10:07.618+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:10:07.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.387 seconds
[2024-06-27T03:10:38.573+0000] {processor.py:161} INFO - Started process (PID=117) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:10:38.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:10:38.581+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:38.580+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:10:38.745+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:38.744+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:10:38.745+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:10:38.748+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:38.748+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:10:38.751+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:38.750+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:10:38.772+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:38.772+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:10:38.814+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:38.813+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:10:38.816+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:38.816+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:10:38.820+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:10:38.859+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:10:38.859+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:10:38.860+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:10:38.910+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.355 seconds
[2024-06-27T03:11:10.250+0000] {processor.py:161} INFO - Started process (PID=129) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:11:10.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:11:10.256+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:10.255+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:11:10.365+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:10.365+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:11:10.366+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:11:10.368+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:10.367+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:11:10.368+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:10.368+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:11:10.383+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:10.383+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:11:10.412+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:10.412+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:11:10.413+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:10.413+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:11:10.414+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:11:10.436+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:10.435+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:11:10.437+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:11:10.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.229 seconds
[2024-06-27T03:11:43.072+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:11:43.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:11:43.077+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:43.076+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:11:43.219+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:43.216+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:11:43.220+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:11:43.225+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:43.224+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:11:43.226+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:43.225+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:11:43.247+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:43.246+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:11:43.295+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:43.295+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:11:43.297+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:43.296+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:11:43.298+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:11:43.336+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:11:43.335+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:11:43.341+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:11:43.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.347 seconds
[2024-06-27T03:12:13.662+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:12:13.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:12:13.667+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:13.666+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:12:13.802+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:13.801+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:12:13.802+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:12:13.804+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:13.804+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:12:13.805+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:13.805+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:12:13.822+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:13.821+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:12:13.847+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:13.847+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:12:13.848+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:13.848+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:12:13.849+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:12:13.868+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:13.867+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:12:13.869+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:12:13.917+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.264 seconds
[2024-06-27T03:12:44.143+0000] {processor.py:161} INFO - Started process (PID=164) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:12:44.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:12:44.149+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:44.148+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:12:44.281+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:44.281+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:12:44.282+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:12:44.284+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:44.283+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:12:44.284+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:44.284+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:12:44.301+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:44.300+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:12:44.325+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:44.324+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:12:44.326+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:44.326+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:12:44.326+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:12:44.348+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:12:44.348+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:12:44.348+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:12:44.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.264 seconds
[2024-06-27T03:13:15.144+0000] {processor.py:161} INFO - Started process (PID=176) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:13:15.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:13:15.148+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:15.147+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:13:15.248+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:15.247+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:13:15.249+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:13:15.250+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:15.250+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:13:15.251+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:15.250+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:13:15.263+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:15.263+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:13:15.281+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:15.281+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:13:15.282+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:15.282+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:13:15.283+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:13:15.300+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:15.300+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:13:15.301+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:13:15.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.193 seconds
[2024-06-27T03:13:45.653+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:13:45.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:13:45.657+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:45.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:13:45.757+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:45.756+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:13:45.757+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:13:45.759+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:45.759+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:13:45.760+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:45.759+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:13:45.773+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:45.773+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:13:45.791+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:45.791+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:13:45.792+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:45.792+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:13:45.793+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:13:45.808+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:13:45.807+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:13:45.809+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:13:45.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.189 seconds
[2024-06-27T03:14:17.825+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:14:17.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:14:17.834+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:17.833+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:14:18.027+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:18.026+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:14:18.027+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:14:18.030+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:18.029+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:14:18.033+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:18.032+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:14:18.052+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:18.051+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:14:18.089+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:18.089+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:14:18.091+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:18.090+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:14:18.093+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:14:18.113+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:18.112+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:14:18.114+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:14:18.164+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.351 seconds
[2024-06-27T03:14:49.987+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:14:49.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:14:49.992+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:49.991+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:14:50.130+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:50.129+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:14:50.131+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:14:50.133+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:50.133+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:14:50.134+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:50.134+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:14:50.166+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:50.166+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:14:50.203+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:50.202+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:14:50.204+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:50.203+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:14:50.204+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:14:50.229+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:14:50.229+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:14:50.230+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:14:50.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.296 seconds
[2024-06-27T03:15:20.759+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:15:20.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:15:20.765+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:20.764+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:15:20.907+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:20.906+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:15:20.908+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:15:20.910+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:20.909+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:15:20.911+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:20.910+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:15:20.927+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:20.927+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:15:20.947+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:20.947+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:15:20.948+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:20.947+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:15:20.948+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:15:20.965+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:20.965+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:15:20.966+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:15:20.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.249 seconds
[2024-06-27T03:15:51.454+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:15:51.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:15:51.459+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:51.459+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:15:51.573+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:51.571+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:15:51.574+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:15:51.576+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:51.575+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:15:51.576+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:51.576+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:15:51.590+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:51.589+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:15:51.615+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:51.614+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:15:51.616+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:51.615+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:15:51.616+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:15:51.634+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:15:51.633+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:15:51.634+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:15:51.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.218 seconds
[2024-06-27T03:16:21.966+0000] {processor.py:161} INFO - Started process (PID=247) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:16:21.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:16:21.978+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:21.978+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:16:22.203+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:22.202+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:16:22.204+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:16:22.205+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:22.205+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:16:22.206+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:22.206+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:16:22.225+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:22.224+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:16:22.271+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:22.271+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:16:22.273+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:22.272+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:16:22.273+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:16:22.315+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:22.314+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:16:22.315+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:16:22.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.467 seconds
[2024-06-27T03:16:54.613+0000] {processor.py:161} INFO - Started process (PID=260) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:16:54.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:16:54.621+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:54.620+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:16:54.799+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:54.798+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:16:54.800+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:16:54.802+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:54.801+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:16:54.803+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:54.803+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:16:54.820+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:54.820+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:16:54.842+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:54.842+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:16:54.843+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:54.843+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:16:54.844+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:16:54.864+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:16:54.864+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:16:54.865+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:16:55.216+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.616 seconds
[2024-06-27T03:17:26.237+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:17:26.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:17:26.241+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:26.241+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:17:26.348+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:26.348+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:17:26.349+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:17:26.350+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:26.350+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:17:26.351+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:26.351+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:17:26.366+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:26.366+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:17:26.387+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:26.386+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:17:26.388+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:26.387+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:17:26.388+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:17:26.404+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:26.404+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:17:26.405+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:17:26.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.203 seconds
[2024-06-27T03:17:57.102+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:17:57.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:17:57.106+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:57.106+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:17:57.215+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:57.214+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:17:57.215+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:17:57.217+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:57.217+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:17:57.218+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:57.218+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:17:57.238+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:57.238+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:17:57.260+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:57.259+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:17:57.261+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:57.261+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:17:57.261+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:17:57.282+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:17:57.282+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:17:57.283+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:17:57.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.221 seconds
[2024-06-27T03:18:27.474+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:18:27.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:18:27.479+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:27.479+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:18:27.601+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:27.600+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:18:27.601+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:18:27.603+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:27.603+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:18:27.605+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:27.604+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:18:27.623+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:27.623+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:18:27.641+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:27.641+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:18:27.642+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:27.642+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:18:27.643+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:18:27.658+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:27.657+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:18:27.658+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:18:27.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.219 seconds
[2024-06-27T03:18:59.272+0000] {processor.py:161} INFO - Started process (PID=308) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:18:59.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:18:59.276+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:59.276+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:18:59.400+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:59.399+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:18:59.400+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:18:59.401+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:59.401+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:18:59.402+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:59.402+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:18:59.413+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:59.413+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:18:59.432+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:59.432+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:18:59.433+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:59.433+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:18:59.434+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:18:59.450+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:18:59.449+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:18:59.450+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:18:59.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.216 seconds
[2024-06-27T03:19:30.095+0000] {processor.py:161} INFO - Started process (PID=320) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:19:30.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:19:30.100+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:19:30.100+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:19:30.242+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:19:30.241+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:19:30.243+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:19:30.244+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:19:30.244+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:19:30.245+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:19:30.245+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:19:30.269+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:19:30.269+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:19:30.298+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:19:30.298+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:19:30.299+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:19:30.299+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:19:30.300+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:19:30.323+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:19:30.322+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:19:30.323+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:19:30.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.272 seconds
[2024-06-27T03:20:01.341+0000] {processor.py:161} INFO - Started process (PID=333) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:20:01.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:20:01.347+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:01.346+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:20:01.498+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:01.494+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:20:01.499+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:20:01.501+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:01.500+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:20:01.502+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:01.502+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:20:01.523+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:01.523+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:20:01.560+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:01.559+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:20:01.561+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:01.560+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:20:01.562+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:20:01.587+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:01.587+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:20:01.588+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:20:01.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.305 seconds
[2024-06-27T03:20:32.053+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:20:32.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:20:32.060+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:32.059+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:20:32.207+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:32.206+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:20:32.207+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:20:32.209+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:32.209+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:20:32.209+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:32.209+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:20:32.227+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:32.226+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:20:32.255+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:32.254+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:20:32.255+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:32.255+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:20:32.256+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:20:32.278+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:20:32.278+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:20:32.279+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:20:32.313+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.275 seconds
[2024-06-27T03:21:02.992+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:21:02.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:21:02.997+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:02.996+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:21:03.125+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:03.125+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:21:03.126+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:21:03.127+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:03.127+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:21:03.128+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:03.128+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:21:03.141+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:03.141+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:21:03.160+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:03.159+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:21:03.161+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:03.160+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:21:03.161+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:21:03.177+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:03.177+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:21:03.178+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:21:03.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.229 seconds
[2024-06-27T03:21:33.657+0000] {processor.py:161} INFO - Started process (PID=368) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:21:33.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:21:33.662+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:33.661+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:21:33.778+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:33.777+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:21:33.778+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:21:33.780+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:33.780+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:21:33.781+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:33.780+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:21:33.795+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:33.794+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:21:33.815+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:33.815+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:21:33.816+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:33.816+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:21:33.816+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:21:33.833+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:21:33.833+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:21:33.834+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:21:33.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.214 seconds
[2024-06-27T03:22:04.580+0000] {processor.py:161} INFO - Started process (PID=380) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:22:04.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:22:04.584+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:04.584+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:22:04.711+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:04.710+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:22:04.711+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:22:04.714+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:04.713+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:22:04.715+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:04.714+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:22:04.728+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:04.728+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:22:04.748+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:04.747+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:22:04.749+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:04.748+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:22:04.749+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:22:04.768+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:04.767+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:22:04.769+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:22:04.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.237 seconds
[2024-06-27T03:22:35.742+0000] {processor.py:161} INFO - Started process (PID=392) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:22:35.746+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:22:35.748+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:35.748+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:22:35.893+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:35.892+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:22:35.894+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:22:35.895+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:35.895+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:22:35.896+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:35.896+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:22:35.911+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:35.910+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:22:35.932+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:35.932+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:22:35.933+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:35.933+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:22:35.934+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:22:35.951+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:22:35.951+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:22:35.951+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:22:35.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.252 seconds
[2024-06-27T03:23:06.810+0000] {processor.py:161} INFO - Started process (PID=404) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:23:06.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:23:06.813+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:06.813+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:23:06.915+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:06.915+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:23:06.916+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:23:06.918+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:06.918+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:23:06.919+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:06.918+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:23:06.933+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:06.933+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:23:06.950+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:06.950+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:23:06.951+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:06.951+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:23:06.952+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:23:06.966+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:06.966+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:23:06.967+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:23:06.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.196 seconds
[2024-06-27T03:23:37.955+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:23:37.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:23:37.962+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:37.960+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:23:38.109+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:38.109+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:23:38.110+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:23:38.111+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:38.111+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:23:38.112+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:38.112+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:23:38.126+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:38.126+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:23:38.153+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:38.153+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:23:38.154+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:38.154+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:23:38.156+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:23:38.173+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:23:38.172+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:23:38.173+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:23:38.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.266 seconds
[2024-06-27T03:24:08.688+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:24:08.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:24:08.694+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:08.693+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:24:08.854+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:08.852+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:24:08.854+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:24:08.857+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:08.856+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:24:08.858+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:08.857+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:24:08.881+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:08.880+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:24:08.910+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:08.909+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:24:08.912+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:08.911+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:24:08.913+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:24:08.948+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:08.948+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:24:08.949+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:24:08.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.315 seconds
[2024-06-27T03:24:40.132+0000] {processor.py:161} INFO - Started process (PID=442) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:24:40.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:24:40.137+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:40.137+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:24:40.346+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:40.345+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:24:40.347+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:24:40.349+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:40.348+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:24:40.349+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:40.349+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:24:40.400+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:40.399+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:24:40.423+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:40.423+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:24:40.425+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:40.424+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:24:40.425+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:24:40.446+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:24:40.446+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:24:40.447+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:24:40.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.362 seconds
[2024-06-27T03:25:11.086+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:25:11.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:25:11.091+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:11.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:25:11.194+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:11.194+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:25:11.195+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:25:11.196+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:11.196+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:25:11.197+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:11.197+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:25:11.209+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:11.209+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:25:11.228+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:11.228+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:25:11.229+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:11.229+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:25:11.230+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:25:11.245+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:11.244+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:25:11.245+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:25:11.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.198 seconds
[2024-06-27T03:25:42.008+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:25:42.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:25:42.013+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:42.012+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:25:42.141+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:42.141+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:25:42.142+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:25:42.144+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:42.143+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:25:42.145+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:42.144+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:25:42.158+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:42.157+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:25:42.177+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:42.177+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:25:42.178+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:42.178+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:25:42.179+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:25:42.193+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:25:42.193+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:25:42.194+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:25:42.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.226 seconds
[2024-06-27T03:26:15.681+0000] {processor.py:161} INFO - Started process (PID=478) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:26:15.734+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:26:15.737+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:26:15.737+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:26:16.082+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:26:16.081+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:26:16.083+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:26:16.085+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:26:16.085+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:26:16.086+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:26:16.086+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:26:16.118+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:26:16.117+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:26:16.197+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:26:16.196+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:26:16.198+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:26:16.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:26:16.198+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:26:16.229+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:26:16.228+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:26:16.232+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:26:16.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.622 seconds
[2024-06-27T03:29:16.094+0000] {processor.py:161} INFO - Started process (PID=491) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:29:16.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:29:16.104+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:16.099+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:29:17.452+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:17.432+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:29:17.453+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:29:17.455+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:17.455+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:29:17.456+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:17.456+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:29:21.363+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:21.360+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:29:22.081+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:22.080+0000] {serialized_dag.py:180} DEBUG - Writing Serialized DAG: selenium to the DB
[2024-06-27T03:29:22.089+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:22.088+0000] {serialized_dag.py:182} DEBUG - DAG: selenium written to the DB
[2024-06-27T03:29:22.090+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:22.089+0000] {dagbag.py:701} DEBUG - Syncing DAG permissions: selenium to the DB
[2024-06-27T03:29:22.625+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:22.624+0000] {override.py:1090} DEBUG - Not syncing DAG-level permissions for DAG 'DAG:selenium' as access control is unset.
[2024-06-27T03:29:22.627+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:22.626+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:29:22.629+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:29:22.652+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:22.651+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:29:22.652+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:29:23.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 6.982 seconds
[2024-06-27T03:29:53.516+0000] {processor.py:161} INFO - Started process (PID=504) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:29:53.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:29:53.520+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:53.520+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:29:53.630+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:53.629+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:29:53.631+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:29:53.633+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:53.633+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:29:53.634+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:53.633+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:29:53.647+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:53.647+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:29:53.663+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:53.663+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:29:53.664+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:53.664+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:29:53.665+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:29:53.679+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:29:53.679+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:29:53.680+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:29:53.710+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.201 seconds
[2024-06-27T03:30:23.974+0000] {processor.py:161} INFO - Started process (PID=522) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:30:23.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:30:23.980+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:23.979+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:30:24.086+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:24.086+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:30:24.087+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:30:24.088+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:24.088+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:30:24.089+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:24.089+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:30:24.102+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:24.102+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:30:24.126+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:24.126+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:30:24.127+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:24.127+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:30:24.128+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:30:24.143+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:24.143+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:30:24.144+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:30:24.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.206 seconds
[2024-06-27T03:30:54.524+0000] {processor.py:161} INFO - Started process (PID=533) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:30:54.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:30:54.528+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:54.528+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:30:54.631+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:54.629+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:30:54.631+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:30:54.633+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:54.633+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:30:54.634+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:54.634+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:30:54.646+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:54.646+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:30:54.663+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:54.663+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:30:54.664+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:54.664+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:30:54.665+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:30:54.679+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:30:54.679+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:30:54.680+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:30:54.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.190 seconds
[2024-06-27T03:31:24.849+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:31:24.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:31:24.855+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:24.854+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:31:25.004+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:24.996+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:31:25.006+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:31:25.008+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:25.007+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:31:25.009+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:25.008+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:31:25.031+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:25.030+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:31:25.062+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:25.062+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:31:25.063+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:25.063+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:31:25.063+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:31:25.080+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:25.080+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:31:25.081+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:31:25.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.280 seconds
[2024-06-27T03:31:55.433+0000] {processor.py:161} INFO - Started process (PID=557) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:31:55.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:31:55.439+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:55.438+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:31:55.671+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:55.669+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:31:55.672+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:31:55.674+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:55.674+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:31:55.675+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:55.674+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:31:55.692+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:55.692+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:31:55.719+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:55.718+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:31:55.720+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:55.720+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:31:55.720+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:31:55.737+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:31:55.737+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:31:55.737+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:31:55.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.359 seconds
[2024-06-27T03:32:26.249+0000] {processor.py:161} INFO - Started process (PID=569) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:32:26.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:32:26.253+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:26.253+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:32:26.370+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:26.369+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:32:26.371+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:32:26.374+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:26.374+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:32:26.376+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:26.376+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:32:26.393+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:26.393+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:32:26.415+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:26.415+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:32:26.416+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:26.416+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:32:26.417+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:32:26.436+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:26.435+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:32:26.437+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:32:26.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.228 seconds
[2024-06-27T03:32:57.314+0000] {processor.py:161} INFO - Started process (PID=581) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:32:57.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:32:57.318+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:57.318+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:32:57.427+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:57.427+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:32:57.428+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:32:57.429+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:57.429+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:32:57.430+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:57.430+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:32:57.443+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:57.443+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:32:57.461+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:57.460+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:32:57.462+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:57.461+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:32:57.462+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:32:57.478+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:32:57.478+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:32:57.479+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:32:57.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.200 seconds
[2024-06-27T03:33:28.004+0000] {processor.py:161} INFO - Started process (PID=593) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:33:28.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:33:28.010+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:28.009+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:33:28.214+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:28.211+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:33:28.214+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:33:28.217+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:28.216+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:33:28.218+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:28.217+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:33:28.248+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:28.247+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:33:28.277+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:28.277+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:33:28.279+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:28.278+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:33:28.280+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:33:28.306+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:28.305+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:33:28.306+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:33:28.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.386 seconds
[2024-06-27T03:33:58.539+0000] {processor.py:161} INFO - Started process (PID=606) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:33:58.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:33:58.545+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:58.544+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:33:58.651+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:58.650+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:33:58.652+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:33:58.653+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:58.653+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:33:58.654+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:58.654+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:33:58.669+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:58.669+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:33:58.692+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:58.691+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:33:58.693+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:58.693+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:33:58.694+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:33:58.713+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:33:58.713+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:33:58.714+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:33:58.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.309 seconds
[2024-06-27T03:34:29.119+0000] {processor.py:161} INFO - Started process (PID=618) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:34:29.122+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:34:29.125+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:34:29.125+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:34:29.296+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:34:29.296+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:34:29.297+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:34:29.299+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:34:29.299+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:34:29.300+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:34:29.300+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:34:29.320+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:34:29.319+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:34:29.343+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:34:29.343+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:34:29.344+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:34:29.344+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:34:29.345+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:34:29.373+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:34:29.373+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:34:29.374+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:34:29.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.302 seconds
[2024-06-27T03:34:59.964+0000] {processor.py:161} INFO - Started process (PID=630) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:34:59.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:34:59.968+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:34:59.968+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:35:00.084+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:00.083+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:35:00.085+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:35:00.086+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:00.086+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:35:00.087+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:00.087+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:35:00.101+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:00.101+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:35:00.118+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:00.117+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:35:00.119+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:00.119+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:35:00.119+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:35:00.135+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:00.134+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:35:00.136+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:35:00.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.204 seconds
[2024-06-27T03:35:30.734+0000] {processor.py:161} INFO - Started process (PID=642) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:35:30.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:35:30.738+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:30.738+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:35:30.872+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:30.872+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:35:30.873+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:35:30.875+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:30.875+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:35:30.876+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:30.875+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:35:30.889+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:30.888+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:35:30.905+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:30.905+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:35:30.906+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:30.906+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:35:30.907+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:35:30.922+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:35:30.922+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:35:30.922+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:35:30.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.222 seconds
[2024-06-27T03:36:01.266+0000] {processor.py:161} INFO - Started process (PID=655) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:36:01.268+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:36:01.271+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:01.270+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:36:01.379+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:01.378+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:36:01.380+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:36:01.381+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:01.381+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:36:01.382+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:01.381+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:36:01.395+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:01.395+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:36:01.412+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:01.412+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:36:01.413+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:01.413+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:36:01.414+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:36:01.429+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:01.429+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:36:01.430+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:36:01.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.199 seconds
[2024-06-27T03:36:32.165+0000] {processor.py:161} INFO - Started process (PID=667) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:36:32.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:36:32.170+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:32.169+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:36:32.278+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:32.277+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:36:32.279+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:36:32.280+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:32.280+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:36:32.281+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:32.281+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:36:32.294+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:32.294+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:36:32.311+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:32.310+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:36:32.312+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:32.312+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:36:32.313+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:36:32.327+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:36:32.327+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:36:32.328+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:36:32.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.198 seconds
[2024-06-27T03:37:02.622+0000] {processor.py:161} INFO - Started process (PID=680) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:37:02.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:37:02.628+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:02.628+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:37:02.786+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:02.785+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:37:02.787+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:37:02.788+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:02.788+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:37:02.789+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:02.789+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:37:02.804+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:02.804+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:37:02.826+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:02.826+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:37:02.828+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:02.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:37:02.830+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:37:02.850+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:02.850+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:37:02.851+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:37:02.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.273 seconds
[2024-06-27T03:37:33.262+0000] {processor.py:161} INFO - Started process (PID=692) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:37:33.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:37:33.266+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:33.265+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:37:33.378+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:33.378+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:37:33.379+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:37:33.381+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:33.380+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:37:33.382+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:33.381+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:37:33.395+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:33.395+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:37:33.411+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:33.411+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:37:33.412+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:33.412+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:37:33.413+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:37:33.429+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:37:33.428+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:37:33.429+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:37:33.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.207 seconds
[2024-06-27T03:38:03.818+0000] {processor.py:161} INFO - Started process (PID=704) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:38:03.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:38:03.822+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:03.821+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:38:03.923+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:03.922+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:38:03.924+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:38:03.925+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:03.925+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:38:03.926+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:03.926+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:38:03.938+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:03.938+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:38:03.956+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:03.956+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:38:03.957+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:03.957+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:38:03.958+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:38:03.972+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:03.971+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:38:03.972+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:38:03.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.186 seconds
[2024-06-27T03:38:34.649+0000] {processor.py:161} INFO - Started process (PID=715) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:38:34.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:38:34.652+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:34.652+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:38:34.757+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:34.756+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:38:34.757+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:38:34.759+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:34.759+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:38:34.759+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:34.759+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:38:34.771+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:34.771+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:38:34.789+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:34.788+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:38:34.790+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:34.789+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:38:34.790+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:38:34.804+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:38:34.804+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:38:34.805+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:38:34.833+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.193 seconds
[2024-06-27T03:39:05.610+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:39:05.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:39:05.614+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:05.614+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:39:05.714+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:05.713+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:39:05.715+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:39:05.716+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:05.716+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:39:05.717+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:05.716+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:39:05.730+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:05.730+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:39:05.749+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:05.749+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:39:05.750+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:05.750+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:39:05.751+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:39:05.766+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:05.765+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:39:05.766+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:39:05.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.187 seconds
[2024-06-27T03:39:36.414+0000] {processor.py:161} INFO - Started process (PID=739) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:39:36.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:39:36.418+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:36.417+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:39:36.537+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:36.536+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:39:36.537+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:39:36.539+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:36.539+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:39:36.540+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:36.540+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:39:36.554+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:36.553+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:39:36.575+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:36.574+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:39:36.575+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:36.575+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:39:36.576+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:39:36.594+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:39:36.593+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:39:36.594+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:39:36.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.214 seconds
[2024-06-27T03:40:07.461+0000] {processor.py:161} INFO - Started process (PID=751) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:40:07.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:40:07.465+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:07.465+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:40:07.591+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:07.589+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:40:07.592+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:40:07.593+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:07.593+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:40:07.593+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:07.593+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:40:07.605+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:07.604+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:40:07.622+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:07.622+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:40:07.623+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:07.623+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:40:07.623+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:40:07.638+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:07.638+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:40:07.639+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:40:07.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.213 seconds
[2024-06-27T03:40:38.290+0000] {processor.py:161} INFO - Started process (PID=763) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:40:38.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:40:38.293+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:38.293+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:40:38.410+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:38.409+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:40:38.410+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:40:38.412+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:38.412+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:40:38.413+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:38.412+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:40:38.426+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:38.426+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:40:38.444+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:38.443+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:40:38.445+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:38.444+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:40:38.445+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:40:38.459+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:40:38.459+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:40:38.460+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:40:38.485+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.202 seconds
[2024-06-27T03:41:09.199+0000] {processor.py:161} INFO - Started process (PID=775) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:41:09.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:41:09.205+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:09.204+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:41:09.387+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:09.387+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:41:09.388+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:41:09.389+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:09.389+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:41:09.389+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:09.389+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:41:09.402+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:09.402+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:41:09.422+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:09.422+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:41:09.423+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:09.423+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:41:09.423+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:41:09.441+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:09.441+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:41:09.442+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:41:09.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.286 seconds
[2024-06-27T03:41:40.015+0000] {processor.py:161} INFO - Started process (PID=787) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:41:40.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:41:40.116+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:40.116+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:41:40.561+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:40.561+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:41:40.562+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:41:40.563+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:40.563+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:41:40.564+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:40.564+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:41:40.578+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:40.577+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:41:40.595+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:40.595+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:41:40.596+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:40.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:41:40.596+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:41:40.612+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:41:40.612+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:41:40.613+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:41:40.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.629 seconds
[2024-06-27T03:42:11.450+0000] {processor.py:161} INFO - Started process (PID=799) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:42:11.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:42:11.491+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:11.491+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:42:11.683+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:11.682+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:42:11.684+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:42:11.686+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:11.686+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:42:11.687+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:11.687+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:42:11.706+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:11.706+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:42:11.729+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:11.729+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:42:11.730+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:11.730+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:42:11.731+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:42:11.745+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:11.745+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:42:11.746+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:42:11.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.326 seconds
[2024-06-27T03:42:41.999+0000] {processor.py:161} INFO - Started process (PID=812) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:42:42.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:42:42.014+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:42.013+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:42:42.361+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:42.359+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:42:42.362+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:42:42.371+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:42.370+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:42:42.373+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:42.372+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:42:42.401+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:42.401+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:42:42.463+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:42.460+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:42:42.468+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:42.468+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:42:42.470+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:42:42.519+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:42:42.519+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:42:42.523+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:42:45.655+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 3.681 seconds
[2024-06-27T03:43:15.884+0000] {processor.py:161} INFO - Started process (PID=826) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:43:15.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:43:15.891+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:15.890+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:43:16.026+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:16.025+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:43:16.027+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:43:16.029+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:16.028+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:43:16.030+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:16.030+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:43:16.046+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:16.045+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:43:16.068+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:16.067+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:43:16.069+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:16.068+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:43:16.070+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:43:16.089+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:16.089+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:43:16.090+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:43:16.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.265 seconds
[2024-06-27T03:43:46.852+0000] {processor.py:161} INFO - Started process (PID=838) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:43:46.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:43:46.857+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:46.856+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:43:47.023+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:47.022+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:43:47.023+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:43:47.025+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:47.025+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:43:47.026+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:47.026+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:43:47.047+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:47.047+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:43:47.082+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:47.082+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:43:47.083+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:47.083+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:43:47.083+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:43:47.105+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:43:47.104+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:43:47.105+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:43:47.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.307 seconds
[2024-06-27T03:44:17.337+0000] {processor.py:161} INFO - Started process (PID=849) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:44:17.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:44:17.373+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:17.372+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:44:17.603+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:17.602+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:44:17.604+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:44:17.608+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:17.607+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:44:17.609+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:17.609+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:44:17.642+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:17.640+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:44:17.685+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:17.684+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:44:17.687+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:17.686+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:44:17.688+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:44:17.729+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:17.728+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:44:17.730+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:44:17.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.477 seconds
[2024-06-27T03:44:48.012+0000] {processor.py:161} INFO - Started process (PID=861) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:44:48.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:44:48.025+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:48.024+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:44:48.254+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:48.253+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:44:48.256+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:44:48.259+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:48.258+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:44:48.262+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:48.261+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:44:48.286+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:48.285+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:44:48.321+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:48.321+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:44:48.322+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:48.322+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:44:48.323+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:44:48.350+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:44:48.349+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:44:48.351+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:44:48.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.409 seconds
[2024-06-27T03:45:19.863+0000] {processor.py:161} INFO - Started process (PID=873) to work on /opt/airflow/dags/crawl.py
[2024-06-27T03:45:19.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T03:45:19.873+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:45:19.872+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T03:45:20.064+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:45:20.063+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T03:45:20.065+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T03:45:20.067+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:45:20.066+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T03:45:20.067+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:45:20.067+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T03:45:20.083+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:45:20.083+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T03:45:20.119+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:45:20.119+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T03:45:20.122+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:45:20.121+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T03:45:20.124+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T03:45:20.153+0000] {logging_mixin.py:188} INFO - [2024-06-27T03:45:20.152+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:45:20.155+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T03:45:20.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.345 seconds
[2024-06-27T06:19:39.664+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:19:39.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:19:39.691+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:19:39.688+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:19:40.218+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:19:40.217+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:19:40.219+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:19:40.223+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:19:40.222+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:19:40.225+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:19:40.224+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:19:40.350+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:19:40.349+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:19:40.425+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:19:40.424+0000] {serialized_dag.py:180} DEBUG - Writing Serialized DAG: selenium to the DB
[2024-06-27T06:19:40.462+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:19:40.461+0000] {serialized_dag.py:182} DEBUG - DAG: selenium written to the DB
[2024-06-27T06:19:40.463+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:19:40.463+0000] {dagbag.py:701} DEBUG - Syncing DAG permissions: selenium to the DB
[2024-06-27T06:19:41.063+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:19:41.062+0000] {override.py:1090} DEBUG - Not syncing DAG-level permissions for DAG 'DAG:selenium' as access control is unset.
[2024-06-27T06:19:41.064+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:19:41.064+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:19:41.065+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:19:41.169+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:19:41.168+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:19:41.170+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:19:41.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 1.742 seconds
[2024-06-27T06:20:11.466+0000] {processor.py:161} INFO - Started process (PID=102) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:20:11.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:20:11.546+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:20:11.470+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:20:11.943+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:20:11.942+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:20:11.943+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:20:11.946+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:20:11.945+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:20:11.948+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:20:11.947+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:20:11.982+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:20:11.982+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:20:12.036+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:20:12.035+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:20:12.038+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:20:12.038+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:20:12.039+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:20:12.099+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:20:12.098+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:20:12.101+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:20:12.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.754 seconds
[2024-06-27T06:22:44.268+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:22:44.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:22:44.292+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:22:44.282+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:22:45.157+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:22:45.153+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:22:45.162+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:22:45.167+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:22:45.166+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:22:45.169+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:22:45.168+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:22:45.303+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:22:45.302+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:22:45.437+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:22:45.435+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:22:45.443+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:22:45.441+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:22:45.445+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:22:45.773+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:22:45.772+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:22:45.774+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:22:46.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 2.000 seconds
[2024-06-27T06:23:16.530+0000] {processor.py:161} INFO - Started process (PID=74) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:23:16.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:23:16.536+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:23:16.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:23:16.739+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:23:16.738+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:23:16.740+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:23:16.742+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:23:16.741+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:23:16.743+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:23:16.743+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:23:16.769+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:23:16.768+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:23:16.803+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:23:16.803+0000] {serialized_dag.py:180} DEBUG - Writing Serialized DAG: selenium to the DB
[2024-06-27T06:23:16.814+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:23:16.814+0000] {serialized_dag.py:182} DEBUG - DAG: selenium written to the DB
[2024-06-27T06:23:16.815+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:23:16.815+0000] {dagbag.py:701} DEBUG - Syncing DAG permissions: selenium to the DB
[2024-06-27T06:23:17.141+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:23:17.139+0000] {override.py:1090} DEBUG - Not syncing DAG-level permissions for DAG 'DAG:selenium' as access control is unset.
[2024-06-27T06:23:17.149+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:23:17.148+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:23:17.151+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:23:17.220+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:23:17.220+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:23:17.222+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:23:17.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.797 seconds
[2024-06-27T06:24:01.035+0000] {processor.py:161} INFO - Started process (PID=93) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:24:01.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:24:01.045+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:01.044+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:24:02.197+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:02.196+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:24:02.199+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:24:02.216+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:02.215+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:24:02.221+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:02.218+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:24:02.302+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:02.301+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:24:02.389+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:02.388+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:24:02.393+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:02.392+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:24:02.394+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:24:02.451+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:02.450+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:24:02.455+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:24:02.571+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 1.556 seconds
[2024-06-27T06:24:33.166+0000] {processor.py:161} INFO - Started process (PID=103) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:24:33.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:24:33.208+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:33.207+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:24:33.582+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:33.581+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:24:33.583+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:24:33.586+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:33.585+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:24:33.588+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:33.587+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:24:33.612+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:33.611+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:24:33.650+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:33.650+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:24:33.652+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:33.652+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:24:33.653+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:24:33.692+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:24:33.692+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:24:33.693+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:24:33.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.595 seconds
[2024-06-27T06:25:04.212+0000] {processor.py:161} INFO - Started process (PID=115) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:25:04.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:25:04.222+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:04.220+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:25:04.387+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:04.386+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:25:04.388+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:25:04.390+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:04.390+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:25:04.391+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:04.391+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:25:04.419+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:04.418+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:25:04.447+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:04.447+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:25:04.449+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:04.448+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:25:04.450+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:25:04.474+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:04.474+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:25:04.475+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:25:04.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.320 seconds
[2024-06-27T06:25:35.675+0000] {processor.py:161} INFO - Started process (PID=127) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:25:35.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:25:35.685+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:35.683+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:25:35.901+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:35.898+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:25:35.904+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:25:35.911+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:35.910+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:25:35.915+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:35.913+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:25:35.950+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:35.949+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:25:36.028+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:36.027+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:25:36.030+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:36.029+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:25:36.032+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:25:36.070+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:25:36.070+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:25:36.071+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:25:36.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.459 seconds
[2024-06-27T06:26:07.221+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:26:07.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:26:07.228+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:07.227+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:26:07.453+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:07.452+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:26:07.454+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:26:07.458+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:07.457+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:26:07.459+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:07.459+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:26:07.495+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:07.495+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:26:07.546+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:07.545+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:26:07.548+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:07.547+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:26:07.549+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:26:07.597+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:07.596+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:26:07.598+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:26:07.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.454 seconds
[2024-06-27T06:26:37.884+0000] {processor.py:161} INFO - Started process (PID=150) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:26:37.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:26:37.890+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:37.889+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:26:38.060+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:38.060+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:26:38.061+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:26:38.064+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:38.064+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:26:38.065+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:38.065+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:26:38.094+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:38.093+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:26:38.137+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:38.136+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:26:38.139+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:38.138+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:26:38.140+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:26:38.171+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:26:38.170+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:26:38.172+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:26:38.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.363 seconds
[2024-06-27T06:27:08.441+0000] {processor.py:161} INFO - Started process (PID=162) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:27:08.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:27:08.450+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:08.448+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:27:08.675+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:08.673+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:27:08.676+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:27:08.680+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:08.679+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:27:08.681+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:08.681+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:27:08.721+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:08.720+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:27:08.773+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:08.771+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:27:08.775+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:08.774+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:27:08.777+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:27:08.821+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:08.820+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:27:08.823+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:27:08.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.478 seconds
[2024-06-27T06:27:39.322+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:27:39.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:27:39.331+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:39.330+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:27:39.498+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:39.497+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:27:39.500+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:27:39.504+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:39.504+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:27:39.508+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:39.505+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:27:39.530+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:39.530+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:27:39.558+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:39.557+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:27:39.559+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:39.559+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:27:39.561+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:27:39.586+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:27:39.586+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:27:39.587+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:27:39.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.323 seconds
[2024-06-27T06:28:10.035+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:28:10.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:28:10.040+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:10.039+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:28:10.184+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:10.183+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:28:10.185+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:28:10.186+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:10.186+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:28:10.187+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:10.187+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:28:10.202+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:10.202+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:28:10.225+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:10.225+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:28:10.226+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:10.226+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:28:10.227+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:28:10.244+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:10.244+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:28:10.245+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:28:10.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.248 seconds
[2024-06-27T06:28:40.451+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:28:40.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:28:40.455+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:40.455+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:28:40.599+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:40.597+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:28:40.600+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:28:40.602+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:40.602+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:28:40.604+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:40.603+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:28:40.625+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:40.624+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:28:40.663+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:40.663+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:28:40.664+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:40.664+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:28:40.664+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:28:40.690+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:28:40.690+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:28:40.691+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:28:40.740+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.316 seconds
[2024-06-27T06:29:11.606+0000] {processor.py:161} INFO - Started process (PID=211) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:29:11.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:29:11.610+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:11.610+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:29:11.776+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:11.775+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:29:11.776+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:29:11.778+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:11.777+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:29:11.778+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:11.778+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:29:11.793+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:11.792+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:29:11.811+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:11.811+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:29:11.812+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:11.812+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:29:11.812+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:29:11.828+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:11.828+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:29:11.829+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:29:11.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.269 seconds
[2024-06-27T06:29:47.145+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:29:47.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:29:47.151+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:47.150+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:29:47.483+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:47.482+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:29:47.484+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:29:47.486+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:47.486+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:29:47.487+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:47.487+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:29:47.503+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:47.503+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:29:47.528+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:47.528+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:29:47.529+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:47.529+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:29:47.529+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:29:47.548+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:29:47.547+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:29:47.548+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:29:47.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.454 seconds
[2024-06-27T06:30:18.322+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:30:18.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:30:18.326+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:18.326+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:30:18.462+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:18.461+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:30:18.463+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:30:18.465+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:18.465+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:30:18.466+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:18.466+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:30:18.485+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:18.485+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:30:18.508+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:18.508+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:30:18.509+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:18.509+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:30:18.510+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:30:18.529+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:18.529+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:30:18.530+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:30:18.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.260 seconds
[2024-06-27T06:30:48.698+0000] {processor.py:161} INFO - Started process (PID=248) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:30:48.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:30:48.703+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:48.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:30:48.821+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:48.820+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:30:48.821+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:30:48.825+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:48.824+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:30:48.826+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:48.825+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:30:48.845+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:48.845+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:30:48.869+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:48.869+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:30:48.870+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:48.870+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:30:48.870+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:30:48.890+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:30:48.890+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:30:48.891+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:30:48.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.251 seconds
[2024-06-27T06:31:19.186+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:31:19.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:31:19.193+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:19.192+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:31:19.394+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:19.393+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:31:19.395+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:31:19.397+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:19.396+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:31:19.397+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:19.397+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:31:19.421+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:19.421+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:31:19.441+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:19.441+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:31:19.442+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:19.442+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:31:19.443+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:31:19.463+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:19.463+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:31:19.464+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:31:19.494+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.321 seconds
[2024-06-27T06:31:49.994+0000] {processor.py:161} INFO - Started process (PID=271) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:31:50.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:31:50.005+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:50.003+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:31:50.281+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:50.279+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:31:50.282+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:31:50.292+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:50.291+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:31:50.294+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:50.293+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:31:50.332+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:50.331+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:31:50.369+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:50.369+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:31:50.371+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:50.371+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:31:50.373+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:31:50.401+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:31:50.400+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:31:50.401+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:31:50.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.467 seconds
[2024-06-27T06:32:20.507+0000] {processor.py:161} INFO - Started process (PID=283) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:32:20.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:32:20.510+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:20.510+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:32:20.619+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:20.618+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:32:20.619+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:32:20.621+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:20.621+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:32:20.622+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:20.622+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:32:20.635+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:20.635+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:32:20.653+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:20.653+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:32:20.654+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:20.654+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:32:20.655+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:32:20.670+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:20.670+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:32:20.671+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:32:20.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.198 seconds
[2024-06-27T06:32:51.523+0000] {processor.py:161} INFO - Started process (PID=295) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:32:51.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:32:51.526+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:51.525+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:32:51.670+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:51.669+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:32:51.670+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:32:51.672+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:51.672+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:32:51.673+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:51.673+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:32:51.686+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:51.686+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:32:51.706+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:51.705+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:32:51.707+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:51.706+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:32:51.707+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:32:51.726+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:32:51.726+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:32:51.727+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:32:51.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.241 seconds
[2024-06-27T06:33:23.532+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:33:23.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:33:23.536+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:23.536+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:33:23.780+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:23.780+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:33:23.781+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:33:23.783+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:23.783+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:33:23.784+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:23.784+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:33:23.798+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:23.797+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:33:23.817+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:23.817+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:33:23.818+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:23.818+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:33:23.819+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:33:23.837+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:23.836+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:33:23.838+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:33:23.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.356 seconds
[2024-06-27T06:33:54.934+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:33:54.935+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:33:54.937+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:54.937+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:33:55.091+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:55.090+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:33:55.092+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:33:55.094+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:55.093+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:33:55.095+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:55.094+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:33:55.114+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:55.113+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:33:55.135+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:55.134+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:33:55.135+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:55.135+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:33:55.136+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:33:55.156+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:33:55.155+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:33:55.156+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:33:55.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.262 seconds
[2024-06-27T06:34:26.668+0000] {processor.py:161} INFO - Started process (PID=331) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:34:26.669+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:34:26.671+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:26.670+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:34:26.842+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:26.841+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:34:26.843+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:34:26.845+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:26.844+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:34:26.846+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:26.846+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:34:26.865+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:26.864+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:34:26.892+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:26.892+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:34:26.893+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:26.893+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:34:26.894+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:34:26.917+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:26.917+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:34:26.918+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:34:26.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.289 seconds
[2024-06-27T06:34:58.827+0000] {processor.py:161} INFO - Started process (PID=345) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:34:58.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:34:58.831+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:58.831+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:34:58.971+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:58.971+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:34:58.972+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:34:58.973+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:58.973+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:34:58.974+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:58.973+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:34:58.989+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:58.989+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:34:59.019+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:59.019+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:34:59.020+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:59.020+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:34:59.021+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:34:59.048+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:34:59.047+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:34:59.049+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:34:59.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.263 seconds
[2024-06-27T06:38:14.314+0000] {processor.py:161} INFO - Started process (PID=358) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:38:14.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:38:14.324+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:38:14.318+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:38:15.173+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:38:15.144+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:38:15.174+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:38:15.177+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:38:15.177+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:38:15.178+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:38:15.178+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:39:02.811+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:39:02.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:39:02.817+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:02.816+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:39:02.991+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:02.990+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:39:02.991+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:39:02.993+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:02.992+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:39:02.993+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:02.993+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:39:03.008+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:03.008+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:39:03.031+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:03.031+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:39:03.032+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:03.032+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:39:03.033+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:39:03.057+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:03.056+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:39:03.057+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:39:03.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.290 seconds
[2024-06-27T06:39:35.854+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:39:35.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:39:35.894+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:35.891+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:39:36.236+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:36.235+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:39:36.237+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:39:36.240+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:36.239+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:39:36.242+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:36.241+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:39:36.295+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:36.294+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:39:36.336+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:36.336+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:39:36.337+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:36.337+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:39:36.338+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:39:36.368+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:39:36.367+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:39:36.369+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:39:36.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.587 seconds
[2024-06-27T06:40:06.961+0000] {processor.py:161} INFO - Started process (PID=82) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:40:06.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:40:06.985+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:06.983+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:40:07.384+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:07.379+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:40:07.385+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:40:07.390+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:07.389+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:40:07.391+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:07.391+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:40:07.414+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:07.413+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:40:07.448+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:07.447+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:40:07.449+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:07.449+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:40:07.450+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:40:07.483+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:07.482+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:40:07.484+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:40:07.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.606 seconds
[2024-06-27T06:40:38.959+0000] {processor.py:161} INFO - Started process (PID=94) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:40:38.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:40:38.964+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:38.963+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:40:39.167+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:39.167+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:40:39.168+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:40:39.169+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:39.169+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:40:39.170+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:39.170+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:40:39.185+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:39.184+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:40:39.215+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:39.214+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:40:39.216+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:39.215+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:40:39.216+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:40:39.239+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:40:39.239+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:40:39.240+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:40:39.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.325 seconds
[2024-06-27T06:41:09.411+0000] {processor.py:161} INFO - Started process (PID=105) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:41:09.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:41:09.416+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:09.416+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:41:09.552+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:09.552+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:41:09.553+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:41:09.555+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:09.554+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:41:09.555+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:09.555+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:41:09.571+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:09.571+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:41:09.591+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:09.591+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:41:09.592+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:09.592+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:41:09.593+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:41:09.609+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:09.609+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:41:09.610+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:41:09.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.240 seconds
[2024-06-27T06:41:40.380+0000] {processor.py:161} INFO - Started process (PID=116) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:41:40.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:41:40.384+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:40.384+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:41:40.645+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:40.643+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:41:40.646+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:41:40.648+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:40.647+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:41:40.648+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:40.648+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:41:40.673+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:40.672+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:41:40.709+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:40.709+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:41:40.711+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:40.711+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:41:40.712+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:41:40.744+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:41:40.744+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:41:40.745+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:41:40.799+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 0.427 seconds
[2024-06-27T06:42:35.574+0000] {processor.py:161} INFO - Started process (PID=123) to work on /opt/airflow/dags/crawl.py
[2024-06-27T06:42:35.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/crawl.py for tasks to queue
[2024-06-27T06:42:35.589+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:42:35.580+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/crawl.py
[2024-06-27T06:42:36.492+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:42:36.480+0000] {dagbag.py:511} DEBUG - Loaded DAG <DAG: selenium>
[2024-06-27T06:42:36.493+0000] {processor.py:840} INFO - DAG(s) 'selenium' retrieved from /opt/airflow/dags/crawl.py
[2024-06-27T06:42:36.495+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:42:36.494+0000] {dagbag.py:667} DEBUG - Running dagbag.sync_to_db with retries. Try 1 of 3
[2024-06-27T06:42:36.495+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:42:36.495+0000] {dagbag.py:672} DEBUG - Calling the DAG.bulk_sync_to_db method
[2024-06-27T06:42:40.894+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:42:40.881+0000] {serialized_dag.py:166} DEBUG - Checking if DAG (selenium) changed
[2024-06-27T06:42:41.076+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:42:41.075+0000] {serialized_dag.py:177} DEBUG - Serialized DAG (selenium) is unchanged. Skipping writing to DB
[2024-06-27T06:42:41.078+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:42:41.077+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-06-27T06:42:41.079+0000] {logging_mixin.py:188} WARNING - Sync 1 DAGs
[2024-06-27T06:42:41.129+0000] {logging_mixin.py:188} INFO - [2024-06-27T06:42:41.128+0000] {dag.py:3954} INFO - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:42:41.130+0000] {logging_mixin.py:188} WARNING - Setting next_dagrun for selenium to None, run_after=None
[2024-06-27T06:42:41.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/crawl.py took 5.674 seconds
